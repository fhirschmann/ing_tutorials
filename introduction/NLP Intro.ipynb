{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Goal of this section is to get started with textual data. We will start preprocessing data and make use of the **Natural Language Toolkit (NLTK)**\n",
    "\n",
    "At the end of this session you will be able to work with textual data and you will know some of the parts related to working with textual data and pre-processing it like:\n",
    "\n",
    "- Cleaning\n",
    "- Tokenizing\n",
    "- Segementation\n",
    "- Normalizing\n",
    "- Stemming\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this part of of the Session we will make use of NKTK and use the data provided by NLTK. To get the relevant data use the download function from NLTK. And download the parts realted to the NLTK Book:\n",
    "1. d (Download function) \n",
    "2. book (Download Content related to the NLTK book)\n",
    "3. q ( Quit)\n",
    "\n",
    "This will download all the data wen need for this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK Downloader\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> d\n",
      "\n",
      "Download which package (l=list; x=cancel)?\n",
      "  Identifier> book\n",
      "    Downloading collection 'book'\n",
      "       | \n",
      "       | Downloading package abc to\n",
      "       |     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "       |   Package abc is already up-to-date!\n",
      "       | Downloading package brown to\n",
      "       |     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "       |   Package brown is already up-to-date!\n",
      "       | Downloading package chat80 to\n",
      "       |     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "       |   Package chat80 is already up-to-date!\n",
      "       | Downloading package cmudict to\n",
      "       |     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "       |   Package cmudict is already up-to-date!\n",
      "       | Downloading package conll2000 to\n",
      "       |     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "       |   Package conll2000 is already up-to-date!\n",
      "       | Downloading package conll2002 to\n",
      "       |     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "       |   Package conll2002 is already up-to-date!\n",
      "       | Downloading package dependency_treebank to\n",
      "       |     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "       |   Package dependency_treebank is already up-to-date!\n",
      "       | Downloading package genesis to\n",
      "       |     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "       |   Package genesis is already up-to-date!\n",
      "       | Downloading package gutenberg to\n",
      "       |     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "       |   Package gutenberg is already up-to-date!\n",
      "       | Downloading package ieer to\n",
      "       |     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "       |   Package ieer is already up-to-date!\n",
      "       | Downloading package inaugural to\n",
      "       |     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "       |   Package inaugural is already up-to-date!\n",
      "       | Downloading package movie_reviews to\n",
      "       |     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "       |   Package movie_reviews is already up-to-date!\n",
      "       | Downloading package nps_chat to\n",
      "       |     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "       |   Package nps_chat is already up-to-date!\n",
      "       | Downloading package names to\n",
      "       |     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "       |   Package names is already up-to-date!\n",
      "       | Downloading package ppattach to\n",
      "       |     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "       |   Package ppattach is already up-to-date!\n",
      "       | Downloading package reuters to\n",
      "       |     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "       |   Package reuters is already up-to-date!\n",
      "       | Downloading package senseval to\n",
      "       |     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "       |   Package senseval is already up-to-date!\n",
      "       | Downloading package state_union to\n",
      "       |     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "       |   Package state_union is already up-to-date!\n",
      "       | Downloading package stopwords to\n",
      "       |     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "       |   Unzipping corpora\\stopwords.zip.\n",
      "       | Downloading package swadesh to\n",
      "       |     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "       |   Package swadesh is already up-to-date!\n",
      "       | Downloading package timit to\n",
      "       |     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "       |   Package timit is already up-to-date!\n",
      "       | Downloading package treebank to\n",
      "       |     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "       |   Package treebank is already up-to-date!\n",
      "       | Downloading package toolbox to\n",
      "       |     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "       |   Package toolbox is already up-to-date!\n",
      "       | Downloading package udhr to\n",
      "       |     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "       |   Package udhr is already up-to-date!\n",
      "       | Downloading package udhr2 to\n",
      "       |     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "       |   Package udhr2 is already up-to-date!\n",
      "       | Downloading package unicode_samples to\n",
      "       |     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "       |   Package unicode_samples is already up-to-date!\n",
      "       | Downloading package webtext to\n",
      "       |     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "       |   Package webtext is already up-to-date!\n",
      "       | Downloading package wordnet to\n",
      "       |     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "       |   Package wordnet is already up-to-date!\n",
      "       | Downloading package wordnet_ic to\n",
      "       |     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "       |   Package wordnet_ic is already up-to-date!\n",
      "       | Downloading package words to\n",
      "       |     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "       |   Package words is already up-to-date!\n",
      "       | Downloading package maxent_treebank_pos_tagger to\n",
      "       |     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "       |   Package maxent_treebank_pos_tagger is already up-to-date!\n",
      "       | Downloading package maxent_ne_chunker to\n",
      "       |     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "       |   Package maxent_ne_chunker is already up-to-date!\n",
      "       | Downloading package universal_tagset to\n",
      "       |     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "       |   Package universal_tagset is already up-to-date!\n",
      "       | Downloading package punkt to\n",
      "       |     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "       |   Package punkt is already up-to-date!\n",
      "       | Downloading package book_grammars to\n",
      "       |     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "       |   Package book_grammars is already up-to-date!\n",
      "       | Downloading package city_database to\n",
      "       |     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "       |   Package city_database is already up-to-date!\n",
      "       | Downloading package tagsets to\n",
      "       |     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "       |   Package tagsets is already up-to-date!\n",
      "       | Downloading package panlex_swadesh to\n",
      "       |     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "       | Downloading package averaged_perceptron_tagger to\n",
      "       |     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "       |   Package averaged_perceptron_tagger is already up-to-date!\n",
      "       | \n",
      "     Done downloading collection book\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> q\n"
     ]
    }
   ],
   "source": [
    "nltk.download_shell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the data and preparing it for the next steps is our first task in many applications. We will perform the following steps:\n",
    "1. Load the raw text.\n",
    "2. Split into tokens.\n",
    "3. Convert to lowercase.\n",
    "4. Remove punctuation from each token.\n",
    "5. Filter out remaining tokens that are not alphabetic.\n",
    "6. Filter out tokens that are stop words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get some HTML data\n",
    "url = \"http://www.madrid-guide-spain.com/classic-madrid.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//E'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib import request\n",
    "html = request.urlopen(url).read()\n",
    "html[:60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For cleaning of the HTML we will use a Python Library called Beatiful Soup. This is in general a very handy Library when working with HTML. More infromation is available at:\n",
    "http://www.crummy.com/software/BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!conda install beautifulsoup4 -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw = BeautifulSoup(html,\"lxml\").get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nClassic Madrid\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFIX.designMode=\"legacy\";FIX.doEndOfHead();\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHomeGetting HereGetting AroundOnward TravelHotelsHostelsActivitiesWhat AttractionsExcursionsFor Kids!CultureSportRomanticShop ´til you Drop!Where to EatEssential InfoAtoZWork Here!BlogSitemapContact usOther Guides\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nClassic Madrid  The Top 10 spots to experience Classic Madrid as per Madrid Guide Spain. Looking for some tips to make your visit special?Not sure exactly what to do now you are here?Try the following:  Top Ten: Classic Madrid   Museo de la Ciudad\\rStudy the citys story from its inception through to the modern day. Who did what? Why? How did the civil war change the face of classic Madrid to the modern metroplois it is now? Discover the origins of the Madrileño!\\nMuseo del Prado\\nTHE gallery to see Picassos works. The largest collection of his work in one place however the gallery explores the works and influences of many other Spanish artists at the same time. Cenerally located and with guide/study materials available in EnglishPlaza ColonA monument with associated subterranean museum dedicated to Spains greatest gift to the world. The discovery of the \"Americas\". See the route taken and the names of the sailors in 30ft high relief. Just off the side of the Castellana and within 20 minutes walk of the city centre.   google_ad_client=\"pub-3211798476142792\";google_ad_width=120;google_ad_height=600;google_ad_format=\"120x600_as\";google_ad_type=\"text_image\";google_ad_channel=\"2928989412\";google_color_border=\"ffcc00\";google_color_bg=\"ffcc00\";google_color_link=\"0000FF\";google_color_text=\"000000\";google_color_url=\"0000ff\";      Museo THYSSEN-BORNEMISZA\\rUnderstand the progression of both materials and styles of Spanish art & sculpture from the 13th Century to today. Conveniently located close to the Mueseo del Prado hours can be spent wallowing in a graphical history of Spain\\rWalk La LatinaJourney through Madrids oldest residential neighbourhood and birthplace of Madrids famous sons. Plaques indicate who lived where and maps are available from the tourist centre in Plaza Mayor with recomended routes! Ventas\\rThe epicentre of Spanish and indeed world bullfighting. Whilst the spectacle itself may be a little too much for some palates the arena itself is a protected / listed building and features heavily in Spanish history. Its even believed to be where communist sympathizers were exectuted during and after the civil war!\\rTeatro & OperaTake in one of the many high class performances of contemperary or classical works in Madrids Gran Via. Regular performances the Spanish national Orchestra see people travelling from Europe to Madrid only for this reason.\\rPlaza MayorThe historic town centre / village square in which regular markets were once held. Famed for its painted decoration of its internal walls it also houses a visitor centre and regular free exhibitions.!\\rRoyal Palace and La AlmudenaVisit two of Madrids principle\\rmonuments\\r and get a taste for the rich history of the city. Conveniently located just 10 minutes walk from the centre of the city you can spend as much or as little time as you want.\\rExhibition centres in Retiro ParkTwo exhibition centres within the confines of this leafy park contain both permanent and temporary exhibitions of Spanish culture. Notwithstanding the fact that the park itself has a history and monuments all of its own!   ... and if these \"Classic Madrid\" suggestions did not take your fancy try some other Top 10s! ...or check out some of Madrids other attractions!   Home     google_ad_client=\"pub-3211798476142792\";google_ad_slot=\"6165530840\";google_ad_width=468;google_ad_height=60;    \\n      Enter your search terms  Submit search form         Web   www.madrid-guide-spain.com               \\n            \\n\\n\\n\\n\\n\\nsocializeit({pack:1,domain:\"madrid-guide-spain.com\",payItText:\"\",szColor:\"\",whatIsThisUrl:\"\"});\\n\\n\\n\\nExplore 100\\'s of pages about Madrid via the Sitemap ...>\\r\\n\\n© 2006-2012 www.Madrid-Guide-Spain.com\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFIX.doEndOfBody();\\n (function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0];if(d.getElementById(id)){return;}js=d.createElement(s);js.id=id;js.src=\"//connect.facebook.net/en_US/all.js#xfbml=1\";fjs.parentNode.insertBefore(js,fjs);}(document,\\'script\\',\\'facebook-jssdk\\'));\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing will split our text first into sentences and then into word tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "Discover the origins of the Madrileño!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import sent_tokenize\n",
    "sentences = sent_tokenize(raw)\n",
    "print(len(sentences))\n",
    "print(sentences[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "['...', 'or', 'check', 'out', 'some', 'of', 'madrids', 'other', 'attractions', '!']\n"
     ]
    }
   ],
   "source": [
    "tokenized_docs = [word_tokenize(sentence.lower()) for sentence in sentences] \n",
    "print(len(tokenized_docs))\n",
    "print(tokenized_docs[27])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop Word removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop words are highly frequent words like \"the\" or \"to\". Stopwords usually have little lexical content and in many cases we want to remove stop words from our text. NLTK comes with a stop words corpus conatining commonly agreed upon stop words for a variety of languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words('english'))\n",
    "stop_words=stopwords.words('english')\n",
    "# getting rid of all the symbols\n",
    "# stop_words.update(['.', ',', '\"', \"'\", '?', '!', ':', ';', '(', ')', '[', ']', '{', '}']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removeStopWords(words):\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_text = [removeStopWords(sentence) for sentence in tokenized_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['looking', 'tips', 'make', 'visit', 'special', '?', 'sure', 'exactly', '?', 'try', 'following', ':', 'top', 'ten', ':', 'classic', 'madrid', 'museo', 'de', 'la', 'ciudad', 'study', 'citys', 'story', 'inception', 'modern', 'day', '.']\n"
     ]
    }
   ],
   "source": [
    "print(clean_text[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative to remove stopwords is to remove stopwords based on a POS Tagger, we will see this later\n",
    "\n",
    "Another normalization task involves identifying non-standard words including numbers, abbreviations, and dates, and mapping any such tokens to a special vocabulary. For example, every decimal number could be mapped to a single token 0.0, and every acronym could be mapped to AAA. This keeps the vocabulary small and improves the accuracy of many language modeling tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# removal of stopwords  alternative check POS TAGSET\n",
    "#https://stackoverflow.com/questions/19130512/stopword-removal-with-nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "NLTK includes several off-the-shelf stemmers, and if you ever need a stemmer you should use one of these in preference to crafting your own using regular expressions, since these handle a wide range of irregular cases. The Porter and Lancaster stemmers follow their own rules for stripping affixes. Observe that the Porter stemmer correctly handles the word lying (mapping it to lie), while the Lancaster stemmer does not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "raw = \"\"\"DENNIS: Listen, strange women lying in ponds distributing swords\n",
    "is no basis for a system of government.  Supreme executive power derives from\n",
    "a mandate from the masses, not from some farcical aquatic ceremony.\"\"\"\n",
    "tokens = word_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DENNIS: Listen, strange women lying in ponds distributing swords\n",
      "is no basis for a system of government.  Supreme executive power derives from\n",
      "a mandate from the masses, not from some farcical aquatic ceremony.\n"
     ]
    }
   ],
   "source": [
    "print(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DENNI', ':', 'Listen', ',', 'strang', 'women', 'lie', 'in', 'pond', 'distribut', 'sword', 'is', 'no', 'basi', 'for', 'a', 'system', 'of', 'govern', '.', 'Suprem', 'execut', 'power', 'deriv', 'from', 'a', 'mandat', 'from', 'the', 'mass', ',', 'not', 'from', 'some', 'farcic', 'aquat', 'ceremoni', '.']\n"
     ]
    }
   ],
   "source": [
    "porter = nltk.PorterStemmer()\n",
    "lancaster = nltk.LancasterStemmer()\n",
    "print([porter.stem(t) for t in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['den', ':', 'list', ',', 'strange', 'wom', 'lying', 'in', 'pond', 'distribut', 'sword', 'is', 'no', 'bas', 'for', 'a', 'system', 'of', 'govern', '.', 'suprem', 'execut', 'pow', 'der', 'from', 'a', 'mand', 'from', 'the', 'mass', ',', 'not', 'from', 'som', 'farc', 'aqu', 'ceremony', '.']\n"
     ]
    }
   ],
   "source": [
    "print([lancaster.stem(t) for t in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DENNIS', ':', 'Listen', ',', 'strange', 'women', 'lie', 'in', 'ponds', 'distribute', 'swords', 'be', 'no', 'basis', 'for', 'a', 'system', 'of', 'government', '.', 'Supreme', 'executive', 'power', 'derive', 'from', 'a', 'mandate', 'from', 'the', 'mass', ',', 'not', 'from', 'some', 'farcical', 'aquatic', 'ceremony', '.']\n"
     ]
    }
   ],
   "source": [
    "wnl = nltk.WordNetLemmatizer()\n",
    "print([wnl.lemmatize(t, pos=\"v\") for t in tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part-of-speech tagging is one of the most important text analysis tasks used to classify words into their part-of-speech and label them accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review = \"\"\"WOW! The best word that describes this movie is \"wow\"! \n",
    "Not only to say that this is the best Action movie of all time, \n",
    "this is probably one of the greatest movies ever made. \n",
    "The people in my country watched this film when there where limited VHS cassettes at all. \n",
    "And again, my favorite Director did an timeless epic-masterpiece. \n",
    "Yes, an epic. Every scene in this movie is beyond the perfection. The timeless plot. \n",
    "Groundbreaking effects. Unforgettable \"Hasta la vista, baby.\" .\n",
    "\n",
    "Perfect direction for a sci-fix action film.\n",
    "When the action starts, you're in for the ride of your life. \n",
    "There never be the same movie like T2. \n",
    "What else I can say about this film? A Must see for everyone.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('best', 'JJS'),\n",
       " ('word', 'NN'),\n",
       " ('that', 'IN'),\n",
       " ('describes', 'VBZ'),\n",
       " ('this', 'DT'),\n",
       " ('movie', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('``', '``'),\n",
       " ('wow', 'JJ'),\n",
       " (\"''\", \"''\"),\n",
       " ('!', '.')]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = word_tokenize(sent_tokenize(review)[1])\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the labels are described in the help of NLTK, to get the description for all POS classes just call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$: dollar\n",
      "    $ -$ --$ A$ C$ HK$ M$ NZ$ S$ U.S.$ US$\n",
      "'': closing quotation mark\n",
      "    ' ''\n",
      "(: opening parenthesis\n",
      "    ( [ {\n",
      "): closing parenthesis\n",
      "    ) ] }\n",
      ",: comma\n",
      "    ,\n",
      "--: dash\n",
      "    --\n",
      ".: sentence terminator\n",
      "    . ! ?\n",
      ":: colon or ellipsis\n",
      "    : ; ...\n",
      "CC: conjunction, coordinating\n",
      "    & 'n and both but either et for less minus neither nor or plus so\n",
      "    therefore times v. versus vs. whether yet\n",
      "CD: numeral, cardinal\n",
      "    mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty-\n",
      "    seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025\n",
      "    fifteen 271,124 dozen quintillion DM2,000 ...\n",
      "DT: determiner\n",
      "    all an another any both del each either every half la many much nary\n",
      "    neither no some such that the them these this those\n",
      "EX: existential there\n",
      "    there\n",
      "FW: foreign word\n",
      "    gemeinschaft hund ich jeux habeas Haementeria Herr K'ang-si vous\n",
      "    lutihaw alai je jour objets salutaris fille quibusdam pas trop Monte\n",
      "    terram fiche oui corporis ...\n",
      "IN: preposition or conjunction, subordinating\n",
      "    astride among uppon whether out inside pro despite on by throughout\n",
      "    below within for towards near behind atop around if like until below\n",
      "    next into if beside ...\n",
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n",
      "JJR: adjective, comparative\n",
      "    bleaker braver breezier briefer brighter brisker broader bumper busier\n",
      "    calmer cheaper choosier cleaner clearer closer colder commoner costlier\n",
      "    cozier creamier crunchier cuter ...\n",
      "JJS: adjective, superlative\n",
      "    calmest cheapest choicest classiest cleanest clearest closest commonest\n",
      "    corniest costliest crassest creepiest crudest cutest darkest deadliest\n",
      "    dearest deepest densest dinkiest ...\n",
      "LS: list item marker\n",
      "    A A. B B. C C. D E F First G H I J K One SP-44001 SP-44002 SP-44005\n",
      "    SP-44007 Second Third Three Two * a b c d first five four one six three\n",
      "    two\n",
      "MD: modal auxiliary\n",
      "    can cannot could couldn't dare may might must need ought shall should\n",
      "    shouldn't will would\n",
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n",
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n",
      "NNPS: noun, proper, plural\n",
      "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
      "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
      "    Apache Apaches Apocrypha ...\n",
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n",
      "PDT: pre-determiner\n",
      "    all both half many quite such sure this\n",
      "POS: genitive marker\n",
      "    ' 's\n",
      "PRP: pronoun, personal\n",
      "    hers herself him himself hisself it itself me myself one oneself ours\n",
      "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
      "PRP$: pronoun, possessive\n",
      "    her his mine my our ours their thy your\n",
      "RB: adverb\n",
      "    occasionally unabatingly maddeningly adventurously professedly\n",
      "    stirringly prominently technologically magisterially predominately\n",
      "    swiftly fiscally pitilessly ...\n",
      "RBR: adverb, comparative\n",
      "    further gloomier grander graver greater grimmer harder harsher\n",
      "    healthier heavier higher however larger later leaner lengthier less-\n",
      "    perfectly lesser lonelier longer louder lower more ...\n",
      "RBS: adverb, superlative\n",
      "    best biggest bluntest earliest farthest first furthest hardest\n",
      "    heartiest highest largest least less most nearest second tightest worst\n",
      "RP: particle\n",
      "    aboard about across along apart around aside at away back before behind\n",
      "    by crop down ever fast for forth from go high i.e. in into just later\n",
      "    low more off on open out over per pie raising start teeth that through\n",
      "    under unto up up-pp upon whole with you\n",
      "SYM: symbol\n",
      "    % & ' '' ''. ) ). * + ,. < = > @ A[fj] U.S U.S.S.R * ** ***\n",
      "TO: \"to\" as preposition or infinitive marker\n",
      "    to\n",
      "UH: interjection\n",
      "    Goodbye Goody Gosh Wow Jeepers Jee-sus Hubba Hey Kee-reist Oops amen\n",
      "    huh howdy uh dammit whammo shucks heck anyways whodunnit honey golly\n",
      "    man baby diddle hush sonuvabitch ...\n",
      "VB: verb, base form\n",
      "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
      "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
      "    boost brace break bring broil brush build ...\n",
      "VBD: verb, past tense\n",
      "    dipped pleaded swiped regummed soaked tidied convened halted registered\n",
      "    cushioned exacted snubbed strode aimed adopted belied figgered\n",
      "    speculated wore appreciated contemplated ...\n",
      "VBG: verb, present participle or gerund\n",
      "    telegraphing stirring focusing angering judging stalling lactating\n",
      "    hankerin' alleging veering capping approaching traveling besieging\n",
      "    encrypting interrupting erasing wincing ...\n",
      "VBN: verb, past participle\n",
      "    multihulled dilapidated aerosolized chaired languished panelized used\n",
      "    experimented flourished imitated reunifed factored condensed sheared\n",
      "    unsettled primed dubbed desired ...\n",
      "VBP: verb, present tense, not 3rd person singular\n",
      "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
      "    appear tend stray glisten obtain comprise detest tease attract\n",
      "    emphasize mold postpone sever return wag ...\n",
      "VBZ: verb, present tense, 3rd person singular\n",
      "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
      "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
      "    seduces fizzes uses bolsters slaps speaks pleads ...\n",
      "WDT: WH-determiner\n",
      "    that what whatever which whichever\n",
      "WP: WH-pronoun\n",
      "    that what whatever whatsoever which who whom whosoever\n",
      "WP$: WH-pronoun, possessive\n",
      "    whose\n",
      "WRB: Wh-adverb\n",
      "    how however whence whenever where whereby whereever wherein whereof why\n",
      "``: opening quotation mark\n",
      "    ` ``\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('.*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER - Named Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of a named entity recognition (NER) system is to identify all textual mentions of the named entities.\n",
    "\n",
    "NLTK provides a classifier that has already been trained to recognize named entities, accessed with the function nltk.ne_chunk(). If we set the parameter binary=True, then named entities are just tagged as NE; otherwise, the classifier adds category labels such as PERSON, ORGANIZATION, and GPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#http://www.bbc.com/future/story/20180126-meet-the-motorbike-racing-robot\n",
    "sent=\"\"\"Yamaha’s initial concept was a “humanoid robot that can ride a motorcycle autonomously” and the company teamed up with SRI International to achieve its vision. SRI, the Stanford Research Institute, as it was originally known, was founded in 1946 to be the cutting edge of innovation in Silicon Valley\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It', 'is', 'home', 'to', 'the', 'longest', 'automobile', 'race', 'in', 'the', 'United', 'States', ',', 'known', 'as', 'the', '25', 'Hours', 'of', 'Thunderhill', ',', 'and', 'last', 'September', ',', 'it', 'was', 'host', 'to', 'a', 'very', 'different', 'kind', 'of', 'race', ':', 'a', 'race', 'between', 'man', 'and', 'machine', '.']\n",
      "[('Yamaha’s', 'NNP'), ('initial', 'JJ'), ('concept', 'NN'), ('was', 'VBD'), ('a', 'DT'), ('“humanoid', 'JJ'), ('robot', 'NN'), ('that', 'WDT'), ('can', 'MD'), ('ride', 'VB'), ('a', 'DT'), ('motorcycle', 'NN'), ('autonomously”', 'NN'), ('and', 'CC'), ('the', 'DT'), ('company', 'NN'), ('teamed', 'VBD'), ('up', 'RP'), ('with', 'IN'), ('SRI', 'NNP'), ('International', 'NNP'), ('to', 'TO'), ('achieve', 'VB'), ('its', 'PRP$'), ('vision', 'NN'), ('.', '.'), ('SRI', 'NNP'), (',', ','), ('the', 'DT'), ('Stanford', 'NNP'), ('Research', 'NNP'), ('Institute', 'NNP'), (',', ','), ('as', 'IN'), ('it', 'PRP'), ('was', 'VBD'), ('originally', 'RB'), ('known', 'VBN'), (',', ','), ('was', 'VBD'), ('founded', 'VBN'), ('in', 'IN'), ('1946', 'CD'), ('to', 'TO'), ('be', 'VB'), ('the', 'DT'), ('cutting', 'VBG'), ('edge', 'NN'), ('of', 'IN'), ('innovation', 'NN'), ('in', 'IN'), ('Silicon', 'NNP'), ('Valley', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "sent=word_tokenize(sent)\n",
    "print(sent_tokenized)\n",
    "sent=nltk.pos_tag(sent)\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  Yamaha’s/NNP\n",
      "  initial/JJ\n",
      "  concept/NN\n",
      "  was/VBD\n",
      "  a/DT\n",
      "  “humanoid/JJ\n",
      "  robot/NN\n",
      "  that/WDT\n",
      "  can/MD\n",
      "  ride/VB\n",
      "  a/DT\n",
      "  motorcycle/NN\n",
      "  autonomously”/NN\n",
      "  and/CC\n",
      "  the/DT\n",
      "  company/NN\n",
      "  teamed/VBD\n",
      "  up/RP\n",
      "  with/IN\n",
      "  (ORGANIZATION SRI/NNP International/NNP)\n",
      "  to/TO\n",
      "  achieve/VB\n",
      "  its/PRP$\n",
      "  vision/NN\n",
      "  ./.\n",
      "  (ORGANIZATION SRI/NNP)\n",
      "  ,/,\n",
      "  the/DT\n",
      "  (ORGANIZATION Stanford/NNP Research/NNP Institute/NNP)\n",
      "  ,/,\n",
      "  as/IN\n",
      "  it/PRP\n",
      "  was/VBD\n",
      "  originally/RB\n",
      "  known/VBN\n",
      "  ,/,\n",
      "  was/VBD\n",
      "  founded/VBN\n",
      "  in/IN\n",
      "  1946/CD\n",
      "  to/TO\n",
      "  be/VB\n",
      "  the/DT\n",
      "  cutting/VBG\n",
      "  edge/NN\n",
      "  of/IN\n",
      "  innovation/NN\n",
      "  in/IN\n",
      "  (GPE Silicon/NNP)\n",
      "  Valley/NNP)\n"
     ]
    }
   ],
   "source": [
    "print(nltk.ne_chunk(sent, binary=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with some easy example for Supervised learning. We will build a classifier that tells us the gender of a name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start by loading the Names corpus and having a look at some attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names = nltk.corpus.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['female.txt', 'male.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "male_names = names.words('male.txt')\n",
    "female_names = names.words('female.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also have a look at names that are ambiguous for gender:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abbey', 'Abbie', 'Abby', 'Addie', 'Adrian', 'Adrien', 'Ajay', 'Alex', 'Alexis', 'Alfie', 'Ali', 'Alix', 'Allie', 'Allyn', 'Andie', 'Andrea', 'Andy', 'Angel', 'Angie', 'Ariel', 'Ashley', 'Aubrey', 'Augustine', 'Austin', 'Averil', 'Barrie', 'Barry', 'Beau', 'Bennie', 'Benny', 'Bernie', 'Bert', 'Bertie', 'Bill', 'Billie', 'Billy', 'Blair', 'Blake', 'Bo', 'Bobbie', 'Bobby', 'Brandy', 'Brett', 'Britt', 'Brook', 'Brooke', 'Brooks', 'Bryn', 'Cal', 'Cam', 'Cammy', 'Carey', 'Carlie', 'Carlin', 'Carmine', 'Carroll', 'Cary', 'Caryl', 'Casey', 'Cass', 'Cat', 'Cecil', 'Chad', 'Chris', 'Chrissy', 'Christian', 'Christie', 'Christy', 'Clair', 'Claire', 'Clare', 'Claude', 'Clem', 'Clemmie', 'Cody', 'Connie', 'Constantine', 'Corey', 'Corrie', 'Cory', 'Courtney', 'Cris', 'Daffy', 'Dale', 'Dallas', 'Dana', 'Dani', 'Daniel', 'Dannie', 'Danny', 'Darby', 'Darcy', 'Darryl', 'Daryl', 'Deane', 'Del', 'Dell', 'Demetris', 'Dennie', 'Denny', 'Devin', 'Devon', 'Dion', 'Dionis', 'Dominique', 'Donnie', 'Donny', 'Dorian', 'Dory', 'Drew', 'Eddie', 'Eddy', 'Edie', 'Elisha', 'Emmy', 'Erin', 'Esme', 'Evelyn', 'Felice', 'Fran', 'Francis', 'Frank', 'Frankie', 'Franky', 'Fred', 'Freddie', 'Freddy', 'Gabriel', 'Gabriell', 'Gail', 'Gale', 'Gay', 'Gayle', 'Gene', 'George', 'Georgia', 'Georgie', 'Geri', 'Germaine', 'Gerri', 'Gerry', 'Gill', 'Ginger', 'Glen', 'Glenn', 'Grace', 'Gretchen', 'Gus', 'Haleigh', 'Haley', 'Hannibal', 'Harley', 'Hazel', 'Heath', 'Henrie', 'Hilary', 'Hillary', 'Holly', 'Ike', 'Ikey', 'Ira', 'Isa', 'Isador', 'Isadore', 'Jackie', 'Jaime', 'Jamie', 'Jan', 'Jean', 'Jere', 'Jermaine', 'Jerrie', 'Jerry', 'Jess', 'Jesse', 'Jessie', 'Jo', 'Jodi', 'Jodie', 'Jody', 'Joey', 'Jordan', 'Juanita', 'Jude', 'Judith', 'Judy', 'Julie', 'Justin', 'Karel', 'Kellen', 'Kelley', 'Kelly', 'Kelsey', 'Kerry', 'Kim', 'Kip', 'Kirby', 'Kit', 'Kris', 'Kyle', 'Lane', 'Lanny', 'Lauren', 'Laurie', 'Lee', 'Leigh', 'Leland', 'Lesley', 'Leslie', 'Lin', 'Lind', 'Lindsay', 'Lindsey', 'Lindy', 'Lonnie', 'Loren', 'Lorne', 'Lorrie', 'Lou', 'Luce', 'Lyn', 'Lynn', 'Maddie', 'Maddy', 'Marietta', 'Marion', 'Marlo', 'Martie', 'Marty', 'Mattie', 'Matty', 'Maurise', 'Max', 'Maxie', 'Mead', 'Meade', 'Mel', 'Meredith', 'Merle', 'Merrill', 'Merry', 'Meryl', 'Michal', 'Michel', 'Michele', 'Mickie', 'Micky', 'Millicent', 'Morgan', 'Morlee', 'Muffin', 'Nat', 'Nichole', 'Nickie', 'Nicky', 'Niki', 'Nikki', 'Noel', 'Ollie', 'Page', 'Paige', 'Pat', 'Patrice', 'Patsy', 'Pattie', 'Patty', 'Pen', 'Pennie', 'Penny', 'Perry', 'Phil', 'Pooh', 'Quentin', 'Quinn', 'Randi', 'Randie', 'Randy', 'Ray', 'Regan', 'Reggie', 'Rene', 'Rey', 'Ricki', 'Rickie', 'Ricky', 'Rikki', 'Robbie', 'Robin', 'Ronnie', 'Ronny', 'Rory', 'Ruby', 'Sal', 'Sam', 'Sammy', 'Sandy', 'Sascha', 'Sasha', 'Saundra', 'Sayre', 'Scotty', 'Sean', 'Shaine', 'Shane', 'Shannon', 'Shaun', 'Shawn', 'Shay', 'Shayne', 'Shea', 'Shelby', 'Shell', 'Shelley', 'Sibyl', 'Simone', 'Sonnie', 'Sonny', 'Stacy', 'Sunny', 'Sydney', 'Tabbie', 'Tabby', 'Tallie', 'Tally', 'Tammie', 'Tammy', 'Tate', 'Ted', 'Teddie', 'Teddy', 'Terri', 'Terry', 'Theo', 'Tim', 'Timmie', 'Timmy', 'Tobe', 'Tobie', 'Toby', 'Tommie', 'Tommy', 'Tony', 'Torey', 'Trace', 'Tracey', 'Tracie', 'Tracy', 'Val', 'Vale', 'Valentine', 'Van', 'Vin', 'Vinnie', 'Vinny', 'Virgie', 'Wallie', 'Wallis', 'Wally', 'Whitney', 'Willi', 'Willie', 'Willy', 'Winnie', 'Winny', 'Wynn']\n"
     ]
    }
   ],
   "source": [
    "print([w for w in male_names if w in female_names])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is well known that names ending in the letter a are almost always female. We can see this and some other patterns in a graph produced by the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cfd = nltk.ConditionalFreqDist(\n",
    "    (fileid, name[-1])\n",
    "    for fileid in names.fileids()\n",
    "        for name in names.words(fileid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cfd.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in building our classifier is to decide for the features and how to encode them. We will start by looking at the final letter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'last_letter': 'k'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gender_features(word):\n",
    "    return {'last_letter': word[-1]}\n",
    "gender_features('Patrick')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeled_names = ([(name, 'male') for name in names.words('male.txt')] + [(name, 'female') for name in names.words('female.txt')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(labeled_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use the feature extractor to process the names data, and divide the resulting list of feature sets into a training set and a test set. The training set is used to train a new \"naive Bayes\" classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featuresets = [(gender_features(n), gender) for (n, gender) in labeled_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set, test_set = featuresets[500:], featuresets[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'male'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(gender_features('Patrick'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'female'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(gender_features('Sohpie'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can systematically evaluate the classifier on a much larger quantity of unseen data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.808\n"
     ]
    }
   ],
   "source": [
    " print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also have a look at the best performing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                last_two = 'na'           female : male   =     98.5 : 1.0\n",
      "                last_two = 'la'           female : male   =     73.2 : 1.0\n",
      "                last_two = 'ia'           female : male   =     40.9 : 1.0\n",
      "             last_letter = 'a'            female : male   =     35.6 : 1.0\n",
      "                last_two = 'sa'           female : male   =     35.1 : 1.0\n",
      "                last_two = 'ta'           female : male   =     32.9 : 1.0\n",
      "             last_letter = 'k'              male : female =     31.1 : 1.0\n",
      "                last_two = 'us'             male : female =     29.5 : 1.0\n",
      "                last_two = 'do'             male : female =     27.4 : 1.0\n",
      "                last_two = 'ra'           female : male   =     27.0 : 1.0\n",
      "                last_two = 'rd'             male : female =     24.8 : 1.0\n",
      "              last_three = 'ana'          female : male   =     24.5 : 1.0\n",
      "                last_two = 'rt'             male : female =     23.8 : 1.0\n",
      "                last_two = 'ld'             male : female =     22.5 : 1.0\n",
      "              last_three = 'ard'            male : female =     21.2 : 1.0\n",
      "              last_three = 'nne'          female : male   =     20.6 : 1.0\n",
      "                last_two = 'os'             male : female =     19.6 : 1.0\n",
      "              last_three = 'vin'            male : female =     17.2 : 1.0\n",
      "              last_three = 'ita'          female : male   =     16.5 : 1.0\n",
      "              last_three = 'old'            male : female =     16.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your Turn: Modify the gender_features() function to provide the classifier with features encoding the length of the name, its first letter, and any other features that seem like they might be informative. Retrain the classifier with these new features, and test its accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gender_features(word):\n",
    "    return {'last_letter': word[-1],\n",
    "            'first_two': word[:-2],\n",
    "            'last_two': word[-2:],\n",
    "            'last_three': word[-3:],\n",
    "            'lenght': len(word),\n",
    "            'first_letter': word[1],\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.808\n"
     ]
    }
   ],
   "source": [
    "featuresets = [(gender_features(n), gender) for (n, gender) in labeled_names]\n",
    "train_set, test_set = featuresets[500:], featuresets[:500]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can also try another classifier, for instance the SVM from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk.classify\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.814\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.classify.SklearnClassifier(LinearSVC(C=0.1,class_weight=\"balanced\"))\n",
    "classifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Review Data\n",
    "\n",
    "lets have a look at more complex problem: Sentiment Analysis\n",
    "\n",
    "Sentiment analysis can be seen as a part of Text classification. Goal is to detect if a text is positive or negative (or neutral)\n",
    "NLTK comes already with a large set of textual documents and also has some data for Sentiment Analysis which we will use in the remainder of this session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a list with movie reviews from the NLTK corpus\n",
    "# every element in the list is a list with the words of the review and the sentiment (pos/neg)\n",
    "documents = [(list(movie_reviews.words(fileid)), category) for category in movie_reviews.categories() for fileid in movie_reviews.fileids(category)]\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "overall we have a set of 2000 movie reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = movie_reviews.raw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plot : two teen couples go to a church party , drink and then drive . \\nthey get into an accident . \\none of the guys dies , but his girlfriend continues to see him in her life , and has nightmares . \\nwhat\\'s the deal ? \\nwatch the movie and \" sorta \" find out . . . \\ncritique : a mind-fuck movie for the teen generation that touches on a very cool idea , but presents it in a very bad package . \\nwhich is what makes this review an even harder one to write , since i generally applaud films which attempt to break the mold , mess with your head and such ( lost highway & memento ) , but there are good and bad ways of making all types of films , and these folks just didn\\'t snag this one correctly . \\nthey seem to have taken this pretty neat concept , but executed it terribly . \\nso what are the problems with the movie ? \\nwell , its main problem is that it\\'s simply too jumbled . \\nit starts off \" normal \" but then downshifts into this \" fantasy \" world in which you , as an audience member , have no id'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pos/cv000_29590.txt', 'pos/cv001_18431.txt', 'pos/cv002_15918.txt', 'pos/cv003_11664.txt', 'pos/cv004_11636.txt', 'pos/cv005_29443.txt', 'pos/cv006_15448.txt', 'pos/cv007_4968.txt', 'pos/cv008_29435.txt', 'pos/cv009_29592.txt']\n",
      "['neg/cv000_29416.txt', 'neg/cv001_19502.txt', 'neg/cv002_17424.txt', 'neg/cv003_12683.txt', 'neg/cv004_12641.txt', 'neg/cv005_29357.txt', 'neg/cv006_17022.txt', 'neg/cv007_4992.txt', 'neg/cv008_29326.txt', 'neg/cv009_29417.txt']\n"
     ]
    }
   ],
   "source": [
    "documents = defaultdict(list)\n",
    "for i in movie_reviews.fileids():\n",
    "    documents[i.split('/')[0]].append(i)\n",
    "print(documents['pos'][:10])# first ten pos reviws.)\n",
    "\n",
    "print(documents['neg'][:10])# first ten neg reviews.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "documents = [([w for w in movie_reviews.words(i) if w.lower() not in stop and w.lower() not in string.punctuation], i.split('/')[0]) for i in movie_reviews.fileids()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "\n",
    "all_words = FreqDist(w.lower() for w in movie_reviews.words())\n",
    "word_features = list(word for (word,count) in all_words.most_common(2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def document_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'contains(should)': False, 'contains(intelligent)': False, 'contains(hilarious)': True, 'contains(grant)': False, 'contains(russell)': False, 'contains(turns)': False, 'contains(hour)': False, 'contains(camera)': False, 'contains(possible)': False, 'contains(anne)': False, 'contains(he)': True, 'contains(tarzan)': False, 'contains(looking)': False, 'contains(audience)': False, 'contains(leading)': False, 'contains(country)': False, 'contains(max)': False, 'contains(cinematography)': False, 'contains(social)': False, 'contains(sounds)': False, 'contains(90)': False, 'contains(robert)': False, 'contains(third)': True, 'contains(once)': True, 'contains(says)': False, 'contains(a)': True, 'contains(had)': False, 'contains(look)': True, 'contains(low)': False, 'contains(mars)': False, 'contains(front)': False, 'contains(credit)': False, 'contains(simply)': False, 'contains(teenagers)': False, 'contains(earlier)': False, 'contains(horror)': False, 'contains(choice)': False, 'contains(headed)': False, 'contains(various)': False, 'contains(land)': False, 'contains(frame)': False, 'contains(professor)': False, 'contains(final)': False, 'contains(ways)': False, 'contains(needs)': False, 'contains(extreme)': False, 'contains(theater)': False, 'contains(emotional)': False, 'contains(annie)': False, 'contains(exciting)': False, 'contains(brother)': False, 'contains(same)': True, 'contains(wrote)': False, 'contains(admit)': False, 'contains(1998)': False, 'contains(driver)': False, 'contains(elements)': False, 'contains(sexy)': False, 'contains(called)': False, 'contains(hit)': False, 'contains(genre)': False, 'contains(save)': False, 'contains(experience)': False, 'contains(richard)': False, 'contains(motion)': False, 'contains(convincing)': False, 'contains(by)': True, 'contains(fans)': False, 'contains(tells)': False, 'contains(ahead)': False, 'contains(subtle)': False, 'contains(-)': True, 'contains(performance)': False, 'contains(lady)': False, 'contains(want)': False, 'contains(technical)': False, 'contains(went)': False, 'contains(ted)': False, 'contains(trust)': False, 'contains(white)': False, 'contains(treat)': False, 'contains(cop)': False, 'contains(audiences)': False, 'contains(loved)': False, 'contains(escape)': False, 'contains(rose)': False, 'contains(fresh)': False, 'contains(reach)': False, 'contains(hot)': False, 'contains(willing)': False, 'contains(free)': False, 'contains(wait)': False, 'contains(1)': False, 'contains(winner)': False, 'contains(hotel)': False, 'contains(take)': False, 'contains(reviews)': False, 'contains(laughable)': False, 'contains(contains)': False, 'contains(light)': False, 'contains(target)': False, 'contains(though)': False, 'contains(mix)': False, 'contains(patrick)': False, 'contains(government)': False, 'contains(actor)': False, 'contains(events)': False, \"contains(')\": True, 'contains(players)': False, 'contains(seems)': False, 'contains(peter)': False, 'contains(call)': False, 'contains(effect)': False, 'contains(sheer)': False, 'contains(obvious)': False, 'contains(instead)': False, 'contains(moments)': False, 'contains(;)': False, 'contains(pure)': False, 'contains(overly)': False, 'contains(when)': True, 'contains(shot)': False, 'contains(dollars)': False, 'contains(x)': False, 'contains(nobody)': False, 'contains(ill)': False, 'contains(fail)': False, 'contains(growing)': False, 'contains(buy)': False, 'contains(mr)': False, 'contains(seemed)': False, 'contains(bill)': False, 'contains(shallow)': False, 'contains(,)': True, 'contains(success)': False, 'contains(recently)': False, 'contains(opportunity)': False, 'contains(tries)': True, 'contains(creepy)': False, 'contains(script)': False, 'contains(al)': False, 'contains(knows)': False, 'contains(seeing)': True, 'contains(van)': False, 'contains(=)': False, 'contains(bug)': False, 'contains(c)': False, 'contains(hair)': False, 'contains(number)': False, 'contains(trip)': False, 'contains(scientist)': False, 'contains(roberts)': False, 'contains(and)': True, 'contains(runs)': False, 'contains(rare)': False, 'contains(vincent)': False, 'contains(owner)': False, 'contains(powers)': False, 'contains(appearance)': False, 'contains(fast)': True, 'contains(talking)': False, 'contains(sorry)': False, 'contains(direction)': False, 'contains(running)': False, 'contains(forces)': False, 'contains(dad)': False, 'contains(gives)': False, 'contains(formula)': False, 'contains(u)': False, 'contains(presence)': False, 'contains(break)': False, 'contains(extremely)': False, 'contains(half)': False, 'contains(form)': False, 'contains(era)': False, 'contains(very)': True, 'contains(crowd)': False, 'contains(travolta)': False, 'contains(atmosphere)': False, 'contains(tony)': False, 'contains(wise)': False, 'contains(taylor)': False, 'contains(impression)': False, 'contains(loving)': False, 'contains(young)': False, 'contains(more)': False, 'contains(first)': False, 'contains(follow)': False, 'contains(vampires)': False, 'contains(winning)': False, 'contains(aren)': False, 'contains(parody)': False, 'contains(recent)': False, 'contains(questions)': False, 'contains(showing)': False, 'contains(film)': False, 'contains(here)': True, 'contains(charles)': False, 'contains(naked)': False, 'contains(matters)': False, 'contains(type)': False, 'contains(necessary)': False, 'contains(above)': False, 'contains(forced)': False, 'contains(top)': True, 'contains(fake)': False, 'contains(price)': False, 'contains(society)': False, 'contains(giving)': False, 'contains(female)': False, 'contains(suppose)': False, 'contains(movie)': True, 'contains(allows)': False, 'contains(seem)': False, 'contains(project)': False, 'contains(lucky)': False, 'contains(point)': False, 'contains(sure)': False, 'contains(exception)': False, 'contains(disappointing)': False, 'contains(characterization)': False, 'contains(during)': False, 'contains(remains)': False, 'contains(before)': False, 'contains(has)': True, 'contains(overall)': False, 'contains(english)': False, 'contains(novel)': False, 'contains(rob)': False, 'contains(any)': False, 'contains(lover)': False, 'contains(south)': False, 'contains(jokes)': False, 'contains(police)': False, 'contains(danny)': False, 'contains(excuse)': False, 'contains(fox)': False, 'contains(boyfriend)': False, 'contains(managed)': False, 'contains(brought)': False, 'contains(taste)': False, 'contains(joe)': False, 'contains(all)': True, 'contains(aspect)': False, 'contains(their)': False, 'contains(example)': False, 'contains(less)': False, 'contains(death)': False, 'contains(literally)': False, 'contains(including)': False, 'contains(situation)': False, 'contains(played)': True, 'contains(dead)': False, 'contains(rival)': False, 'contains(video)': False, 'contains(inspired)': False, 'contains(emotionally)': False, 'contains(house)': False, 'contains(early)': True, 'contains(helps)': False, 'contains(decision)': False, 'contains(100)': False, 'contains(father)': False, 'contains(\")': True, 'contains(could)': False, 'contains(whose)': False, 'contains(violence)': False, 'contains(teen)': False, 'contains(herself)': False, 'contains(field)': True, 'contains(give)': False, 'contains(accent)': False, 'contains(movies)': True, 'contains(mission)': False, 'contains(reading)': False, 'contains(color)': False, 'contains(keep)': False, 'contains(no)': False, 'contains(sets)': False, 'contains(hand)': False, 'contains(everything)': True, 'contains(voice)': False, 'contains(burton)': False, 'contains(money)': False, 'contains(attitude)': False, 'contains(happening)': False, 'contains(genius)': False, 'contains(came)': False, 'contains(anyone)': False, 'contains(is)': True, 'contains(actress)': False, 'contains(previous)': False, 'contains(scary)': False, 'contains(tom)': False, 'contains(decade)': False, 'contains(it)': True, 'contains(determined)': False, 'contains(girl)': False, 'contains(decided)': False, 'contains(anti)': False, 'contains(building)': False, 'contains(computer)': False, 'contains(interest)': False, 'contains(stay)': False, 'contains(gets)': True, 'contains(everyone)': False, 'contains(ray)': False, 'contains(due)': False, 'contains(aliens)': False, 'contains(filmed)': False, 'contains(must)': False, 'contains(writer)': False, 'contains(princess)': False, 'contains(narrative)': False, 'contains(along)': True, 'contains(later)': False, 'contains(male)': False, 'contains(brief)': True, 'contains(arts)': False, 'contains(best)': True, 'contains(boat)': False, 'contains(adds)': False, 'contains(memorable)': False, 'contains(chase)': True, 'contains(train)': True, 'contains(easily)': False, 'contains(cliches)': False, 'contains(cash)': False, 'contains(america)': False, 'contains(relationships)': False, 'contains(mel)': False, 'contains(simon)': False, 'contains(generally)': False, 'contains(whatever)': False, 'contains(about)': True, 'contains(released)': False, 'contains(dvd)': False, 'contains(down)': False, 'contains(usual)': False, 'contains(rock)': False, 'contains(likes)': False, 'contains(five)': False, 'contains(phantom)': False, 'contains(asks)': False, 'contains(magic)': False, 'contains(absolutely)': False, 'contains(onto)': False, 'contains(alive)': False, 'contains(instance)': False, 'contains(highly)': False, 'contains(men)': False, 'contains(10)': False, 'contains(words)': False, 'contains(finally)': False, 'contains(impossible)': False, 'contains(right)': False, 'contains(pg)': False, 'contains(jay)': False, 'contains(&)': False, 'contains(important)': False, 'contains(charming)': False, 'contains(constantly)': False, 'contains(blood)': False, 'contains(makes)': False, 'contains(leave)': False, 'contains(+)': False, 'contains(remarkable)': False, 'contains(greatest)': False, 'contains(sandler)': False, 'contains(solid)': False, 'contains(13)': False, 'contains(cover)': False, 'contains(comic)': False, 'contains(20)': False, 'contains(silent)': False, 'contains(superb)': False, 'contains(forever)': False, 'contains(results)': False, 'contains(lawyer)': False, 'contains(surprisingly)': False, 'contains(appears)': False, 'contains(new)': False, 'contains(fame)': False, 'contains(learn)': False, 'contains(stone)': False, 'contains(action)': True, 'contains(appear)': False, 'contains(explain)': False, 'contains(innocent)': False, 'contains(hurt)': False, 'contains(soundtrack)': False, 'contains(acted)': False, 'contains(waste)': False, 'contains(blame)': False, 'contains(happen)': False, 'contains(pointless)': False, 'contains(seemingly)': False, 'contains(unfunny)': False, 'contains(place)': True, 'contains(viewer)': False, 'contains(spend)': False, 'contains(virtually)': False, 'contains(decides)': False, 'contains(in)': True, 'contains(have)': True, 'contains(animation)': False, 'contains(difficult)': True, 'contains(our)': False, 'contains(easy)': False, 'contains(shakespeare)': False, 'contains(some)': False, 'contains(control)': False, 'contains(writers)': False, 'contains(guys)': False, 'contains(adaptation)': False, 'contains(song)': False, 'contains(victim)': False, 'contains(stunning)': False, 'contains(fear)': False, 'contains(child)': False, 'contains(dramatic)': False, 'contains(see)': False, 'contains(looks)': True, 'contains(major)': False, 'contains(porn)': False, 'contains(buddy)': False, 'contains(heaven)': False, 'contains(2)': False, 'contains(virus)': False, 'contains(wouldn)': False, 'contains(way)': True, 'contains(claire)': False, 'contains(character)': False, 'contains(eye)': False, 'contains(stuff)': False, 'contains(bizarre)': False, 'contains(actual)': False, 'contains(failure)': False, 'contains(within)': False, 'contains(line)': False, 'contains(de)': False, 'contains(knew)': False, 'contains(away)': False, 'contains(possibly)': False, 'contains(snake)': False, 'contains(itself)': False, 'contains(old)': False, 'contains(add)': False, 'contains(coming)': False, 'contains(jackson)': False, 'contains(amazing)': False, 'contains(hits)': False, 'contains(appealing)': False, 'contains(kept)': False, 'contains(wasn)': False, 'contains(matter)': False, 'contains(romance)': False, 'contains(names)': False, 'contains(direct)': False, 'contains(job)': False, 'contains(version)': False, 'contains(lord)': False, 'contains(ghost)': False, 'contains(cameo)': False, 'contains(cause)': False, 'contains(aside)': False, 'contains(confusing)': False, 'contains(security)': True, 'contains(wants)': False, 'contains(speech)': False, 'contains(needed)': False, 'contains(will)': True, 'contains(leaves)': False, 'contains(fi)': False, 'contains(slightly)': False, 'contains(street)': False, 'contains(trek)': False, 'contains(read)': False, 'contains(group)': False, 'contains(energy)': False, 'contains(visually)': False, 'contains(sent)': False, 'contains(documentary)': False, 'contains(doubt)': False, 'contains(problem)': False, 'contains(beach)': False, 'contains(living)': False, 'contains(able)': False, 'contains(walk)': False, 'contains(meets)': False, 'contains(secret)': False, 'contains(class)': False, 'contains(ms)': False, 'contains(sequences)': False, 'contains(using)': False, 'contains(know)': False, 'contains(learns)': False, 'contains(jackie)': True, 'contains(presents)': False, 'contains(bland)': False, 'contains(always)': False, 'contains(dull)': False, 'contains(none)': False, 'contains(strong)': False, 'contains(reveal)': False, 'contains(depth)': False, 'contains(position)': False, 'contains(paced)': False, 'contains(material)': False, 'contains(plain)': False, 'contains(post)': False, 'contains(rent)': False, 'contains(girls)': False, 'contains(however)': True, 'contains(willis)': False, 'contains(decent)': False, 'contains(mess)': False, 'contains(crap)': False, 'contains(near)': False, 'contains(surprise)': False, 'contains(york)': False, 'contains(becoming)': False, 'contains(rich)': False, 'contains(huge)': False, 'contains(strength)': False, 'contains(frightening)': False, 'contains(prove)': False, 'contains(pretty)': False, 'contains(hollywood)': False, 'contains(list)': False, 'contains(was)': False, 'contains(face)': False, 'contains(d)': False, 'contains(the)': True, 'contains(too)': False, 'contains(wedding)': False, 'contains(gangster)': True, 'contains(feelings)': False, 'contains(done)': False, 'contains(suspect)': False, 'contains(you)': True, 'contains(amount)': False, 'contains(series)': True, 'contains(ford)': False, 'contains(former)': False, 'contains(affair)': False, 'contains(horrible)': False, 'contains(turning)': False, 'contains(fun)': True, 'contains(content)': False, 'contains(cartoon)': False, 'contains(biggest)': False, 'contains(apart)': False, 'contains(manages)': False, 'contains(given)': False, 'contains(company)': False, 'contains(own)': True, 'contains(allow)': False, 'contains(?)': False, 'contains(offer)': False, 'contains(word)': False, 'contains(pick)': False, 'contains(disturbing)': False, 'contains(legend)': False, 'contains(successful)': False, 'contains(world)': True, 'contains(adult)': False, 'contains(since)': False, 'contains(costumes)': False, 'contains(speaking)': False, 'contains(feet)': False, 'contains(need)': False, 'contains(gibson)': False, 'contains(effects)': False, 'contains(contrived)': False, 'contains(man)': False, 'contains(trailer)': False, 'contains(husband)': False, 'contains(cameron)': False, 'contains(plays)': False, 'contains(gave)': False, 'contains(west)': False, 'contains(prison)': False, 'contains(ask)': False, 'contains(themselves)': False, 'contains(routine)': False, 'contains(spends)': False, 'contains(queen)': False, 'contains(talents)': False, 'contains(surprises)': False, 'contains(didn)': False, 'contains(himself)': False, 'contains(caught)': False, 'contains(lee)': False, 'contains(henry)': False, 'contains(particularly)': False, 'contains(funniest)': False, 'contains(let)': False, 'contains(etc)': False, 'contains(reality)': False, 'contains(merely)': False, 'contains(island)': False, 'contains(figures)': False, 'contains(late)': False, 'contains(ending)': False, 'contains(past)': False, 'contains(climax)': True, 'contains(joke)': False, 'contains(standing)': True, 'contains(up)': False, 'contains(takes)': False, 'contains(jean)': False, 'contains(ultimately)': False, 'contains(mark)': False, 'contains(l)': False, 'contains(crime)': False, 'contains(beginning)': False, 'contains(hard)': False, 'contains(elizabeth)': False, 'contains(named)': False, 'contains(completely)': False, 'contains(totally)': False, 'contains(strange)': False, 'contains(obviously)': False, 'contains(kill)': False, 'contains(ben)': False, 'contains(difference)': False, 'contains(because)': False, 'contains(epic)': False, 'contains(ice)': False, 'contains(second)': False, 'contains(ed)': False, 'contains(rescue)': False, 'contains(detail)': False, 'contains(outstanding)': False, 'contains(stop)': True, 'contains(enjoyable)': True, 'contains(while)': True, 'contains(worked)': False, 'contains(six)': False, 'contains(black)': False, 'contains(store)': False, 'contains(someone)': False, 'contains(enjoyed)': False, 'contains(story)': False, 'contains(provide)': False, 'contains(community)': False, 'contains(opening)': False, 'contains(situations)': False, 'contains(drive)': False, 'contains(sci)': False, 'contains(actions)': False, 'contains(build)': False, 'contains(member)': False, 'contains(water)': False, 'contains(officer)': False, 'contains(supporting)': False, 'contains(allen)': False, 'contains(few)': False, 'contains(task)': False, 'contains(tired)': False, 'contains(pass)': False, 'contains(rate)': False, 'contains(work)': False, 'contains(brilliant)': False, 'contains(serve)': False, 'contains(turn)': False, 'contains(play)': False, 'contains(lack)': False, 'contains(slapstick)': False, 'contains(self)': False, 'contains(cute)': False, 'contains(might)': False, 'contains(killer)': False, 'contains(loses)': False, 'contains(doctor)': False, 'contains(across)': False, 'contains(films)': False, 'contains(beat)': False, 'contains(mentioned)': False, 'contains(returns)': False, 'contains(cinema)': False, 'contains(driving)': False, 'contains(pain)': False, 'contains(anything)': False, 'contains(like)': True, 'contains(places)': False, 'contains(care)': False, 'contains(each)': True, 'contains(mary)': False, 'contains(dog)': False, 'contains(carter)': False, 'contains(rush)': False, 'contains(changed)': False, 'contains(michael)': False, 'contains(well)': True, 'contains(kong)': True, 'contains(utterly)': False, 'contains(planet)': False, 'contains(quality)': False, 'contains(believes)': False, 'contains(those)': False, 'contains(spielberg)': False, 'contains(filmmaker)': False, 'contains(except)': False, 'contains(lines)': False, 'contains(8)': False, 'contains(again)': False, 'contains(oh)': False, 'contains(manage)': False, 'contains(last)': False, 'contains(most)': True, 'contains(around)': False, 'contains(count)': False, 'contains(protagonist)': False, 'contains(portrayed)': False, 'contains(leads)': False, 'contains(send)': False, 'contains(until)': False, 'contains(arnold)': True, 'contains(placed)': False, 'contains(rating)': False, 'contains(shows)': False, 'contains(m)': False, 'contains(god)': False, 'contains(hear)': False, 'contains(eyes)': False, 'contains(details)': False, 'contains(court)': False, 'contains(president)': False, 'contains(forgotten)': False, 'contains(general)': False, 'contains(plane)': False, 'contains(box)': False, 'contains(concept)': False, 'contains(guess)': False, 'contains(dimensional)': False, 'contains(at)': False, 'contains(middle)': False, 'contains(shame)': False, 'contains(run)': False, 'contains(set)': False, 'contains(gore)': False, 'contains(watching)': False, 'contains(yes)': False, 'contains(charlie)': False, 'contains(chosen)': False, 'contains(contact)': False, 'contains(nights)': False, 'contains(pieces)': False, 'contains(write)': False, 'contains(characters)': False, 'contains(else)': False, 'contains(dude)': False, 'contains(moral)': False, 'contains(portrayal)': False, 'contains(jr)': False, 'contains(wish)': False, 'contains(deal)': False, 'contains(substance)': False, 'contains(or)': False, 'contains(hunt)': False, 'contains(scene)': True, 'contains(although)': False, 'contains(martin)': False, 'contains(surprising)': False, 'contains(introduced)': False, 'contains(unlike)': False, 'contains(non)': True, 'contains(fighting)': False, 'contains(come)': False, 'contains(american)': False, 'contains(bus)': False, 'contains(background)': False, 'contains(trying)': False, 'contains(yourself)': False, 'contains(director)': False, 'contains(sea)': False, 'contains(vegas)': False, 'contains(robin)': False, 'contains(crystal)': False, 'contains(car)': False, 'contains(sadly)': False, 'contains(note)': False, 'contains(discovers)': False, 'contains(suspense)': False, 'contains(editing)': False, 'contains(strike)': False, 'contains(couldn)': False, 'contains(gang)': False, 'contains(if)': True, 'contains(attack)': False, 'contains(opinion)': False, 'contains(share)': False, 'contains(getting)': True, 'contains(realized)': False, 'contains(different)': False, 'contains(question)': False, 'contains(kate)': False, 'contains(whether)': False, 'contains(reason)': False, 'contains(her)': False, 'contains(comedy)': True, 'contains(miss)': True, 'contains(deserves)': False, 'contains(available)': False, 'contains(effort)': False, 'contains(immediately)': False, 'contains(:)': True, 'contains(uses)': False, 'contains(can)': False, 'contains(powerful)': False, 'contains(guard)': True, 'contains(sick)': False, 'contains(added)': False, 'contains(blue)': False, 'contains(nature)': False, 'contains(toy)': False, 'contains(guy)': True, 'contains(apartment)': False, 'contains(hall)': False, 'contains(wife)': True, 'contains(picture)': False, 'contains(room)': False, 'contains(urban)': False, 'contains(casting)': False, 'contains(party)': False, 'contains(directors)': False, 'contains(credits)': False, 'contains(cinematographer)': False, 'contains(images)': False, 'contains(badly)': False, 'contains(respect)': False, 'contains(mike)': False, 'contains(storyline)': False, 'contains(love)': False, 'contains(performances)': False, 'contains(entirely)': False, 'contains(appropriate)': False, 'contains(war)': False, 'contains(actually)': True, 'contains(seagal)': False, 'contains(woods)': False, 'contains(budget)': False, 'contains(truman)': False, 'contains(mulan)': False, 'contains(real)': False, 'contains(quiet)': False, 'contains(dennis)': False, 'contains(product)': False, 'contains(pictures)': False, 'contains(his)': True, 'contains(started)': False, 'contains(small)': False, 'contains(under)': False, 'contains(slasher)': False, 'contains(effective)': False, 'contains(working)': False, 'contains(heard)': False, 'contains(central)': False, 'contains(spice)': False, 'contains(6)': False, 'contains(phone)': False, 'contains(i)': False, 'contains(girlfriend)': True, 'contains(serious)': False, 'contains(visual)': False, 'contains(bright)': False, 'contains(vampire)': False, 'contains(blade)': False, 'contains(helen)': False, 'contains(hong)': True, 'contains(short)': False, 'contains(produced)': False, 'contains(ability)': False, 'contains(actors)': False, 'contains(brown)': False, 'contains(heads)': False, 'contains(drugs)': False, 'contains(big)': False, 'contains(9)': False, 'contains(julie)': False, 'contains(books)': False, 'contains(why)': False, 'contains(liners)': False, 'contains(moves)': False, 'contains(never)': True, 'contains(became)': False, 'contains(rising)': False, 'contains(hidden)': False, 'contains(wrong)': True, 'contains(feature)': False, 'contains(total)': False, 'contains(things)': True, 'contains(saying)': False, 'contains(design)': False, 'contains(batman)': False, 'contains(perhaps)': False, 'contains(its)': False, 'contains(loves)': False, 'contains(act)': False, 'contains(unique)': True, 'contains(haunting)': False, 'contains(wit)': False, 'contains(mind)': False, 'contains(suddenly)': False, 'contains(machine)': False, 'contains(seven)': False, 'contains(complex)': False, 'contains(hope)': False, 'contains(imagine)': False, 'contains(army)': False, 'contains(accept)': False, 'contains(cage)': False, 'contains(creating)': False, 'contains(bloody)': False, 'contains(thin)': False, 'contains(recommend)': False, 'contains(directly)': False, 'contains(fault)': False, 'contains(kiss)': False, 'contains(others)': True, 'contains(harry)': False, 'contains(lots)': False, 'contains(lose)': False, 'contains(interesting)': False, 'contains(head)': False, 'contains(impact)': False, 'contains(david)': False, 'contains(damn)': False, 'contains(political)': False, 'contains(continues)': False, 'contains(r)': False, 'contains(private)': False, 'contains(times)': False, 'contains(check)': False, 'contains(julia)': False, 'contains(professional)': False, 'contains(comes)': False, 'contains(normal)': False, 'contains(between)': True, 'contains(academy)': False, 'contains(flaws)': False, 'contains(support)': False, 'contains(twenty)': False, 'contains(sees)': True, 'contains(j)': False, 'contains(considering)': False, 'contains(scale)': False, 'contains(becomes)': False, 'contains(touching)': False, 'contains(special)': False, 'contains(b)': False, 'contains(only)': True, 'contains(nuclear)': False, 'contains(daughter)': False, 'contains(red)': False, 'contains(angels)': False, 'contains(role)': False, 'contains(football)': False, 'contains(spent)': False, 'contains(century)': False, 'contains(artist)': False, 'contains(your)': False, 'contains(say)': False, 'contains(footage)': False, 'contains(jennifer)': False, 'contains(thankfully)': False, 'contains(chan)': True, 'contains(even)': False, 'contains(hanks)': False, 'contains(wonder)': False, 'contains(nowhere)': False, 'contains(pull)': False, 'contains(pop)': False, 'contains(reeves)': False, 'contains(club)': False, 'contains(finale)': False, 'contains(okay)': False, 'contains(intelligence)': False, 'contains(time)': False, 'contains(brain)': False, 'contains(mostly)': False, 'contains(are)': True, 'contains(washington)': False, 'contains(captain)': False, 'contains(involving)': False, 'contains(sad)': False, 'contains(keeps)': True, 'contains(basic)': False, 'contains(satire)': False, 'contains(missing)': False, 'contains(almost)': False, 'contains(public)': False, 'contains(my)': False, 'contains(accident)': False, 'contains(humor)': False, 'contains(sex)': False, 'contains(directed)': False, 'contains(johnny)': False, 'contains(paul)': False, 'contains(scream)': True, 'contains(creates)': False, 'contains(carrey)': False, 'contains(shouldn)': False, 'contains(hunting)': False, 'contains(producers)': False, 'contains(lynch)': False, 'contains(on)': True, 'contains(responsible)': False, 'contains(dream)': False, 'contains(there)': True, 'contains(studio)': False, 'contains(little)': True, 'contains(sexual)': False, 'contains(fascinating)': False, 'contains(better)': False, 'contains(roles)': False, 'contains(dying)': False, 'contains(over)': False, 'contains(ten)': False, 'contains(college)': False, 'contains(1996)': False, 'contains(journey)': False, 'contains(true)': False, 'contains(crew)': False, 'contains(douglas)': False, 'contains(fat)': False, 'contains(stands)': False, 'contains(thinking)': False, 'contains(exist)': False, 'contains(horse)': False, 'contains(local)': False, 'contains(7)': False, 'contains(brooks)': False, 'contains(air)': False, 'contains(broken)': False, 'contains(leader)': False, 'contains(damon)': False, 'contains(thomas)': False, 'contains(long)': False, 'contains(cheap)': False, 'contains(fully)': False, 'contains(edge)': False, 'contains(next)': False, 'contains(friend)': False, 'contains(failed)': False, 'contains(!)': True, 'contains(fbi)': False, 'contains(grows)': False, 'contains(similar)': False, 'contains(considered)': False, 'contains(smart)': False, 'contains(detective)': False, 'contains(end)': False, 'contains(clearly)': False, 'contains(thinks)': False, 'contains(taken)': False, 'contains(wild)': False, 'contains(ride)': False, 'contains(spawn)': False, 'contains(dealing)': False, 'contains(dreams)': False, 'contains(engaging)': False, 'contains(delivers)': False, 'contains(singer)': False, 'contains(campbell)': False, 'contains(student)': False, 'contains(natural)': False, 'contains(struggle)': False, 'contains(style)': False, 'contains(opposite)': False, 'contains(calls)': False, 'contains(slow)': True, 'contains(g)': False, 'contains(tv)': False, 'contains(band)': False, 'contains(left)': False, 'contains(bond)': False, 'contains(chance)': False, 'contains(mother)': False, 'contains(chemistry)': True, 'contains(minor)': False, 'contains(win)': False, 'contains(crazy)': False, 'contains(animated)': False, 'contains(award)': False, 'contains(talk)': True, 'contains(television)': False, 'contains(from)': True, 'contains(other)': True, 'contains(menace)': False, 'contains(ended)': False, 'contains(human)': False, 'contains(ryan)': False, 'contains(sympathetic)': False, 'contains(level)': False, 'contains(moore)': False, 'contains(giant)': False, 'contains(visuals)': False, 'contains(gags)': False, 'contains(grand)': False, 'contains(hey)': False, 'contains(nick)': False, 'contains(compelling)': False, 'contains(realizes)': False, 'contains(williamson)': False, 'contains(going)': False, 'contains(s)': True, 'contains(fantastic)': False, 'contains(saving)': False, 'contains(such)': False, 'contains(subject)': False, 'contains(put)': False, 'contains(compared)': False, 'contains(larry)': False, 'contains(guns)': False, 'contains(fit)': False, 'contains(made)': False, 'contains(excellent)': False, 'contains(goal)': False, 'contains(john)': False, 'contains(joan)': False, 'contains(aspects)': False, 'contains(superior)': False, 'contains(potential)': False, 'contains(certain)': False, 'contains(race)': False, 'contains(parts)': False, 'contains(humans)': False, 'contains(lies)': False, 'contains(jane)': False, 'contains(streets)': False, 'contains(another)': False, 'contains(intriguing)': False, 'contains(seconds)': False, 'contains(loud)': False, 'contains(enough)': False, 'contains(sequel)': False, 'contains(mad)': False, 'contains(desperate)': False, 'contains(christmas)': False, 'contains(5)': False, 'contains(week)': False, 'contains(ll)': False, 'contains(person)': False, 'contains(current)': False, 'contains(woman)': True, 'contains(thought)': False, 'contains(review)': False, 'contains(seat)': False, 'contains(said)': False, 'contains(saw)': False, 'contains(masterpiece)': False, 'contains(meet)': False, 'contains(definitely)': False, 'contains(figure)': False, 'contains(against)': False, 'contains(tension)': False, 'contains(soldiers)': False, 'contains(minutes)': False, 'contains(succeeds)': False, 'contains(super)': False, 'contains(avoid)': False, 'contains(plot)': True, 'contains(bring)': False, 'contains(funny)': True, 'contains(think)': False, 'contains(still)': False, 'contains(terrific)': False, 'contains(without)': False, 'contains(suspects)': False, 'contains(identity)': False, 'contains(clear)': False, 'contains(industry)': False, 'contains(element)': False, 'contains(talent)': False, 'contains(comparison)': False, 'contains(won)': False, 'contains(comedies)': False, 'contains(terms)': False, 'contains(team)': False, 'contains(double)': False, 'contains(mob)': False, 'contains(survive)': False, 'contains(created)': False, 'contains(road)': False, 'contains(stuart)': False, 'contains(press)': False, 'contains(now)': False, 'contains(don)': False, 'contains(graphic)': False, 'contains(younger)': False, 'contains(try)': False, 'contains(certainly)': False, 'contains(twice)': False, 'contains(either)': False, 'contains(core)': False, 'contains(goofy)': False, 'contains(provided)': False, 'contains(boss)': True, 'contains(somewhat)': False, 'contains(mysterious)': False, 'contains(flying)': False, 'contains(entertainment)': False, 'contains(nice)': False, 'contains(waiting)': False, 'contains(drug)': True, 'contains(animals)': False, 'contains(parents)': False, 'contains(whole)': False, 'contains(mediocre)': False, 'contains(stupid)': False, 'contains(kids)': False, 'contains(breaks)': False, 'contains(laugh)': True, 'contains(shown)': False, 'contains(viewing)': False, 'contains(also)': True, 'contains(beyond)': False, 'contains(night)': False, 'contains(title)': False, 'contains(join)': False, 'contains(indeed)': False, 'contains(scorsese)': False, 'contains(who)': True, 'contains(am)': False, 'contains(zero)': False, 'contains(nicely)': False, 'contains(unfortunately)': False, 'contains(critics)': False, 'contains(one)': True, 'contains(anthony)': False, 'contains(finds)': False, 'contains(catch)': False, 'contains(inside)': False, 'contains(scenes)': False, 'contains(discover)': False, 'contains(upon)': False, 'contains(three)': False, 'contains(them)': True, 'contains(skills)': False, 'contains(full)': False, 'contains(joel)': False, 'contains(singing)': False, 'contains(through)': False, 'contains(ultimate)': False, 'contains(presented)': False, 'contains(welcome)': False, 'contains(clever)': False, 'contains(heart)': False, 'contains(ve)': False, 'contains(happened)': False, 'contains(eventually)': False, 'contains(career)': False, 'contains(often)': True, 'contains(()': True, 'contains(having)': False, 'contains(meeting)': False, 'contains(kind)': True, 'contains(attempts)': False, 'contains(name)': False, 'contains(3)': False, 'contains(throughout)': False, 'contains(t)': False, 'contains(reasons)': False, 'contains(truth)': False, 'contains(austin)': False, 'contains(despite)': False, 'contains(ridiculous)': False, 'contains(williams)': False, 'contains(show)': False, 'contains(yet)': False, 'contains(average)': False, 'contains(killing)': False, 'contains(murder)': False, 'contains(especially)': True, 'contains(so)': False, 'contains(together)': False, 'contains(ass)': True, 'contains(originally)': False, 'contains(works)': False, 'contains(cool)': False, 'contains(chris)': False, 'contains(features)': True, 'contains(how)': True, 'contains(cannot)': False, 'contains(may)': False, 'contains(wide)': False, 'contains(fine)': False, 'contains())': True, 'contains(taking)': False, 'contains(kevin)': True, 'contains(debut)': False, 'contains(george)': False, 'contains(forget)': False, 'contains(nor)': False, 'contains(shooting)': False, 'contains(godzilla)': False, 'contains(premise)': False, 'contains(smith)': False, 'contains(disaster)': False, 'contains(playing)': True, 'contains(school)': False, 'contains(lead)': True, 'contains(manner)': False, 'contains(gold)': False, 'contains(supposedly)': False, 'contains(pleasure)': False, 'contains(weird)': False, 'contains(master)': False, 'contains(deep)': True, 'contains(lacking)': False, 'contains(food)': True, 'contains(among)': True, 'contains(nothing)': False, 'contains(wayne)': False, 'contains(french)': False, 'contains(alan)': False, 'contains(spirit)': False, 'contains(acts)': False, 'contains(involved)': False, 'contains(tough)': False, 'contains(that)': True, 'contains(make)': True, 'contains(plenty)': False, 'contains(o)': False, 'contains(meant)': False, 'contains(ever)': True, 'contains(relief)': False, 'contains(live)': False, 'contains(poorly)': False, 'contains(keeping)': False, 'contains(this)': True, 'contains(back)': False, 'contains(shock)': False, 'contains(odd)': False, 'contains(ups)': False, 'contains(good)': False, 'contains(cruise)': False, 'contains(jedi)': False, 'contains(offers)': False, 'contains(sister)': False, 'contains(beast)': False, 'contains(moment)': False, 'contains(boys)': False, 'contains(bottom)': False, 'contains(isn)': False, 'contains(battle)': False, 'contains(driven)': False, 'contains(people)': False, 'contains(rules)': False, 'contains(deliver)': False, 'contains(mystery)': False, 'contains(viewers)': False, 'contains(safe)': False, 'contains(lets)': False, 'contains(device)': False, 'contains(likely)': False, 'contains(fall)': False, 'contains(town)': False, 'contains(tommy)': False, 'contains(catherine)': False, 'contains(would)': False, 'contains(life)': False, 'contains(focus)': False, 'contains(center)': False, 'contains(fair)': False, 'contains(nasty)': False, 'contains(weren)': False, 'contains(pair)': False, 'contains(f)': False, 'contains(used)': True, 'contains(wondering)': True, 'contains(common)': False, 'contains(villain)': False, 'contains(humorous)': False, 'contains(born)': False, 'contains(please)': False, 'contains(single)': False, 'contains(news)': False, 'contains(believable)': False, 'contains(dumb)': False, 'contains(entire)': False, 'contains(includes)': False, 'contains(length)': False, 'contains(sam)': False, 'contains(blair)': False, 'contains(exactly)': False, 'contains(return)': False, 'contains(message)': False, 'contains(nearly)': False, 'contains(plans)': False, 'contains(turned)': False, 'contains(hoping)': False, 'contains(000)': False, 'contains(brian)': False, 'contains(twists)': False, 'contains(they)': True, 'contains(being)': False, 'contains(be)': True, 'contains(baby)': False, 'contains(emotion)': False, 'contains(anyway)': False, 'contains(incredibly)': False, 'contains(boring)': False, 'contains(realize)': False, 'contains(serial)': False, 'contains(ok)': False, 'contains(likable)': False, 'contains(original)': False, 'contains(worse)': False, 'contains(guilty)': False, 'contains(enjoy)': False, 'contains(star)': False, 'contains(provides)': False, 'contains(angry)': False, 'contains(amusing)': False, 'contains(with)': True, 'contains(something)': False, 'contains(james)': False, 'contains(realistic)': False, 'contains(family)': False, 'contains(alex)': False, 'contains(poor)': False, 'contains(result)': False, 'contains(honest)': False, 'contains(disney)': False, 'contains(married)': False, 'contains(baldwin)': False, 'contains(view)': False, 'contains(silly)': False, 'contains(starts)': False, 'contains(nudity)': False, 'contains(couple)': False, 'contains(speak)': False, 'contains(re)': True, 'contains(neither)': False, 'contains(forward)': False, 'contains(spectacular)': False, 'contains(barely)': False, 'contains(worst)': False, 'contains(whom)': False, 'contains(city)': False, 'contains(falling)': False, 'contains(create)': False, 'contains(changes)': False, 'contains(million)': True, 'contains(home)': False, 'contains(personality)': False, 'contains(we)': False, 'contains(piece)': False, 'contains(watch)': True, 'contains(office)': False, 'contains(die)': False, 'contains(just)': True, 'contains(somewhere)': False, 'contains(japanese)': False, 'contains(died)': False, 'contains(physical)': True, 'contains(large)': False, 'contains(ship)': False, 'contains(co)': False, 'contains(slowly)': False, 'contains(tone)': False, 'contains(alone)': False, 'contains(wall)': False, 'contains(issues)': False, 'contains(children)': False, 'contains(answer)': False, 'contains(teacher)': False, 'contains(humour)': False, 'contains(troopers)': False, 'contains(include)': False, 'contains(supposed)': False, 'contains(jones)': False, 'contains(flat)': False, 'contains(involves)': True, 'contains(technology)': False, 'contains(emotions)': False, 'contains(sometimes)': False, 'contains(believe)': False, 'contains(adams)': False, 'contains(teenage)': False, 'contains(present)': False, 'contains(romantic)': False, 'contains(])': False, 'contains(faith)': False, 'contains(hopes)': False, 'contains(christopher)': False, 'contains(plan)': False, 'contains(great)': True, 'contains(william)': False, 'contains(hill)': False, 'contains(filmmaking)': False, 'contains(criminal)': False, 'contains(yeah)': False, 'contains(wanted)': False, 'contains(of)': True, 'contains(sub)': False, 'contains(acting)': False, 'contains(start)': True, 'contains(gary)': False, 'contains(fire)': False, 'contains(latter)': False, 'contains(points)': False, 'contains(understand)': False, 'contains(season)': False, 'contains(watched)': False, 'contains(oscar)': False, 'contains(were)': False, 'contains(cult)': False, 'contains(appeal)': False, 'contains(began)': False, 'contains(shots)': False, 'contains(somehow)': False, 'contains(cops)': False, 'contains(thoroughly)': False, 'contains(desire)': False, 'contains(bar)': False, 'contains(further)': False, 'contains(player)': False, 'contains(quick)': True, 'contains(law)': False, 'contains(as)': True, 'contains(stars)': False, 'contains(move)': False, 'contains(where)': True, 'contains(woody)': False, 'contains(occasionally)': False, 'contains(ready)': False, 'contains(carpenter)': False, 'contains(space)': False, 'contains(power)': False, 'contains(lacks)': False, 'contains(after)': False, 'contains(eight)': True, 'contains(pace)': False, 'contains(producer)': False, 'contains(model)': False, 'contains(language)': False, 'contains(sort)': False, 'contains(open)': False, 'contains(problems)': True, 'contains(filmmakers)': False, 'contains(damme)': False, 'contains(business)': False, 'contains(gay)': False, 'contains(lame)': False, 'contains(stock)': False, 'contains(matrix)': False, 'contains(son)': False, 'contains(folks)': False, 'contains(frank)': False, 'contains(wonderful)': False, 'contains(music)': False, 'contains(use)': False, 'contains(carry)': False, 'contains(event)': False, 'contains(military)': False, 'contains(sound)': False, 'contains(files)': False, 'contains(fly)': False, 'contains(to)': True, 'contains(surprised)': False, 'contains(maybe)': False, 'contains(date)': False, 'contains(pulp)': False, 'contains(travel)': False, 'contains(not)': True, 'contains(floor)': False, 'contains(cold)': False, 'contains(hold)': False, 'contains(sweet)': False, 'contains(usually)': False, 'contains(leaving)': False, 'contains(gun)': True, 'contains(flick)': False, 'contains(charm)': False, 'contains(touch)': False, 'contains(thrown)': False, 'contains(tale)': False, 'contains(/)': False, 'contains(musical)': False, 'contains(throw)': False, 'contains(hasn)': False, 'contains(expect)': False, 'contains(united)': False, 'contains(bunch)': False, 'contains(trouble)': True, 'contains(murphy)': False, 'contains([)': False, 'contains(age)': False, 'contains(game)': False, 'contains(led)': False, 'contains(main)': False, 'contains(la)': False, 'contains(brings)': False, 'contains(creative)': False, 'contains(science)': False, 'contains(simple)': False, 'contains(stand)': False, 'contains(--)': True, 'contains(themes)': False, 'contains(tarantino)': False, 'contains(making)': True, 'contains(history)': False, 'contains(favorite)': False, 'contains(pay)': False, 'contains(twist)': False, 'contains(steve)': False, 'contains(smile)': False, 'contains(wonderfully)': False, 'contains(feels)': False, 'contains(annoying)': False, 'contains(edward)': False, 'contains(bored)': False, 'contains(year)': False, 'contains(drama)': False, 'contains(addition)': False, 'contains(help)': True, 'contains(several)': False, 'contains(eccentric)': False, 'contains(monster)': False, 'contains(equally)': False, 'contains(wasted)': False, 'contains(therefore)': False, 'contains(rocky)': False, 'contains(summer)': False, 'contains(confused)': False, 'contains(day)': True, 'contains(fight)': True, 'contains(stephen)': False, 'contains(test)': False, 'contains(based)': False, 'contains(liked)': False, 'contains(days)': False, 'contains(hopkins)': False, 'contains(roger)': False, 'contains(sarah)': False, 'contains(bob)': False, 'contains(witch)': False, 'contains(impressive)': False, 'contains(older)': False, 'contains(mean)': False, 'contains(affleck)': False, 'contains(radio)': False, 'contains(attempt)': False, 'contains(modern)': False, 'contains(track)': False, 'contains(asked)': False, 'contains(out)': True, 'contains(offensive)': False, 'contains(happens)': False, 'contains(cinematic)': False, 'contains(tim)': False, 'contains(worthy)': False, 'contains(interested)': False, 'contains(ugly)': False, 'contains(cut)': False, 'contains(development)': False, 'contains(stuck)': False, 'contains(agent)': False, 'contains(stories)': False, 'contains(sean)': False, 'contains(heroes)': False, 'contains(for)': True, 'contains(step)': False, 'contains(towards)': False, 'contains(wars)': False, 'contains(martial)': False, 'contains(green)': False, 'contains(begins)': False, 'contains(brothers)': False, 'contains(cheesy)': False, 'contains(appreciate)': False, 'contains(heavy)': False, 'contains(looked)': False, 'contains(force)': False, 'contains(him)': True, 'contains(pathetic)': False, 'contains(bringing)': False, 'contains(filled)': False, 'contains(puts)': False, 'contains(every)': False, 'contains(four)': False, 'contains(image)': False, 'contains(generation)': False, 'contains(follows)': False, 'contains(perfectly)': False, 'contains(flicks)': False, 'contains(soul)': False, 'contains(promise)': False, 'contains(board)': False, 'contains(body)': False, 'contains(mrs)': False, 'contains(ends)': False, 'contains(relationship)': False, 'contains(truly)': False, 'contains(patch)': False, 'contains(limited)': False, 'contains(proves)': False, 'contains(camp)': False, 'contains(attention)': False, 'contains(conflict)': False, 'contains(been)': False, 'contains(state)': False, 'contains(change)': False, 'contains(system)': False, 'contains(apparently)': False, 'contains(terrible)': False, 'contains(release)': False, 'contains(bit)': False, 'contains(comedic)': False, 'contains(hands)': False, 'contains(worth)': True, 'contains(but)': True, 'contains(meaning)': False, 'contains(means)': True, 'contains(basically)': False, 'contains(notice)': False, 'contains(otherwise)': False, 'contains(flynt)': False, 'contains(theme)': False, 'contains(much)': False, 'contains(lot)': False, 'contains(these)': False, 'contains(minute)': False, 'contains(apes)': False, 'contains(fails)': False, 'contains(evil)': False, 'contains(search)': False, 'contains(sequence)': False, 'contains(find)': False, 'contains(bad)': False, 'contains(got)': True, 'contains(information)': False, 'contains(fairly)': True, 'contains(alien)': False, 'contains(part)': False, 'contains(lucas)': False, 'contains(complete)': False, 'contains(get)': True, 'contains(miller)': False, 'contains(scott)': False, 'contains(intense)': False, 'contains($)': False, 'contains(remake)': False, 'contains(conclusion)': False, 'contains(bruce)': False, 'contains(took)': False, 'contains(order)': False, 'contains(begin)': False, 'contains(generated)': False, 'contains(species)': False, 'contains(many)': True, 'contains(thus)': False, 'contains(states)': False, 'contains(close)': False, 'contains(plus)': False, 'contains(jim)': False, 'contains(written)': False, 'contains(ago)': False, 'contains(apparent)': False, 'contains(fact)': False, 'contains(grace)': False, 'contains(drawn)': False, 'contains(expectations)': False, 'contains(rated)': False, 'contains(holds)': False, 'contains(doing)': False, 'contains(standard)': False, 'contains(kid)': False, 'contains(sight)': False, 'contains(hero)': False, 'contains(ex)': False, 'contains(thriller)': False, 'contains(myself)': False, 'contains(mouth)': False, 'contains(beautiful)': False, 'contains(killed)': False, 'contains(crash)': False, 'contains(hell)': False, 'contains(fashion)': False, 'contains(surface)': False, 'contains(villains)': False, 'contains(songs)': False, 'contains(eddie)': False, 'contains(dr)': False, 'contains(steven)': False, 'contains(behind)': False, 'contains(happy)': False, 'contains(adventure)': False, 'contains(hours)': False, 'contains(off)': False, 'contains(sharp)': False, 'contains(deals)': False, 'contains(course)': True, 'contains(consider)': False, 'contains(cares)': False, 'contains(station)': False, 'contains(lost)': False, 'contains(finding)': False, 'contains(latest)': False, 'contains(screenwriter)': False, 'contains(titanic)': False, 'contains(shoot)': False, 'contains(sit)': False, 'contains(high)': False, 'contains(window)': False, 'contains(goes)': False, 'contains(side)': False, 'contains(adults)': False, 'contains(art)': False, 'contains(members)': False, 'contains(faces)': False, 'contains(classic)': False, 'contains(speed)': False, 'contains(both)': False, 'contains(score)': False, 'contains(ideas)': False, 'contains(fare)': False, 'contains(feel)': False, 'contains(chinese)': True, 'contains(expected)': False, 'contains(found)': False, 'contains(remember)': False, 'contains(unless)': False, 'contains(ground)': False, 'contains(theaters)': False, 'contains(production)': False, 'contains(humanity)': False, 'contains(ones)': False, 'contains(lives)': False, 'contains(seriously)': False, 'contains(numerous)': False, 'contains(purpose)': False, 'contains(outside)': False, 'contains(1997)': False, 'contains(myers)': False, 'contains(jason)': False, 'contains(predictable)': False, 'contains(dangerous)': True, 'contains(told)': False, 'contains(screen)': True, 'contains(incredible)': False, 'contains(rarely)': False, 'contains(directing)': False, 'contains(laughs)': False, 'contains(amy)': False, 'contains(go)': False, 'contains(kills)': False, 'contains(constant)': False, 'contains(months)': False, 'contains(dialogue)': False, 'contains(screenplay)': False, 'contains(fate)': False, 'contains(marriage)': False, 'contains(`)': False, 'contains(dance)': False, 'contains(starship)': False, 'contains(she)': True, 'contains(following)': False, 'contains(then)': True, 'contains(match)': False, 'contains(jerry)': False, 'contains(particular)': False, 'contains(jimmy)': False, 'contains(what)': True, 'contains(friends)': True, 'contains(matthew)': False, 'contains(already)': False, 'contains(case)': False, 'contains(destroy)': False, 'contains(personal)': False, 'contains(process)': False, 'contains(beauty)': False, 'contains(far)': False, 'contains(tell)': False, 'contains(soon)': False, 'contains(famous)': False, 'contains(probably)': False, 'contains(than)': False, 'contains(kelly)': False, 'contains(entertaining)': False, 'contains(stage)': False, 'contains(billy)': False, 'contains(earth)': False, 'contains(least)': True, 'contains(become)': False, 'contains(writing)': False, 'contains(hate)': False, 'contains(fan)': False, 'contains(cross)': False, 'contains(matt)': False, 'contains(sign)': False, 'contains(jack)': False, 'contains(starring)': False, 'contains(toward)': False, 'contains(familiar)': False, 'contains(fiction)': False, 'contains(thanks)': False, 'contains(developed)': False, 'contains(creature)': False, 'contains(period)': False, 'contains(rest)': False, 'contains(dies)': False, 'contains(clich)': False, 'contains(door)': False, 'contains(key)': True, 'contains(boy)': False, 'contains(straight)': False, 'contains(tried)': False, 'contains(doesn)': False, 'contains(partner)': False, 'contains(known)': True, 'contains(e)': False, 'contains(mention)': False, 'contains(hardly)': False, 'contains(longer)': False, 'contains(feeling)': False, 'contains(jeff)': False, 'contains(did)': False, 'contains(decide)': False, 'contains(rather)': False, 'contains(hospital)': False, 'contains(park)': False, 'contains(gone)': False, 'contains(.)': True, 'contains(which)': True, 'contains(quickly)': False, 'contains(perfect)': False, 'contains(imagination)': False, 'contains(moving)': True, 'contains(violent)': False, 'contains(ii)': False, 'contains(do)': True, 'contains(fantasy)': False, 'contains(laughing)': False, 'contains(really)': False, 'contains(anderson)': False, 'contains(*)': True, 'contains(1999)': False, 'contains(british)': False, 'contains(featuring)': False, 'contains(witty)': False, 'contains(seen)': False, 'contains(woo)': False, 'contains(jail)': True, 'contains(4)': False, 'contains(visit)': False, 'contains(popular)': False, 'contains(mood)': False, 'contains(devil)': False, 'contains(approach)': False, 'contains(two)': True, 'contains(students)': False, 'contains(haven)': False, 'contains(sitting)': False, 'contains(into)': True, 'contains(individual)': False, 'contains(culture)': False, 'contains(media)': False, 'contains(expecting)': False, 'contains(us)': True, 'contains(awful)': False, 'contains(telling)': False, 'contains(fellow)': False, 'contains(genuine)': False, 'contains(me)': True, 'contains(walking)': False, 'contains(intended)': False, 'contains(revenge)': False, 'contains(book)': False, 'contains(subplot)': False, 'contains(meanwhile)': False, 'contains(episode)': False, 'contains(opens)': False, 'contains(women)': False, 'contains(an)': True, 'contains(talented)': False, 'contains(sense)': False, 'contains(future)': False, 'contains(years)': False, 'contains(cast)': False, 'contains(weak)': False, 'contains(falls)': False, 'contains(today)': True, 'contains(king)': False, 'contains(does)': False, 'contains(idea)': True, 'contains(30)': False, 'contains(setting)': False, 'contains(babe)': False, 'contains(thing)': False, 'contains(felt)': False, 'contains(dark)': False, 'contains(typical)': False, 'contains(attractive)': True, 'contains(quite)': False}\n"
     ]
    }
   ],
   "source": [
    "print(document_features(movie_reviews.words('pos/cv957_8737.txt'))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
    "train_set, test_set = featuresets[100:], featuresets[:100]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "   contains(outstanding) = True              pos : neg    =     10.4 : 1.0\n",
      "        contains(seagal) = True              neg : pos    =      8.7 : 1.0\n",
      "         contains(mulan) = True              pos : neg    =      8.1 : 1.0\n",
      "   contains(wonderfully) = True              pos : neg    =      6.3 : 1.0\n",
      "         contains(damon) = True              pos : neg    =      5.7 : 1.0\n",
      "          contains(lame) = True              neg : pos    =      5.6 : 1.0\n",
      "        contains(wasted) = True              neg : pos    =      5.6 : 1.0\n",
      "         contains(awful) = True              neg : pos    =      5.4 : 1.0\n",
      "         contains(flynt) = True              pos : neg    =      5.1 : 1.0\n",
      "    contains(ridiculous) = True              neg : pos    =      5.1 : 1.0\n",
      "        contains(poorly) = True              neg : pos    =      4.9 : 1.0\n",
      "         contains(waste) = True              neg : pos    =      4.9 : 1.0\n",
      "          contains(jedi) = True              pos : neg    =      4.8 : 1.0\n",
      "       contains(unfunny) = True              neg : pos    =      4.3 : 1.0\n",
      "         contains(worst) = True              neg : pos    =      4.3 : 1.0\n",
      "         contains(bland) = True              neg : pos    =      4.2 : 1.0\n",
      "        contains(superb) = True              pos : neg    =      4.2 : 1.0\n",
      "           contains(era) = True              pos : neg    =      4.2 : 1.0\n",
      "     contains(fantastic) = True              pos : neg    =      4.1 : 1.0\n",
      "        contains(allows) = True              pos : neg    =      4.0 : 1.0\n",
      "        contains(stupid) = True              neg : pos    =      3.9 : 1.0\n",
      "          contains(dull) = True              neg : pos    =      3.8 : 1.0\n",
      "     contains(laughable) = True              neg : pos    =      3.8 : 1.0\n",
      "          contains(mess) = True              neg : pos    =      3.6 : 1.0\n",
      "     contains(pointless) = True              neg : pos    =      3.6 : 1.0\n",
      "      contains(terrific) = True              pos : neg    =      3.6 : 1.0\n",
      "         contains(badly) = True              neg : pos    =      3.5 : 1.0\n",
      "        contains(boring) = True              neg : pos    =      3.5 : 1.0\n",
      "     contains(portrayal) = True              pos : neg    =      3.5 : 1.0\n",
      "     contains(memorable) = True              pos : neg    =      3.4 : 1.0\n",
      "      contains(terrible) = True              neg : pos    =      3.4 : 1.0\n",
      "   contains(masterpiece) = True              pos : neg    =      3.3 : 1.0\n",
      "         contains(lucas) = True              pos : neg    =      3.1 : 1.0\n",
      "     contains(portrayed) = True              pos : neg    =      3.1 : 1.0\n",
      "        contains(subtle) = True              pos : neg    =      3.0 : 1.0\n",
      "     contains(perfectly) = True              pos : neg    =      3.0 : 1.0\n",
      "     contains(excellent) = True              pos : neg    =      3.0 : 1.0\n",
      "         contains(clich) = True              neg : pos    =      3.0 : 1.0\n",
      "         contains(hanks) = True              pos : neg    =      2.9 : 1.0\n",
      "          contains(epic) = True              pos : neg    =      2.9 : 1.0\n",
      "          contains(zero) = True              neg : pos    =      2.9 : 1.0\n",
      "         contains(naked) = True              neg : pos    =      2.9 : 1.0\n",
      "         contains(julie) = True              neg : pos    =      2.8 : 1.0\n",
      "       contains(complex) = True              pos : neg    =      2.7 : 1.0\n",
      "       contains(sandler) = True              neg : pos    =      2.7 : 1.0\n",
      "     contains(realistic) = True              pos : neg    =      2.7 : 1.0\n",
      "     contains(effective) = True              pos : neg    =      2.7 : 1.0\n",
      "         contains(damme) = True              neg : pos    =      2.6 : 1.0\n",
      "         contains(patch) = True              neg : pos    =      2.6 : 1.0\n",
      "          contains(tony) = True              pos : neg    =      2.6 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current version gets an accuracy of ~ 0.88, lets see how much better we can get by applying some of the learned methods, e.g. stemming or POS tagging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wnl = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_words = FreqDist(wnl.lemmatize(w.lower()) for w in movie_reviews.words())\n",
    "word_features = list(word for (word,count) in all_words.most_common(2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def document_features(document):\n",
    "    words=[wnl.lemmatize(word) for word in document]\n",
    "    document_words = set(words)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featuresets = [(document_features(d), c) for (d,c) in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set, test_set = featuresets[100:], featuresets[:100]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using only adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adjectives=[]\n",
    "for sent in movie_reviews.sents():\n",
    "    for word, pos in nltk.pos_tag(sent):\n",
    "        if pos in [\"JJ\",\"JJR\" \"JJS\"]: # feel free to add any other  tags\n",
    "            adjectives.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fuck',\n",
       " 'teen',\n",
       " 'cool',\n",
       " 'bad',\n",
       " 'such',\n",
       " 'good',\n",
       " 'bad',\n",
       " 't',\n",
       " 'neat',\n",
       " 'main',\n",
       " 's',\n",
       " 'normal',\n",
       " '\"',\n",
       " 'dead',\n",
       " 'dead',\n",
       " 'strange',\n",
       " 'weird',\n",
       " 'don',\n",
       " 't',\n",
       " 'same',\n",
       " 'i',\n",
       " 's',\n",
       " 's',\n",
       " 'big',\n",
       " 'final',\n",
       " 'sad',\n",
       " 'half',\n",
       " 'little',\n",
       " 'bottom',\n",
       " 'sure',\n",
       " 'secret',\n",
       " 'i',\n",
       " 'melissa',\n",
       " 'plain',\n",
       " 'lazy',\n",
       " 'different',\n",
       " 'further',\n",
       " 'pretty',\n",
       " 'fuck',\n",
       " 'i',\n",
       " 'little',\n",
       " 'good',\n",
       " 'wes',\n",
       " 'exact',\n",
       " 'same',\n",
       " 'american',\n",
       " 'new',\n",
       " 'own',\n",
       " 'entire',\n",
       " 's',\n",
       " 'overall',\n",
       " 't',\n",
       " 's',\n",
       " 'pretty',\n",
       " 'pretty',\n",
       " 'teen',\n",
       " 's',\n",
       " 'hot',\n",
       " 's',\n",
       " 'elm',\n",
       " 'happy',\n",
       " 's',\n",
       " 'quick',\n",
       " 's',\n",
       " 'head',\n",
       " 'deserted',\n",
       " 'russian',\n",
       " 'little',\n",
       " 'few',\n",
       " 'empty',\n",
       " 'big',\n",
       " 'flashy',\n",
       " 'donald',\n",
       " 's',\n",
       " 's',\n",
       " 'below',\n",
       " 'likely',\n",
       " 'halloween',\n",
       " 's',\n",
       " 'real',\n",
       " 'stan',\n",
       " 's',\n",
       " 'schnazzy',\n",
       " 'occasional',\n",
       " 'good',\n",
       " 's',\n",
       " 's',\n",
       " 'sunken',\n",
       " 'jaded',\n",
       " 'timex',\n",
       " 'late',\n",
       " 's',\n",
       " 'same',\n",
       " 'reformed',\n",
       " 'wrong',\n",
       " 'quick',\n",
       " 'cool',\n",
       " 's',\n",
       " 'nice',\n",
       " 'like',\n",
       " 'cool',\n",
       " 'first',\n",
       " 'fifteen',\n",
       " 'apparent',\n",
       " 'complete',\n",
       " 'nice',\n",
       " 't',\n",
       " 'long',\n",
       " 'single',\n",
       " 'spectacular',\n",
       " 'only',\n",
       " 'unscathed',\n",
       " 'giovanni',\n",
       " 'only',\n",
       " 'worth',\n",
       " 'convoluted',\n",
       " 'screen',\n",
       " 'young',\n",
       " 'cool',\n",
       " 'nice',\n",
       " 'american',\n",
       " 'juvenile',\n",
       " 'spoon',\n",
       " 'hard',\n",
       " 'predictable',\n",
       " 's',\n",
       " 'questionable',\n",
       " 'memorable',\n",
       " 'clear',\n",
       " 'clear',\n",
       " 'teenage',\n",
       " 'awful',\n",
       " 'teen',\n",
       " 'late',\n",
       " '\"',\n",
       " 'warner',\n",
       " 's',\n",
       " 'other',\n",
       " 'recent',\n",
       " 'last',\n",
       " '20th',\n",
       " 's',\n",
       " 'lively',\n",
       " 'colorful',\n",
       " 's',\n",
       " '\"',\n",
       " 'much',\n",
       " 'dead',\n",
       " 'magic',\n",
       " '\"',\n",
       " 'dull',\n",
       " 'free',\n",
       " 'early',\n",
       " 'teen',\n",
       " 'belated',\n",
       " 's',\n",
       " 's',\n",
       " 'gary',\n",
       " 'ex',\n",
       " 'table',\n",
       " 'bad',\n",
       " 's',\n",
       " 'magical',\n",
       " 'dangerous',\n",
       " 'carey',\n",
       " 'eric',\n",
       " 's',\n",
       " 'able',\n",
       " 'medieval',\n",
       " 's',\n",
       " 'essential',\n",
       " 's',\n",
       " 'high',\n",
       " '\"',\n",
       " 'd',\n",
       " 'saturday',\n",
       " 'subpar',\n",
       " 'forgettable',\n",
       " 'computerized',\n",
       " 's',\n",
       " 'angry',\n",
       " 's',\n",
       " 'interesting',\n",
       " 'much',\n",
       " 's',\n",
       " 'cloying',\n",
       " 'early',\n",
       " 'tgif',\n",
       " 'urkel',\n",
       " 'white',\n",
       " 'bronson',\n",
       " 'same',\n",
       " 'few',\n",
       " 'enough',\n",
       " 'specific',\n",
       " 'enthusiastic',\n",
       " 't',\n",
       " 'big',\n",
       " 'musical',\n",
       " 'much',\n",
       " 'good',\n",
       " 'bored',\n",
       " 'grievous',\n",
       " 'complete',\n",
       " 'long',\n",
       " 'unstable',\n",
       " 'psychotherapy',\n",
       " 'fatal',\n",
       " 'fledgling',\n",
       " 'endless',\n",
       " 'spurned',\n",
       " 'stable',\n",
       " 'theatrical',\n",
       " 'direct',\n",
       " 'due',\n",
       " 'inexpensive',\n",
       " 'special',\n",
       " 'big',\n",
       " 'late',\n",
       " 'stalked',\n",
       " 'contrary',\n",
       " 'ex',\n",
       " 'other',\n",
       " 'redundant',\n",
       " 'much',\n",
       " 'serious',\n",
       " 'stalked',\n",
       " 'obvious',\n",
       " 'obvious',\n",
       " 'obvious',\n",
       " 'desperate',\n",
       " 'elaborate',\n",
       " 'psycho',\n",
       " 'murdered',\n",
       " 's',\n",
       " 'dead',\n",
       " 'inevitable',\n",
       " 'll',\n",
       " 's',\n",
       " 'uniformly',\n",
       " 'bad',\n",
       " 'much',\n",
       " 'other',\n",
       " 'creepy',\n",
       " 'only',\n",
       " 'adequate',\n",
       " 'ditzy',\n",
       " 'strong',\n",
       " 'independent',\n",
       " 'ditzy',\n",
       " 'front',\n",
       " 'oblivious',\n",
       " 'whole',\n",
       " 'incredible',\n",
       " 's',\n",
       " 's',\n",
       " 'derivative',\n",
       " 'boring',\n",
       " 'bad',\n",
       " 'several',\n",
       " 'brief',\n",
       " 'offensive',\n",
       " 'many',\n",
       " 'other',\n",
       " 'good',\n",
       " 'whole',\n",
       " 'many',\n",
       " 'previous',\n",
       " 'precinct',\n",
       " 'new',\n",
       " 'horrible',\n",
       " 'same',\n",
       " 'bad',\n",
       " 'low',\n",
       " 'alien',\n",
       " 'chock',\n",
       " 'full',\n",
       " 'precinct',\n",
       " 'many',\n",
       " 'previous',\n",
       " 'such',\n",
       " 'novel',\n",
       " 'good',\n",
       " 'good',\n",
       " 's',\n",
       " 'normal',\n",
       " 'little',\n",
       " 's',\n",
       " 'female',\n",
       " 'minor',\n",
       " 'technological',\n",
       " 'basic',\n",
       " 'common',\n",
       " 'precinct',\n",
       " 'precinct',\n",
       " 'precinct',\n",
       " 'tacky',\n",
       " 'rundown',\n",
       " 'martian',\n",
       " 'criminal',\n",
       " 'napolean',\n",
       " 'criminal',\n",
       " 'automatic',\n",
       " 'alien',\n",
       " 'alien',\n",
       " 'human',\n",
       " 'red',\n",
       " 'yellow',\n",
       " 'black',\n",
       " 'powerful',\n",
       " 'opening',\n",
       " 'martian',\n",
       " 'heavy',\n",
       " 'little',\n",
       " 'much',\n",
       " 'fugitive',\n",
       " 'sudden',\n",
       " 'scary',\n",
       " 'boring',\n",
       " 'great',\n",
       " 'unimpressive',\n",
       " 'cgi',\n",
       " 'digital',\n",
       " 'short',\n",
       " 'red',\n",
       " 'many',\n",
       " 's',\n",
       " 'classic',\n",
       " 'precinct',\n",
       " 'same',\n",
       " '\"',\n",
       " 'wholesome',\n",
       " 'sleazy',\n",
       " 'big',\n",
       " 'sordid',\n",
       " 'sick',\n",
       " 'depraved',\n",
       " 't',\n",
       " 'twisted',\n",
       " 'sick',\n",
       " 'demented',\n",
       " '\"',\n",
       " 'recent',\n",
       " 'big',\n",
       " '\"',\n",
       " '\"',\n",
       " 'first',\n",
       " 'conventional',\n",
       " 'unsavory',\n",
       " 's',\n",
       " 's',\n",
       " 'ridiculous',\n",
       " 'righteous',\n",
       " 'whole',\n",
       " 'unpleasant',\n",
       " 'private',\n",
       " 'wealthy',\n",
       " 'late',\n",
       " 's',\n",
       " 'safe',\n",
       " 'young',\n",
       " 's',\n",
       " 'specialized',\n",
       " 'easy',\n",
       " 'obsessed',\n",
       " 'paul',\n",
       " 'little',\n",
       " 'flickering',\n",
       " 'unpleasant',\n",
       " 'lovely',\n",
       " 'ugly',\n",
       " '\"',\n",
       " 'subject',\n",
       " 'kevin',\n",
       " 's',\n",
       " 'first',\n",
       " 'hollywood',\n",
       " 'nicolas',\n",
       " 's',\n",
       " 'good',\n",
       " 'interesting',\n",
       " 'flunky',\n",
       " 'horrid',\n",
       " 'familiar',\n",
       " 'offensive',\n",
       " 'sexual',\n",
       " 'everyday',\n",
       " 'standard',\n",
       " '\"',\n",
       " 'long',\n",
       " 'terrible',\n",
       " 'terrible',\n",
       " 'huge',\n",
       " 'whole',\n",
       " 'oral',\n",
       " '/',\n",
       " 're',\n",
       " 'nervous',\n",
       " 'other',\n",
       " 'bad',\n",
       " 's',\n",
       " 's',\n",
       " 'double',\n",
       " 'robin',\n",
       " 'obstetrician',\n",
       " 'pregnant',\n",
       " 'big',\n",
       " 'predictable',\n",
       " 'successful',\n",
       " 'unfunny',\n",
       " 'nervous',\n",
       " 'english',\n",
       " 'i',\n",
       " 'talent',\n",
       " '_huge_',\n",
       " 'hugh',\n",
       " 's',\n",
       " 'many',\n",
       " 'stupid',\n",
       " 'ten',\n",
       " 'pregnant',\n",
       " 'usual',\n",
       " 'fluttered',\n",
       " 'nervous',\n",
       " 'possible',\n",
       " 's',\n",
       " 'pregnant',\n",
       " 'cacophonous',\n",
       " 'funny',\n",
       " 'such',\n",
       " 'own',\n",
       " 'only',\n",
       " 'interesting',\n",
       " 'dreadful',\n",
       " 'simultaneous',\n",
       " 'robin',\n",
       " 'russian',\n",
       " 'veterinary',\n",
       " 'old',\n",
       " 'foreign',\n",
       " 'english',\n",
       " 's',\n",
       " 'favorite',\n",
       " 's',\n",
       " 'nasty',\n",
       " 'unamusing',\n",
       " 'ten',\n",
       " 'complete',\n",
       " 'low',\n",
       " 'high',\n",
       " 'unfunny',\n",
       " 'other',\n",
       " 'uninspired',\n",
       " 'nervous',\n",
       " 'forced',\n",
       " 'unauthentic',\n",
       " 'unfulfilled',\n",
       " 't',\n",
       " 's',\n",
       " 'difficult',\n",
       " 'screen',\n",
       " 'reliable',\n",
       " 'swedish',\n",
       " 'forgettable',\n",
       " 'sentimental',\n",
       " 'mundane',\n",
       " 'european',\n",
       " 'unable',\n",
       " 'late',\n",
       " 'accurate',\n",
       " 'aberdeen',\n",
       " 'alcoholic',\n",
       " 'alienated',\n",
       " 'hostile',\n",
       " 'lena',\n",
       " 't',\n",
       " 'long',\n",
       " 's',\n",
       " 'few',\n",
       " 'open',\n",
       " 'other',\n",
       " 'periodic',\n",
       " 't',\n",
       " 'rotten',\n",
       " 'sloshed',\n",
       " 't',\n",
       " 'kaisa',\n",
       " 'personal',\n",
       " 'unable',\n",
       " 'vindictive',\n",
       " 'unable',\n",
       " 'true',\n",
       " 'unspoken',\n",
       " 'familial',\n",
       " 'bitchy',\n",
       " 'amundsen',\n",
       " 'nosy',\n",
       " 'flat',\n",
       " 'schematic',\n",
       " 'convenient',\n",
       " 's',\n",
       " 'simplistic',\n",
       " 'many',\n",
       " 'bad',\n",
       " 'own',\n",
       " 'aberdeen',\n",
       " 'weak',\n",
       " 'unimaginative',\n",
       " 'pivotal',\n",
       " 'lena',\n",
       " 'able',\n",
       " 'own',\n",
       " 'pastoral',\n",
       " 'certain',\n",
       " 'superior',\n",
       " 'american',\n",
       " 'flick',\n",
       " 'busy',\n",
       " 'last',\n",
       " 'd',\n",
       " 's',\n",
       " 'aberdeen',\n",
       " 's',\n",
       " 'disturbed',\n",
       " 'parental',\n",
       " 'ceremonial',\n",
       " 'significant',\n",
       " 'aberdeen',\n",
       " 'luminous',\n",
       " 'static',\n",
       " 's',\n",
       " 'solid',\n",
       " 'pathetic',\n",
       " 'catatonic',\n",
       " 's',\n",
       " 'genuine',\n",
       " 'understated',\n",
       " 'gray',\n",
       " 'accompany',\n",
       " 'torn',\n",
       " 'stifled',\n",
       " 's',\n",
       " 'neurotic',\n",
       " 's',\n",
       " 'willing',\n",
       " 've',\n",
       " 'traditional',\n",
       " 'ambitious',\n",
       " 'content',\n",
       " 'other',\n",
       " 'real',\n",
       " 's',\n",
       " 'useful',\n",
       " 'grand',\n",
       " 's',\n",
       " 's',\n",
       " 'foreign',\n",
       " 'young',\n",
       " 'french',\n",
       " 'i',\n",
       " 'evil',\n",
       " 'old',\n",
       " 'fourteen',\n",
       " 'swish',\n",
       " 'swish',\n",
       " 'bad',\n",
       " 's',\n",
       " 'plain',\n",
       " 'original',\n",
       " 'predictable',\n",
       " 's',\n",
       " 'main',\n",
       " 'uncharismatic',\n",
       " 'chris',\n",
       " 'bad',\n",
       " 'thora',\n",
       " 'miscast',\n",
       " 'bad',\n",
       " 'awful',\n",
       " 'piss',\n",
       " 'poor',\n",
       " 'sure',\n",
       " 's',\n",
       " 'only',\n",
       " 'tim',\n",
       " 'irrepressible',\n",
       " 'bad',\n",
       " 't',\n",
       " 'same',\n",
       " 'modern',\n",
       " '\"',\n",
       " 'american',\n",
       " '\"',\n",
       " 'nice',\n",
       " 'romantic',\n",
       " 'bad',\n",
       " 'few',\n",
       " 'certain',\n",
       " 's',\n",
       " 'important',\n",
       " '\"',\n",
       " 'real',\n",
       " '\"',\n",
       " 'whole',\n",
       " 'old',\n",
       " 'shoddy',\n",
       " 's',\n",
       " 'own',\n",
       " 'certain',\n",
       " '\"',\n",
       " 't',\n",
       " 'atrocious',\n",
       " 'romantic',\n",
       " 'high',\n",
       " 'little',\n",
       " 'main',\n",
       " 'etre',\n",
       " 'french',\n",
       " 'cool',\n",
       " 'major',\n",
       " 'first',\n",
       " 'other',\n",
       " 'definite',\n",
       " 'catherine',\n",
       " 's',\n",
       " 'ugh',\n",
       " 'small',\n",
       " 's',\n",
       " 's',\n",
       " 'american',\n",
       " 'understated',\n",
       " 'hannibal',\n",
       " 's',\n",
       " 'scottish',\n",
       " 'brian',\n",
       " 'special',\n",
       " 'long',\n",
       " 'kiss',\n",
       " 'substantial',\n",
       " 'brilliant',\n",
       " 'dogged',\n",
       " 'opposite',\n",
       " 'ken',\n",
       " 's',\n",
       " 'hidden',\n",
       " 'big',\n",
       " 'new',\n",
       " 'indie',\n",
       " 'other',\n",
       " 'big',\n",
       " 'big',\n",
       " 'empathetic',\n",
       " 'funny',\n",
       " 'robust',\n",
       " 'old',\n",
       " 'high',\n",
       " 'own',\n",
       " 'elaborate',\n",
       " 'long',\n",
       " 'middle',\n",
       " 'pretty',\n",
       " 'dangerous',\n",
       " 'old',\n",
       " 'paul',\n",
       " 'own',\n",
       " 's',\n",
       " 'big',\n",
       " 'red',\n",
       " 'complex',\n",
       " 'usual',\n",
       " 'half',\n",
       " 'short',\n",
       " 'advised',\n",
       " 'big',\n",
       " 's',\n",
       " 'unnecessary',\n",
       " 'miserable',\n",
       " 'hot',\n",
       " 'white',\n",
       " 'degenerate',\n",
       " 'middle',\n",
       " 'homoerotic',\n",
       " 'gary',\n",
       " 'handsome',\n",
       " 'artful',\n",
       " 'suburban',\n",
       " 'awkward',\n",
       " 'big',\n",
       " 'paced',\n",
       " 'faded',\n",
       " 'quiet',\n",
       " 'first',\n",
       " 'withdrawn',\n",
       " 'transparent',\n",
       " 'dramatic',\n",
       " 'broad',\n",
       " 'obvious',\n",
       " 's',\n",
       " 'admirable',\n",
       " 's',\n",
       " 'big',\n",
       " 'precious',\n",
       " 'ecstatic',\n",
       " 'big',\n",
       " 's',\n",
       " 'much',\n",
       " 'obvious',\n",
       " 'dramatic',\n",
       " 'big',\n",
       " 'other',\n",
       " 'walter',\n",
       " 'jealous',\n",
       " 'content',\n",
       " 'observational',\n",
       " 'teen',\n",
       " 's',\n",
       " 'cuesta',\n",
       " 'own',\n",
       " 'ambivalent',\n",
       " 's',\n",
       " 'typical',\n",
       " 'unimaginative',\n",
       " 'complex',\n",
       " 'philosophical',\n",
       " 'other',\n",
       " 'indie',\n",
       " 'common',\n",
       " 'blockbuster',\n",
       " 'real',\n",
       " 'dramatic',\n",
       " 'romantic',\n",
       " 'good',\n",
       " 'couple',\n",
       " 'predestined',\n",
       " 'few',\n",
       " 'popular',\n",
       " 'political',\n",
       " 'flat',\n",
       " 'jay',\n",
       " 'leary',\n",
       " 'stereotypical',\n",
       " 'only',\n",
       " 'irish',\n",
       " 'catholic',\n",
       " 'kennedy',\n",
       " 'popular',\n",
       " 'leary',\n",
       " 'wrong',\n",
       " 'tiny',\n",
       " 'other',\n",
       " 'first',\n",
       " 'unconventional',\n",
       " 'cinematic',\n",
       " 'garofalo',\n",
       " 'nude',\n",
       " 'david',\n",
       " 'same',\n",
       " 'd',\n",
       " 'superficial',\n",
       " 'happy',\n",
       " 'irish',\n",
       " 'small',\n",
       " 'annual',\n",
       " 'irish',\n",
       " 'souls',\n",
       " 'll',\n",
       " 'respectable',\n",
       " 'comedic',\n",
       " 'weak',\n",
       " 'garofalo',\n",
       " 'leary',\n",
       " 'same',\n",
       " 'leary',\n",
       " 'old',\n",
       " 's',\n",
       " 'high',\n",
       " 'hong',\n",
       " 'kong',\n",
       " 't',\n",
       " 'lukewarm',\n",
       " 'popular',\n",
       " 'asian',\n",
       " 'xiong',\n",
       " 'prior',\n",
       " 'american',\n",
       " 'laughable',\n",
       " 'double',\n",
       " 'cinematic',\n",
       " 'tepid',\n",
       " 'dull',\n",
       " 'bad',\n",
       " 'asian',\n",
       " 'simple',\n",
       " 'justin',\n",
       " 'vengeful',\n",
       " 'cardinal',\n",
       " 'stephen',\n",
       " 's',\n",
       " 'black',\n",
       " 'tim',\n",
       " 'drunk',\n",
       " 'nick',\n",
       " 'steven',\n",
       " 'imprisoned',\n",
       " 's',\n",
       " 'new',\n",
       " 'frisky',\n",
       " 'mena',\n",
       " 'other',\n",
       " 'cardinal',\n",
       " 'catherine',\n",
       " 'artagnan',\n",
       " 'eastern',\n",
       " 'western',\n",
       " 'eastern',\n",
       " 'western',\n",
       " 's',\n",
       " 'high',\n",
       " 'rip',\n",
       " 'die',\n",
       " 'hard',\n",
       " 'other',\n",
       " 'little',\n",
       " 'ten',\n",
       " 'asian',\n",
       " 'predictable',\n",
       " 'monotonous',\n",
       " 'sudden',\n",
       " 'horrible',\n",
       " 'stephen',\n",
       " 'prosaic',\n",
       " 'mousy',\n",
       " 'artangnan',\n",
       " 's',\n",
       " '17th',\n",
       " 'only',\n",
       " 'overall',\n",
       " 'flat',\n",
       " 'mortal',\n",
       " 'rampant',\n",
       " 'randian',\n",
       " 'entire',\n",
       " 'ironic',\n",
       " 'marxist',\n",
       " 'fair',\n",
       " '*',\n",
       " 'necessary',\n",
       " 'familiar',\n",
       " 'whole',\n",
       " 'first',\n",
       " 'first',\n",
       " 'mortal',\n",
       " 'martial',\n",
       " 's',\n",
       " 'poor',\n",
       " 'final',\n",
       " 'mortal',\n",
       " 'ready',\n",
       " 'fighting',\n",
       " 'first',\n",
       " 'many',\n",
       " 'basic',\n",
       " 't',\n",
       " 'cool',\n",
       " 'cool',\n",
       " 'non',\n",
       " 'mortal',\n",
       " 'introductory',\n",
       " 'first',\n",
       " 'silly',\n",
       " 'trite',\n",
       " 'stupid',\n",
       " 'general',\n",
       " 'last',\n",
       " 'such',\n",
       " '*',\n",
       " 'real',\n",
       " '*',\n",
       " 'bad',\n",
       " 'stick',\n",
       " 'first',\n",
       " 'wrong',\n",
       " 'high',\n",
       " 'bad',\n",
       " 'execrable',\n",
       " 'johnny',\n",
       " 'first',\n",
       " 'mis',\n",
       " 'i',\n",
       " 'first',\n",
       " 'french',\n",
       " 'japanese',\n",
       " 'chinese',\n",
       " 'tim',\n",
       " 'tiny',\n",
       " 'fifth',\n",
       " 'favorite',\n",
       " '\"',\n",
       " 'wrong',\n",
       " 'many',\n",
       " 'important',\n",
       " 'meaningless',\n",
       " 'muddled',\n",
       " 'robin',\n",
       " 'mystical',\n",
       " 'irina',\n",
       " 'many',\n",
       " 'huge',\n",
       " 'first',\n",
       " 'first',\n",
       " 'convincing',\n",
       " 'hess',\n",
       " 'martial',\n",
       " 'believable',\n",
       " 'fight',\n",
       " '*',\n",
       " '*',\n",
       " '\"',\n",
       " '\"',\n",
       " '\"',\n",
       " 'big',\n",
       " 'similar',\n",
       " 'first',\n",
       " 'many',\n",
       " 'first',\n",
       " 'robust',\n",
       " 'mud',\n",
       " 'sexist',\n",
       " 'special',\n",
       " 'final',\n",
       " '\"',\n",
       " 'first',\n",
       " 'first',\n",
       " 'much',\n",
       " 'first',\n",
       " 'fair',\n",
       " 'anne',\n",
       " 're',\n",
       " 'hired',\n",
       " 'hired',\n",
       " 's',\n",
       " 'william',\n",
       " 'much',\n",
       " 'painful',\n",
       " 'pedestrian',\n",
       " 'parillaud',\n",
       " 'black',\n",
       " 'black',\n",
       " 'black',\n",
       " '*',\n",
       " 'boring',\n",
       " 's',\n",
       " 'stupid',\n",
       " 'shakespearean',\n",
       " 'such',\n",
       " 'leaden',\n",
       " 'free',\n",
       " 't',\n",
       " 's',\n",
       " 's',\n",
       " 'i',\n",
       " 'wonderful',\n",
       " 'i',\n",
       " '\"',\n",
       " 'nice',\n",
       " 'interesting',\n",
       " 'other',\n",
       " 'tough',\n",
       " 'interested',\n",
       " 's',\n",
       " 'graham',\n",
       " '\"',\n",
       " 'fortune',\n",
       " 's',\n",
       " 'bad',\n",
       " 'clear',\n",
       " 'new',\n",
       " '\"',\n",
       " '\"',\n",
       " 's',\n",
       " '\"',\n",
       " 's',\n",
       " 'possessive',\n",
       " 'unashamed',\n",
       " 'special',\n",
       " 'idiotic',\n",
       " 'chaotic',\n",
       " 'dormant',\n",
       " 'red',\n",
       " 'testy',\n",
       " 'grand',\n",
       " 'bah',\n",
       " 'martian',\n",
       " 'official',\n",
       " 'natasha',\n",
       " 'only',\n",
       " 'silly',\n",
       " 'incarcerated',\n",
       " '\"',\n",
       " 'pretty',\n",
       " ...]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_words = FreqDist(wnl.lemmatize(w.lower(),pos=\"a\") for w in adjectives)\n",
    "word_features = list(word for (word,count) in all_words.most_common(2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s',\n",
       " '\"',\n",
       " 'good',\n",
       " 't',\n",
       " 'other',\n",
       " 'i',\n",
       " 'first',\n",
       " 'bad',\n",
       " 'little',\n",
       " 'new',\n",
       " 'many',\n",
       " 'much',\n",
       " 'great',\n",
       " 'big',\n",
       " 'such',\n",
       " 'few',\n",
       " 'real',\n",
       " 'same',\n",
       " 'old',\n",
       " 'last',\n",
       " 'own',\n",
       " 'young',\n",
       " 'original',\n",
       " 'only',\n",
       " 'funny',\n",
       " 'high',\n",
       " 'special',\n",
       " 'american',\n",
       " 'black',\n",
       " 'hard',\n",
       " 'interesting',\n",
       " 'long',\n",
       " 'different',\n",
       " 'small',\n",
       " 'next',\n",
       " 'several',\n",
       " 'whole',\n",
       " 'true',\n",
       " 'entire',\n",
       " 'human',\n",
       " 'll',\n",
       " 'main',\n",
       " 'dead',\n",
       " 'comic',\n",
       " 'final',\n",
       " 'second',\n",
       " 'full',\n",
       " 'wrong',\n",
       " 'sure',\n",
       " 'able',\n",
       " 'right',\n",
       " 'nice',\n",
       " 'white',\n",
       " 'short',\n",
       " 'major',\n",
       " 'perfect',\n",
       " 'obvious',\n",
       " 'evil',\n",
       " 'enough',\n",
       " 'strong',\n",
       " 'beautiful',\n",
       " 'fine',\n",
       " 'top',\n",
       " 'possible',\n",
       " 'romantic',\n",
       " 'classic',\n",
       " 'stupid',\n",
       " 'deep',\n",
       " 'simple',\n",
       " 'single',\n",
       " 'emotional',\n",
       " 're',\n",
       " 'wild',\n",
       " 'poor',\n",
       " 'easy',\n",
       " 'serious',\n",
       " 'important',\n",
       " 'happy',\n",
       " 'impressive',\n",
       " 'recent',\n",
       " '*',\n",
       " 'wonderful',\n",
       " 'early',\n",
       " 'dark',\n",
       " 'local',\n",
       " 'difficult',\n",
       " 'hilarious',\n",
       " 'certain',\n",
       " 'popular',\n",
       " 'effective',\n",
       " 'late',\n",
       " 'due',\n",
       " 'dramatic',\n",
       " 'personal',\n",
       " 'entertaining',\n",
       " 'sexual',\n",
       " 'similar',\n",
       " 'john',\n",
       " 'red',\n",
       " 'former',\n",
       " 'successful',\n",
       " 'previous',\n",
       " 'familiar',\n",
       " 'rich',\n",
       " 'general',\n",
       " 'powerful',\n",
       " 'david',\n",
       " 'visual',\n",
       " 'usual',\n",
       " 'clear',\n",
       " 'large',\n",
       " 'predictable',\n",
       " 'low',\n",
       " 'strange',\n",
       " 'slow',\n",
       " 'complete',\n",
       " 'solid',\n",
       " 'huge',\n",
       " 'scary',\n",
       " 'excellent',\n",
       " 'third',\n",
       " 'enjoyable',\n",
       " 'private',\n",
       " 'impossible',\n",
       " 'd',\n",
       " 'modern',\n",
       " 'various',\n",
       " 'political',\n",
       " 'smart',\n",
       " 'particular',\n",
       " 'musical',\n",
       " '/',\n",
       " 'overall',\n",
       " 'memorable',\n",
       " 'alien',\n",
       " 'decent',\n",
       " 've',\n",
       " 'michael',\n",
       " 'actual',\n",
       " 'brilliant',\n",
       " 'english',\n",
       " 'british',\n",
       " 'typical',\n",
       " 'ridiculous',\n",
       " 'intelligent',\n",
       " 'terrible',\n",
       " 'heavy',\n",
       " 'free',\n",
       " 'present',\n",
       " 'boring',\n",
       " 'cinematic',\n",
       " 'secret',\n",
       " 'flat',\n",
       " 'cool',\n",
       " 'common',\n",
       " 'close',\n",
       " 'complex',\n",
       " 'tough',\n",
       " 'realistic',\n",
       " 'past',\n",
       " 'famous',\n",
       " 'sweet',\n",
       " 'pretty',\n",
       " 'potential',\n",
       " 'giant',\n",
       " 'favorite',\n",
       " 'french',\n",
       " 'awful',\n",
       " 'minor',\n",
       " 'subtle',\n",
       " 'worth',\n",
       " 'double',\n",
       " 'non',\n",
       " 'believable',\n",
       " 'basic',\n",
       " 'central',\n",
       " 'robert',\n",
       " 'quick',\n",
       " 'interested',\n",
       " 'cheap',\n",
       " 'mysterious',\n",
       " 'teen',\n",
       " 'screen',\n",
       " 'hot',\n",
       " 'dumb',\n",
       " 'tom',\n",
       " 'thin',\n",
       " 'cold',\n",
       " 'live',\n",
       " 'alive',\n",
       " 'violent',\n",
       " 'brief',\n",
       " 'likely',\n",
       " 'normal',\n",
       " 'amazing',\n",
       " 'social',\n",
       " 'ready',\n",
       " 'mary',\n",
       " 'm',\n",
       " 'open',\n",
       " 'unique',\n",
       " 'natural',\n",
       " 'weak',\n",
       " 'half',\n",
       " 'horrible',\n",
       " 'numerous',\n",
       " 'chinese',\n",
       " 'light',\n",
       " 'sean',\n",
       " 'fresh',\n",
       " 'average',\n",
       " 'wide',\n",
       " 'talented',\n",
       " 'dull',\n",
       " 'bizarre',\n",
       " 'apparent',\n",
       " 'technical',\n",
       " 'pathetic',\n",
       " 'incredible',\n",
       " 'sad',\n",
       " 'innocent',\n",
       " 'terrific',\n",
       " 'green',\n",
       " 'odd',\n",
       " 'necessary',\n",
       " 'straight',\n",
       " 'bright',\n",
       " 'physical',\n",
       " 'superior',\n",
       " 'military',\n",
       " 'female',\n",
       " 'genuine',\n",
       " 'humorous',\n",
       " 'angry',\n",
       " 'unfunny',\n",
       " 'rare',\n",
       " 'united',\n",
       " 'urban',\n",
       " 'surprising',\n",
       " 'fun',\n",
       " 'grand',\n",
       " 'martial',\n",
       " 'fellow',\n",
       " 'clever',\n",
       " 'fair',\n",
       " 'appropriate',\n",
       " 'desperate',\n",
       " 'willing',\n",
       " 'animated',\n",
       " 'moral',\n",
       " 'william',\n",
       " 'exciting',\n",
       " 'loud',\n",
       " 'intense',\n",
       " 'key',\n",
       " 'attractive',\n",
       " 'graphic',\n",
       " 'sympathetic',\n",
       " 'dangerous',\n",
       " 'silent',\n",
       " 'steven',\n",
       " 'current',\n",
       " 'likable',\n",
       " 'jean',\n",
       " 'spectacular',\n",
       " 'comedic',\n",
       " 'tim',\n",
       " 'total',\n",
       " 'fantastic',\n",
       " 'constant',\n",
       " 'safe',\n",
       " 'quiet',\n",
       " 'blue',\n",
       " 'available',\n",
       " 'ultimate',\n",
       " 'nasty',\n",
       " 'guilty',\n",
       " 'gary',\n",
       " 'weird',\n",
       " 'disappointing',\n",
       " 'laughable',\n",
       " 'outstanding',\n",
       " 'nuclear',\n",
       " 'crazy',\n",
       " 'responsible',\n",
       " 'silly',\n",
       " 'witty',\n",
       " 'chris',\n",
       " 'fast',\n",
       " 'nick',\n",
       " 'subject',\n",
       " 'sharp',\n",
       " 'japanese',\n",
       " 'danny',\n",
       " 'ten',\n",
       " 'inevitable',\n",
       " 'lead',\n",
       " 'extra',\n",
       " 'offensive',\n",
       " 'remarkable',\n",
       " 'standard',\n",
       " 'religious',\n",
       " 'professional',\n",
       " 'middle',\n",
       " 'public',\n",
       " 'titanic',\n",
       " 'serial',\n",
       " 'frank',\n",
       " 'unexpected',\n",
       " 'rocky',\n",
       " 'capable',\n",
       " 'creative',\n",
       " '=',\n",
       " 'scorsese',\n",
       " 'russian',\n",
       " 'positive',\n",
       " 'unnecessary',\n",
       " 'limited',\n",
       " 'eddie',\n",
       " 'international',\n",
       " 'shallow',\n",
       " 'eccentric',\n",
       " 'traditional',\n",
       " 'tony',\n",
       " 'dimensional',\n",
       " 'national',\n",
       " 'psychological',\n",
       " 'occasional',\n",
       " 'lucky',\n",
       " 'bottom',\n",
       " 'cute',\n",
       " 'regular',\n",
       " 'mental',\n",
       " 'historical',\n",
       " 'lame',\n",
       " 'narrative',\n",
       " 'theatrical',\n",
       " 'detective',\n",
       " 'empty',\n",
       " 'soft',\n",
       " 'criminal',\n",
       " 'mad',\n",
       " 'unbelievable',\n",
       " 'gross',\n",
       " 'convincing',\n",
       " 'painful',\n",
       " 'future',\n",
       " 'critical',\n",
       " 'anti',\n",
       " 'foreign',\n",
       " 'african',\n",
       " 'sexy',\n",
       " 'significant',\n",
       " 'aware',\n",
       " 'worthy',\n",
       " 'latter',\n",
       " 'suspenseful',\n",
       " 'naked',\n",
       " 'sick',\n",
       " 'intriguing',\n",
       " 'fat',\n",
       " 'extraordinary',\n",
       " 'german',\n",
       " 'pure',\n",
       " 'ian',\n",
       " 'unusual',\n",
       " 'alex',\n",
       " 'sudden',\n",
       " 'unable',\n",
       " 'sci',\n",
       " 'ordinary',\n",
       " 'eric',\n",
       " 'robin',\n",
       " 'unknown',\n",
       " 'italian',\n",
       " 'unlikely',\n",
       " 'christian',\n",
       " 'delightful',\n",
       " 'exact',\n",
       " 'ryan',\n",
       " 'sole',\n",
       " 'wealthy',\n",
       " 'utterly',\n",
       " 'co',\n",
       " 'initial',\n",
       " 'climactic',\n",
       " 'fascinating',\n",
       " 'stunning',\n",
       " 'commercial',\n",
       " 'medical',\n",
       " 'mean',\n",
       " 'steve',\n",
       " 'married',\n",
       " 'digital',\n",
       " 'erotic',\n",
       " 'inventive',\n",
       " 'joe',\n",
       " 'fake',\n",
       " 'golden',\n",
       " 'magical',\n",
       " 'outrageous',\n",
       " 'brian',\n",
       " 'super',\n",
       " 'artistic',\n",
       " 'conventional',\n",
       " 'extreme',\n",
       " 'tiny',\n",
       " 'gorgeous',\n",
       " 'notable',\n",
       " 'ex',\n",
       " 'prime',\n",
       " 'contemporary',\n",
       " 'sixth',\n",
       " 'directorial',\n",
       " 'western',\n",
       " 'ed',\n",
       " 'obnoxious',\n",
       " 'endless',\n",
       " 'fifteen',\n",
       " 'tight',\n",
       " 'colorful',\n",
       " 'rival',\n",
       " 'generic',\n",
       " 'kevin',\n",
       " 'multiple',\n",
       " 'tragic',\n",
       " 'elaborate',\n",
       " 'patrick',\n",
       " 'likeable',\n",
       " 'ben',\n",
       " 'gratuitous',\n",
       " 'aforementioned',\n",
       " 'intellectual',\n",
       " 'expensive',\n",
       " 'self',\n",
       " 'primary',\n",
       " 'stereotypical',\n",
       " 'irish',\n",
       " 'tedious',\n",
       " 'legendary',\n",
       " 'spiritual',\n",
       " 'saturday',\n",
       " 'ironic',\n",
       " 'near',\n",
       " 'individual',\n",
       " 'independent',\n",
       " 'virtual',\n",
       " 'dry',\n",
       " 'queen',\n",
       " 'false',\n",
       " 'warm',\n",
       " 'tired',\n",
       " 'fifth',\n",
       " 'enormous',\n",
       " 'crucial',\n",
       " 'energetic',\n",
       " 'equal',\n",
       " 'idiotic',\n",
       " 'ensemble',\n",
       " 'unfortunate',\n",
       " 'mere',\n",
       " 'negative',\n",
       " 'civil',\n",
       " 'pleasant',\n",
       " 'peter',\n",
       " 'welcome',\n",
       " 'pregnant',\n",
       " 'confusing',\n",
       " 'universal',\n",
       " 'susan',\n",
       " 'infamous',\n",
       " 'superb',\n",
       " 'direct',\n",
       " '[',\n",
       " 'lost',\n",
       " 'stylish',\n",
       " 'sub',\n",
       " 'brutal',\n",
       " 'uninteresting',\n",
       " 'pointless',\n",
       " 'ill',\n",
       " 'amusing',\n",
       " 'bitter',\n",
       " 'bloody',\n",
       " 'invisible',\n",
       " 'morgan',\n",
       " 'charismatic',\n",
       " 'compelling',\n",
       " 'supernatural',\n",
       " 'paul',\n",
       " 'richard',\n",
       " 'vicious',\n",
       " 'inner',\n",
       " 'matt',\n",
       " 'troubled',\n",
       " 'ludicrous',\n",
       " 'fourth',\n",
       " 'absurd',\n",
       " 'running',\n",
       " 'southern',\n",
       " 'van',\n",
       " 'twisted',\n",
       " 'south',\n",
       " 'miss',\n",
       " 'bleak',\n",
       " 'mixed',\n",
       " 'un',\n",
       " 'reese',\n",
       " 'acting',\n",
       " 'ancient',\n",
       " 'male',\n",
       " 'fbi',\n",
       " 'psychotic',\n",
       " 'u',\n",
       " 'uninspired',\n",
       " 'trite',\n",
       " 'lethal',\n",
       " 'ambitious',\n",
       " 'quirky',\n",
       " 'friendly',\n",
       " 'confused',\n",
       " 'superficial',\n",
       " 'credible',\n",
       " 'flashy',\n",
       " 'wish',\n",
       " 'mediocre',\n",
       " 'nervous',\n",
       " 'melodramatic',\n",
       " 'suspicious',\n",
       " 'opposite',\n",
       " 'tommy',\n",
       " 'inept',\n",
       " 'neil',\n",
       " 'excessive',\n",
       " 'cynical',\n",
       " 'reminiscent',\n",
       " 'pretentious',\n",
       " 'porn',\n",
       " 'sentimental',\n",
       " 'lovely',\n",
       " 'broad',\n",
       " 'massive',\n",
       " 'fatal',\n",
       " 'loose',\n",
       " 'lee',\n",
       " 'isn',\n",
       " 'hidden',\n",
       " 'novel',\n",
       " 'controversial',\n",
       " 'wooden',\n",
       " 'further',\n",
       " 'extended',\n",
       " 'upper',\n",
       " 'fugitive',\n",
       " 'catholic',\n",
       " 'like',\n",
       " 'clean',\n",
       " 'stephen',\n",
       " 'routine',\n",
       " 'naive',\n",
       " 'gay',\n",
       " 'magnificent',\n",
       " 'sloppy',\n",
       " 'uncomfortable',\n",
       " 'natasha',\n",
       " 'surreal',\n",
       " 'busy',\n",
       " 'proper',\n",
       " 'known',\n",
       " 'shot',\n",
       " 'documentary',\n",
       " 'simon',\n",
       " 'inspired',\n",
       " 'wacky',\n",
       " 'asian',\n",
       " 'afraid',\n",
       " 'sophisticated',\n",
       " 'authentic',\n",
       " 'obligatory',\n",
       " 'unpleasant',\n",
       " 'deadly',\n",
       " 'legal',\n",
       " 'acceptable',\n",
       " 'nazi',\n",
       " 'frightening',\n",
       " 'respective',\n",
       " 'arnold',\n",
       " 'outside',\n",
       " 'jewish',\n",
       " 'manipulative',\n",
       " 'indian',\n",
       " 'artificial',\n",
       " 'drunken',\n",
       " 'futuristic',\n",
       " 'australian',\n",
       " 'definite',\n",
       " 'essential',\n",
       " 'hollow',\n",
       " 'jealous',\n",
       " 'animal',\n",
       " 'utter',\n",
       " 'harsh',\n",
       " 'curious',\n",
       " 'adequate',\n",
       " 'broken',\n",
       " 'specific',\n",
       " 'marvelous',\n",
       " 'sound',\n",
       " 'distant',\n",
       " 'sensitive',\n",
       " 'unpredictable',\n",
       " 'satisfying',\n",
       " 'uma',\n",
       " 'nifty',\n",
       " 'unhappy',\n",
       " 'illegal',\n",
       " 'austin',\n",
       " 'matthew',\n",
       " 'underrated',\n",
       " 'lovable',\n",
       " 'fable',\n",
       " 'accurate',\n",
       " 'lesbian',\n",
       " 'awkward',\n",
       " 'mystical',\n",
       " 'amy',\n",
       " 'jurassic',\n",
       " 'financial',\n",
       " 'handsome',\n",
       " 'don',\n",
       " 'bob',\n",
       " 'elderly',\n",
       " 'poignant',\n",
       " 'upcoming',\n",
       " 'reluctant',\n",
       " 'halloween',\n",
       " 'plausible',\n",
       " 'anthony',\n",
       " 'evident',\n",
       " 'semi',\n",
       " 'slight',\n",
       " 'exceptional',\n",
       " 'loyal',\n",
       " 'miserable',\n",
       " 'academy',\n",
       " 'fish',\n",
       " 'hong',\n",
       " 'mortal',\n",
       " 'boogie',\n",
       " 'forgettable',\n",
       " 'repetitive',\n",
       " 'vast',\n",
       " 'watchable',\n",
       " 'foul',\n",
       " 'tremendous',\n",
       " 'grim',\n",
       " 'raw',\n",
       " 'corrupt',\n",
       " 'east',\n",
       " 'comical',\n",
       " 'frequent',\n",
       " 'ultra',\n",
       " 'johnny',\n",
       " 'awesome',\n",
       " 'adam',\n",
       " 'disturbing',\n",
       " 'jason',\n",
       " 'comfortable',\n",
       " 'following',\n",
       " 'satirical',\n",
       " 'useless',\n",
       " 'creepy',\n",
       " 'thoughtful',\n",
       " 'truman',\n",
       " 'north',\n",
       " 'worthwhile',\n",
       " 'daniel',\n",
       " 'tense',\n",
       " 'san',\n",
       " 'unrealistic',\n",
       " 'sappy',\n",
       " 'selfish',\n",
       " 'vincent',\n",
       " 'native',\n",
       " 'annoying',\n",
       " 'precious',\n",
       " 'countless',\n",
       " 'uneven',\n",
       " 'underground',\n",
       " 'tall',\n",
       " 'alan',\n",
       " 'cultural',\n",
       " 'detailed',\n",
       " 'sadistic',\n",
       " 'sam',\n",
       " 'plain',\n",
       " 'lisa',\n",
       " 'pivotal',\n",
       " 'imaginative',\n",
       " 'clumsy',\n",
       " 'crystal',\n",
       " 'gothic',\n",
       " 'vulnerable',\n",
       " 'fairy',\n",
       " 'arrogant',\n",
       " 'respectable',\n",
       " 'straightforward',\n",
       " 'canadian',\n",
       " 'macho',\n",
       " 'warrior',\n",
       " 'needless',\n",
       " 'spanish',\n",
       " 'critic',\n",
       " 'kong',\n",
       " 'failed',\n",
       " 'lonely',\n",
       " 'admirable',\n",
       " 'ominous',\n",
       " 'cartoonish',\n",
       " 'formulaic',\n",
       " 'facial',\n",
       " 'unconvincing',\n",
       " 'everyday',\n",
       " 'lazy',\n",
       " 'dreadful',\n",
       " 'slapstick',\n",
       " 'unforgettable',\n",
       " 'terrorist',\n",
       " 'reliable',\n",
       " 'federal',\n",
       " 'noble',\n",
       " 'insightful',\n",
       " 'mindless',\n",
       " 'token',\n",
       " 'back',\n",
       " 'thirteenth',\n",
       " 'julia',\n",
       " 'immediate',\n",
       " 'noticeable',\n",
       " 'freddie',\n",
       " 'prominent',\n",
       " 'hysterical',\n",
       " 'generated',\n",
       " 'separate',\n",
       " 'seagal',\n",
       " 'elizabeth',\n",
       " 'pg',\n",
       " 'fictional',\n",
       " 'eager',\n",
       " 'ok',\n",
       " 'jonathan',\n",
       " 'lousy',\n",
       " 'masterful',\n",
       " 'hokey',\n",
       " 'allen',\n",
       " 'ideal',\n",
       " 'confident',\n",
       " 'philosophical',\n",
       " 'twenty',\n",
       " 'sleazy',\n",
       " 'gory',\n",
       " 'understated',\n",
       " 'kathy',\n",
       " 'snow',\n",
       " 'implausible',\n",
       " 'andy',\n",
       " 'forced',\n",
       " 'chief',\n",
       " 'manic',\n",
       " 'funeral',\n",
       " 'secondary',\n",
       " 'mechanical',\n",
       " 'strict',\n",
       " 'logical',\n",
       " 'catherine',\n",
       " 'subsequent',\n",
       " 'understandable',\n",
       " 'isolated',\n",
       " 'innovative',\n",
       " 'contrary',\n",
       " 'internal',\n",
       " 'nicolas',\n",
       " 'considerable',\n",
       " 'potent',\n",
       " 'rough',\n",
       " 'alec',\n",
       " 'dubious',\n",
       " 'absolute',\n",
       " 'mild',\n",
       " 'natalie',\n",
       " 'cruel',\n",
       " 'psychic',\n",
       " 'reasonable',\n",
       " 'lackluster',\n",
       " 'impressed',\n",
       " 'rapid',\n",
       " 'irresistible',\n",
       " 'complicated',\n",
       " 'goofy',\n",
       " 'european',\n",
       " 'amanda',\n",
       " 'cheesy',\n",
       " 'healthy',\n",
       " 'ethan',\n",
       " 'fantasy',\n",
       " 'nicole',\n",
       " '20th',\n",
       " 'phantom',\n",
       " 'hollywood',\n",
       " 'jim',\n",
       " 'proud',\n",
       " 'stellar',\n",
       " 'contrived',\n",
       " 'oh',\n",
       " 'albert',\n",
       " 'cliched',\n",
       " 'die',\n",
       " 'domestic',\n",
       " 'weary',\n",
       " 'front',\n",
       " 'lengthy',\n",
       " 'vital',\n",
       " 'nude',\n",
       " 'gritty',\n",
       " 'stuart',\n",
       " 'art',\n",
       " 'homosexual',\n",
       " 'mel',\n",
       " 'intricate',\n",
       " 'sarah',\n",
       " 'meaningful',\n",
       " 'couple',\n",
       " 'proverbial',\n",
       " 'randy',\n",
       " 'concerned',\n",
       " 'verbal',\n",
       " 'teenage',\n",
       " 'fabulous',\n",
       " 'flawless',\n",
       " 'senior',\n",
       " 'toy',\n",
       " 'adorable',\n",
       " 'industrial',\n",
       " 'correct',\n",
       " 'ricky',\n",
       " 'faithful',\n",
       " 'unintentional',\n",
       " 'dreary',\n",
       " 'incomprehensible',\n",
       " 'fi',\n",
       " 'val',\n",
       " 'slick',\n",
       " 'thirty',\n",
       " 'ambiguous',\n",
       " 'gentle',\n",
       " 'stylistic',\n",
       " 'o',\n",
       " 'related',\n",
       " 'blatant',\n",
       " 'exotic',\n",
       " 'unseen',\n",
       " 'wong',\n",
       " 'magic',\n",
       " '+',\n",
       " 'paranoid',\n",
       " 'stale',\n",
       " 'lifeless',\n",
       " 'hideous',\n",
       " 'neat',\n",
       " 'depressing',\n",
       " 'samuel',\n",
       " 'spielberg',\n",
       " 'donald',\n",
       " 'betty',\n",
       " 'moronic',\n",
       " 'underwritten',\n",
       " 'phony',\n",
       " 'leigh',\n",
       " 'kathleen',\n",
       " 'doesn',\n",
       " 'underdeveloped',\n",
       " 'skin',\n",
       " 'striking',\n",
       " 'flesh',\n",
       " 'corporate',\n",
       " 'laura',\n",
       " 'advanced',\n",
       " 'touching',\n",
       " 'natured',\n",
       " 'accomplished',\n",
       " 'dismal',\n",
       " 'explicit',\n",
       " 'neurotic',\n",
       " 'fancy',\n",
       " 'notorious',\n",
       " 'distinct',\n",
       " 'shady',\n",
       " 'preposterous',\n",
       " 'crazed',\n",
       " 'ted',\n",
       " 'geoffrey',\n",
       " 'sarcastic',\n",
       " 'nc',\n",
       " 'substantial',\n",
       " 'anne',\n",
       " 'aggressive',\n",
       " 'maximum',\n",
       " 'murderous',\n",
       " 'jon',\n",
       " 'disappointed',\n",
       " 'suitable',\n",
       " 'liam',\n",
       " 'depressed',\n",
       " 'bold',\n",
       " 'content',\n",
       " 'dynamic',\n",
       " 'peaceful',\n",
       " 'gabriel',\n",
       " 'surprised',\n",
       " 'practical',\n",
       " 'promising',\n",
       " 'holy',\n",
       " 'uncertain',\n",
       " 'developed',\n",
       " 'random',\n",
       " 'furious',\n",
       " 'timothy',\n",
       " 'uplifting',\n",
       " 'irrelevant',\n",
       " 'minimal',\n",
       " 'sonny',\n",
       " 'unbearable',\n",
       " 'los',\n",
       " 'child',\n",
       " 'gigantic',\n",
       " 'questionable',\n",
       " 'tiresome',\n",
       " 'risky',\n",
       " 'absent',\n",
       " 'engaging',\n",
       " 'stop',\n",
       " 'honest',\n",
       " 'jamie',\n",
       " 'noteworthy',\n",
       " 'nicky',\n",
       " 'ish',\n",
       " 'fox',\n",
       " 'unoriginal',\n",
       " 'charming',\n",
       " 'martin',\n",
       " 'angela',\n",
       " 'todd',\n",
       " 'martian',\n",
       " 'damn',\n",
       " 'luke',\n",
       " 'eerie',\n",
       " 'insipid',\n",
       " 'love',\n",
       " 'simplistic',\n",
       " 'n',\n",
       " 'misguided',\n",
       " 'daily',\n",
       " 'abusive',\n",
       " 'ali',\n",
       " 'horrific',\n",
       " 'nearby',\n",
       " 'multi',\n",
       " 'las',\n",
       " 'glamorous',\n",
       " 'onscreen',\n",
       " 'vague',\n",
       " 'primitive',\n",
       " 'above',\n",
       " 'sir',\n",
       " 'scottish',\n",
       " 'chase',\n",
       " 'wicked',\n",
       " 'neo',\n",
       " 'unsettling',\n",
       " 'underused',\n",
       " 'shy',\n",
       " 'extensive',\n",
       " 'girl',\n",
       " 'remote',\n",
       " 'jack',\n",
       " 'commentary',\n",
       " 'crisp',\n",
       " 'edgy',\n",
       " 'keanu',\n",
       " 'atrocious',\n",
       " 'thomas',\n",
       " 'unsatisfying',\n",
       " 'consistent',\n",
       " 'thought',\n",
       " 'norman',\n",
       " 'foolish',\n",
       " 'inferior',\n",
       " 'diabolical',\n",
       " 'principal',\n",
       " 'literary',\n",
       " ...]"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def document_features(document):\n",
    "    words=[wnl.lemmatize(word.lower(),pos=\"a\") for word in document]\n",
    "    document_words = set(words)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word.lower())] = (word.lower() in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featuresets = [(document_features(d), c) for (d,c) in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set, test_set = featuresets[100:], featuresets[:100]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "     contains(insulting) = True              neg : pos    =     11.8 : 1.0\n",
      "     contains(ludicrous) = True              neg : pos    =     11.0 : 1.0\n",
      "   contains(outstanding) = True              pos : neg    =     10.4 : 1.0\n",
      "    contains(incoherent) = True              neg : pos    =     10.0 : 1.0\n",
      "      contains(seamless) = True              pos : neg    =      9.3 : 1.0\n",
      "      contains(thematic) = True              pos : neg    =      9.3 : 1.0\n",
      "        contains(feeble) = True              neg : pos    =      9.3 : 1.0\n",
      "     contains(illogical) = True              neg : pos    =      9.3 : 1.0\n",
      "        contains(seagal) = True              neg : pos    =      8.7 : 1.0\n",
      " contains(unimaginative) = True              neg : pos    =      7.8 : 1.0\n",
      "      contains(poignant) = True              pos : neg    =      7.6 : 1.0\n",
      "       contains(abysmal) = True              neg : pos    =      7.0 : 1.0\n",
      "        contains(shoddy) = True              neg : pos    =      7.0 : 1.0\n",
      "        contains(crappy) = True              neg : pos    =      7.0 : 1.0\n",
      "      contains(marginal) = True              neg : pos    =      7.0 : 1.0\n",
      "       contains(idiotic) = True              neg : pos    =      7.0 : 1.0\n",
      "       contains(insipid) = True              neg : pos    =      6.9 : 1.0\n",
      "     contains(marvelous) = True              pos : neg    =      6.8 : 1.0\n",
      "     contains(atrocious) = True              neg : pos    =      6.4 : 1.0\n",
      "        contains(anakin) = True              pos : neg    =      6.3 : 1.0\n",
      "       contains(supreme) = True              pos : neg    =      6.3 : 1.0\n",
      "           contains(qui) = True              pos : neg    =      6.3 : 1.0\n",
      "   contains(magnificent) = True              pos : neg    =      6.3 : 1.0\n",
      "       contains(amateur) = True              neg : pos    =      6.3 : 1.0\n",
      "    contains(unbearable) = True              neg : pos    =      6.0 : 1.0\n",
      " contains(unintentional) = True              neg : pos    =      5.9 : 1.0\n",
      "          contains(lame) = True              neg : pos    =      5.8 : 1.0\n",
      "         contains(damon) = True              pos : neg    =      5.7 : 1.0\n",
      " contains(introspective) = True              pos : neg    =      5.7 : 1.0\n",
      "        contains(wasted) = True              neg : pos    =      5.6 : 1.0\n",
      "      contains(palpable) = True              pos : neg    =      5.6 : 1.0\n",
      "        contains(justin) = True              neg : pos    =      5.6 : 1.0\n",
      "      contains(angelina) = True              neg : pos    =      5.6 : 1.0\n",
      "   contains(ineffectual) = True              neg : pos    =      5.6 : 1.0\n",
      "      contains(passable) = True              neg : pos    =      5.6 : 1.0\n",
      "         contains(inept) = True              neg : pos    =      5.6 : 1.0\n",
      "         contains(rabid) = True              neg : pos    =      5.6 : 1.0\n",
      "   contains(uninvolving) = True              neg : pos    =      5.6 : 1.0\n",
      "        contains(sloppy) = True              neg : pos    =      5.6 : 1.0\n",
      "     contains(uplifting) = True              pos : neg    =      5.5 : 1.0\n",
      "         contains(awful) = True              neg : pos    =      5.4 : 1.0\n",
      "      contains(dazzling) = True              pos : neg    =      5.3 : 1.0\n",
      "        contains(alicia) = True              neg : pos    =      5.2 : 1.0\n",
      " contains(technological) = True              pos : neg    =      5.1 : 1.0\n",
      "  contains(subconscious) = True              pos : neg    =      5.1 : 1.0\n",
      "      contains(everyday) = True              pos : neg    =      5.1 : 1.0\n",
      "    contains(ridiculous) = True              neg : pos    =      5.1 : 1.0\n",
      "       contains(offbeat) = True              pos : neg    =      5.0 : 1.0\n",
      "        contains(poorly) = True              neg : pos    =      4.9 : 1.0\n",
      "    contains(unoriginal) = True              neg : pos    =      4.9 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just try other things "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
