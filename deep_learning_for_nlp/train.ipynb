{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for NLP Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we are going to apply recurrent neural networks to a text classification problem in order to predict in which forum on Stackexchnage questions were asked.\n",
    "\n",
    "Please note: \n",
    "\n",
    "- You can interrupt the training process at any time by clicking on *Kernel* and then *Interrupt*.\n",
    "- This notebook has not yet been adapted to Keras 2. If you use Python and don't want to use AWS, please do: `conda install keras==1.1.1 graphviz pydot`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the [Keras](http://keras.io) framework that provides a high-level interface to common deep learning methods. We will only use the [funcational API](https://keras.io/getting-started/functional-api-guide/) due to its expressive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(42)\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.layers.wrappers import *\n",
    "from keras.optimizers import *\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.visualize_util import plot, model_to_dot\n",
    "from IPython.display import SVG\n",
    "try:\n",
    "    from sklearn.model_selection import train_test_split\n",
    "except ImportError:\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data has been already preprocessed from raw XML format and saved to csv. However, you must remeber that Keras works on numpy arrays so we will prepare data before feed it to the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_final = pd.read_csv(\"dataset_final.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's focus on columns with questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am trying to model the effect of advertisement on sales in Stata. The data is weekly and there are around 150 observations. I started by applying an ARMAX(1,0,1) model with the following exogenous variables: investment in advertisement, quantities bought by visit and some seasonal dummies (Q1, Q2, Q3).  \\n\\nI would like to have some ideas regarding the model:\\n\\n<ol>\\n<li>Is this the best model to estimate the coefficients accurately?</li>\\n<li>Should I be worried about endogeneity?</li>\\n<li>Is there any way to impose (or test) diminishing returns for the investment in advertisement?</li>\\n</ol>\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['question'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = np.array(df_final['forum'])\n",
    "X = df_final.drop('forum', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have split the data into train and test let's finally preprocess the question column. Remember that you cannot just input words - they must be in numerical form. Keras has a lot of [methods](https://keras.io/preprocessing/text/#tokenizer) to tackle that issue.\n",
    "\n",
    "In this tutorial, we use a tokenizer that splits sentences into words in form of indices in a word dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the tokenizer on the training data (build the vocabulary of words):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(list(X_train['question'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And look up the word indices in the tokenizer model for our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_tokenized = tokenizer.texts_to_sequences(list(X_train['question'].values))\n",
    "X_test_tokenized = tokenizer.texts_to_sequences(list(X_test['question'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we will be training in mini-baches that need to fit into a numpy array, we need our sentences to have the same number of words. We can achieve this by a method called padding. Padding simply fills up our sentences (list of word indices) with zeros until there are at least `maxlen` words in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_padded = sequence.pad_sequences(X_train_tokenized, maxlen=150)\n",
    "X_test_padded = sequence.pad_sequences(X_test_tokenized, maxlen=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect what padding did to our data. We can see that before padding, we had 70 words in sentence 155:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_tokenized[155])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After padding, we have exactly 150:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_padded[155].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the missing words were filled up with zeros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     9,\n",
       "         239,   430,    41,    23,   323,   334,    77,   174,   112,\n",
       "         140,   698,   235,    13,    17,     1,   179,   342,   356,\n",
       "           4,  1027,  2083,    15,   152,     2,    50,    33,   136,\n",
       "         162,   356,    11,     1,  2097,   334,     6,    41,     3,\n",
       "        1806,     5,  1584,   179,   342,    11,    55,  2097,   169,\n",
       "          30,     6,    41,    64,   204,     9,  2097,    11,  2083,\n",
       "          15,    30,    58,   539,    17,     4,  1027,    71,     1,\n",
       "         212, 11104, 10478,     9,  2097,   221], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_padded[155]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the last step, do not forget to turn the target columns into an one-hot encoded array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "Y_train = np.eye(3)[le.fit_transform(y_train).reshape(-1)]\n",
    "Y_test = np.eye(3)[le.transform(y_test).reshape(-1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling our first network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's inspect the data that we obtained. Figuring out right shapes is crucial.\n",
    "\n",
    "In this dataset we have..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timesteps = X_train_padded.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timesteps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define the input layer, which just takes in our data. It does not contain any logic other than defining the shape of our input. Since we use the functional API, this also means that all matrix shapes in the following layers will be inferred automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = Input(shape=(timesteps, ), name=\"inputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To model words we use an `Embedding` layer.\n",
    "\n",
    "The embedding layer turns positive integers (indexes) into dense vectors of fixed size. eg. `[[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]]`. The first parameter defines how many words are in the dictionary, the second parameter defines the size of the vector the input is reduced to.\n",
    "\n",
    "Skip-gram, CBOW, and GloVe (or any other word2vec variant) are pre-trained word embeddings which can be set as the weight of an embedding layer. If the weight of this layer (generally the first layer of the network) is not initialized by these pre-trained vectors, the model/network itself would assign random weights and will learn the embeddings (i.e. weights) on the fly. The latter is what we will be doing in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Embedding(len(tokenizer.word_index)+1, 32, mask_zero=True)(input) # +1 for the vocabulary sign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the fun parts starts. We will add an LSTM layer that builds a representation of each posted question based on the words in the sentence.\n",
    "\n",
    "Remember the unfolding in time computation graph for an RNN\n",
    "\n",
    "![image](http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/09/rnn.jpg)\n",
    "\n",
    "where $x_t$ are words in particular question, e.g. $x_1$ is the first word and $x_2$ is the second word. In our case, we are only interested in the last output $o_t$ where $t$ corresponds to the last word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = LSTM(10)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're almost done! Let's wire up the 10 output neurons of the LSTM to 3 output neurons using a [Dense](https://keras.io/layers/core/#dense) layer (because we have 3 output classes). A Dense layer is just your regular fully connected NN layer. The softmax activation function squeezes these 3 numbers such that they sum up to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = Dense(3, activation='softmax', name='output')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's wrap up the input and output of our Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(input=input, output=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will compile our model. Here, we specify two parameters:\n",
    "\n",
    "- optimizer: an optimizer does all the work for us. Given the input and the computed errors, it decides which direction to take. There are quite a few [optimizers available in Keras](https://keras.io/optimizers/).\n",
    "- loss: the loss or objective function tells the model how well we are doing on our data. In our case, this is simply categorical crossentropy, but in other cases this may be e.g. mean squared error or binary crossentropy. Note that this function needs to be differentiable because during training we need to be able to compute the weight updates. Hence, we cannot optimize for e.g. ROCAUC directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Nadam(), loss=\"categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print out a nice plot of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"304pt\" viewBox=\"0.00 0.00 328.00 304.00\" width=\"328pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 300)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-300 324,-300 324,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140170831253008 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140170831253008</title>\n",
       "<polygon fill=\"none\" points=\"32.5,-249.5 32.5,-295.5 287.5,-295.5 287.5,-249.5 32.5,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"91\" y=\"-268.8\">inputs: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"149.5,-249.5 149.5,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"177\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"149.5,-272.5 204.5,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"177\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"204.5,-249.5 204.5,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"246\" y=\"-280.3\">(None, 150)</text>\n",
       "<polyline fill=\"none\" points=\"204.5,-272.5 287.5,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"246\" y=\"-257.3\">(None, 150)</text>\n",
       "</g>\n",
       "<!-- 140170830389136 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140170830389136</title>\n",
       "<polygon fill=\"none\" points=\"0,-166.5 0,-212.5 320,-212.5 320,-166.5 0,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"80.5\" y=\"-185.8\">embedding_1: Embedding</text>\n",
       "<polyline fill=\"none\" points=\"161,-166.5 161,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"188.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"161,-189.5 216,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"188.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"216,-166.5 216,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"268\" y=\"-197.3\">(None, 150)</text>\n",
       "<polyline fill=\"none\" points=\"216,-189.5 320,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"268\" y=\"-174.3\">(None, 150, 32)</text>\n",
       "</g>\n",
       "<!-- 140170831253008&#45;&gt;140170830389136 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140170831253008-&gt;140170830389136</title>\n",
       "<path d=\"M160,-249.366C160,-241.152 160,-231.658 160,-222.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"163.5,-222.607 160,-212.607 156.5,-222.607 163.5,-222.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140170829622608 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140170829622608</title>\n",
       "<polygon fill=\"none\" points=\"31.5,-83.5 31.5,-129.5 288.5,-129.5 288.5,-83.5 31.5,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"80.5\" y=\"-102.8\">lstm_1: LSTM</text>\n",
       "<polyline fill=\"none\" points=\"129.5,-83.5 129.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"157\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"129.5,-106.5 184.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"157\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"184.5,-83.5 184.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"236.5\" y=\"-114.3\">(None, 150, 32)</text>\n",
       "<polyline fill=\"none\" points=\"184.5,-106.5 288.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"236.5\" y=\"-91.3\">(None, 10)</text>\n",
       "</g>\n",
       "<!-- 140170830389136&#45;&gt;140170829622608 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140170830389136-&gt;140170829622608</title>\n",
       "<path d=\"M160,-166.366C160,-158.152 160,-148.658 160,-139.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"163.5,-139.607 160,-129.607 156.5,-139.607 163.5,-139.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140170827820176 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140170827820176</title>\n",
       "<polygon fill=\"none\" points=\"48.5,-0.5 48.5,-46.5 271.5,-46.5 271.5,-0.5 48.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"94.5\" y=\"-19.8\">output: Dense</text>\n",
       "<polyline fill=\"none\" points=\"140.5,-0.5 140.5,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"168\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"140.5,-23.5 195.5,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"168\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"195.5,-0.5 195.5,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"233.5\" y=\"-31.3\">(None, 10)</text>\n",
       "<polyline fill=\"none\" points=\"195.5,-23.5 271.5,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"233.5\" y=\"-8.3\">(None, 3)</text>\n",
       "</g>\n",
       "<!-- 140170829622608&#45;&gt;140170827820176 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140170829622608-&gt;140170827820176</title>\n",
       "<path d=\"M160,-83.3664C160,-75.1516 160,-65.6579 160,-56.7252\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"163.5,-56.6068 160,-46.6068 156.5,-56.6069 163.5,-56.6068\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that *None* simply means that the model does not really care how many instances we input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's train!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train using a mini-batch size of 50 instances at a time. This speeds things up, because a mini-batch can be computed in parallel on a GPU/CPU. We train for eight epochs, i.e. we go over our training set three times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please leave *verbose* at 2** in the following call, otherwise your notebook may freeze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "inputs (InputLayer)              (None, 150)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)          (None, 150, 32)       1716704     inputs[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 10)            1720        embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "output (Dense)                   (None, 3)             33          lstm_1[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 1718457\n",
      "____________________________________________________________________________________________________\n",
      "Train on 9707 samples, validate on 2427 samples\n",
      "Epoch 1/4\n",
      "11s - loss: 0.8533 - acc: 0.5568 - val_loss: 0.7466 - val_acc: 0.6753\n",
      "Epoch 2/4\n",
      "9s - loss: 0.6774 - acc: 0.7220 - val_loss: 0.6931 - val_acc: 0.7079\n",
      "Epoch 3/4\n",
      "9s - loss: 0.6159 - acc: 0.7298 - val_loss: 0.7221 - val_acc: 0.6481\n",
      "Epoch 4/4\n",
      "15s - loss: 0.5102 - acc: 0.7914 - val_loss: 0.6486 - val_acc: 0.7248\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7bd6bc8190>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()\n",
    "model.fit(X_train_padded, Y_train, verbose=2, nb_epoch=4, batch_size=bs, validation_data=(X_test_padded, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Increase the number of neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe the model is simply to small to accomodate patterns in our data? Let's try to increase our neurons!\n",
    "\n",
    "**Your task** is to:\n",
    "\n",
    "- Mark this chunk and select *Cell* and then *Run All Above*\n",
    "- Increase the number of neurons to 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "inputs (InputLayer)              (None, 150)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)          (None, 150, 32)       1716704     inputs[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 10)            1720        embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "output (Dense)                   (None, 3)             33          lstm_1[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 1718457\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input = Input(shape=(timesteps,), name=\"inputs\")\n",
    "x = input\n",
    "\n",
    "### Your code/changes here\n",
    "x = Embedding(len(tokenizer.word_index)+1, 32, mask_zero=True)(x)\n",
    "x = LSTM(10)(x)\n",
    "###\n",
    "\n",
    "output = Dense(3, activation='softmax', name='output')(x)\n",
    "model1 = Model(input=input, output=output)\n",
    "model.summary()\n",
    "model1.compile(optimizer=Nadam(), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9707 samples, validate on 2427 samples\n",
      "Epoch 1/4\n",
      "13s - loss: 0.8607 - acc: 0.5486 - val_loss: 0.8328 - val_acc: 0.5595\n",
      "Epoch 2/4\n",
      "20s - loss: 0.5870 - acc: 0.7659 - val_loss: 0.6142 - val_acc: 0.7417\n",
      "Epoch 3/4\n",
      "16s - loss: 0.4027 - acc: 0.8527 - val_loss: 0.5867 - val_acc: 0.7779\n",
      "Epoch 4/4\n",
      "16s - loss: 0.2838 - acc: 0.9071 - val_loss: 0.6504 - val_acc: 0.7697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7bceaba7d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train_padded, Y_train, verbose=2, nb_epoch=4, batch_size=bs, validation_data=(X_test_padded, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Use Bidirectional layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make our model deeper! This is deep learning after all. Note that our network is already deep in time, i.e. we take into consideration 150 time steps. But we can also make it deeper vertically.\n",
    "\n",
    "Your task is to\n",
    "\n",
    "- instead of LSTM use Bidirectional LSTM layer with 20 neurons\n",
    "\n",
    "- Next, add another bidirectional LSTM layer on top of the first layer. At each time step, the first LSTM will feed into the second LSTM. This is called stacking.\n",
    "\n",
    "Note that for this, you have to set *return_sequences=True* in the first LSTM. Do you understand why this is required?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = Input(shape=(timesteps,), name=\"inputs\")\n",
    "x = input\n",
    "\n",
    "x = Embedding(len(tokenizer.word_index)+1, 32, mask_zero=True)(x)\n",
    "\n",
    "### Your code goes here:\n",
    "\n",
    "##\n",
    "\n",
    "output = Dense(3, activation='softmax', name='output')(x)\n",
    "model2 = Model(input=input, output=output)\n",
    "model2.compile(optimizer=Nadam(), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"387pt\" viewBox=\"0.00 0.00 485.00 387.00\" width=\"485pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 383)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-383 481,-383 481,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140169725083600 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140169725083600</title>\n",
       "<polygon fill=\"none\" points=\"111,-332.5 111,-378.5 366,-378.5 366,-332.5 111,-332.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"169.5\" y=\"-351.8\">inputs: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"228,-332.5 228,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"255.5\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"228,-355.5 283,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"255.5\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"283,-332.5 283,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"324.5\" y=\"-363.3\">(None, 150)</text>\n",
       "<polyline fill=\"none\" points=\"283,-355.5 366,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"324.5\" y=\"-340.3\">(None, 150)</text>\n",
       "</g>\n",
       "<!-- 140169724653968 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140169724653968</title>\n",
       "<polygon fill=\"none\" points=\"78.5,-249.5 78.5,-295.5 398.5,-295.5 398.5,-249.5 78.5,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"159\" y=\"-268.8\">embedding_3: Embedding</text>\n",
       "<polyline fill=\"none\" points=\"239.5,-249.5 239.5,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"267\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"239.5,-272.5 294.5,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"267\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"294.5,-249.5 294.5,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"346.5\" y=\"-280.3\">(None, 150)</text>\n",
       "<polyline fill=\"none\" points=\"294.5,-272.5 398.5,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"346.5\" y=\"-257.3\">(None, 150, 32)</text>\n",
       "</g>\n",
       "<!-- 140169725083600&#45;&gt;140169724653968 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140169725083600-&gt;140169724653968</title>\n",
       "<path d=\"M238.5,-332.366C238.5,-324.152 238.5,-314.658 238.5,-305.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"242,-305.607 238.5,-295.607 235,-305.607 242,-305.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140169724686736 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140169724686736</title>\n",
       "<polygon fill=\"none\" points=\"0,-166.5 0,-212.5 477,-212.5 477,-166.5 0,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"159\" y=\"-185.8\">bidirectional_1(forward_lstm_3): Bidirectional(LSTM)</text>\n",
       "<polyline fill=\"none\" points=\"318,-166.5 318,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"345.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"318,-189.5 373,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"345.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"373,-166.5 373,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"425\" y=\"-197.3\">(None, 150, 32)</text>\n",
       "<polyline fill=\"none\" points=\"373,-189.5 477,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"425\" y=\"-174.3\">(None, 150, 40)</text>\n",
       "</g>\n",
       "<!-- 140169724653968&#45;&gt;140169724686736 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140169724653968-&gt;140169724686736</title>\n",
       "<path d=\"M238.5,-249.366C238.5,-241.152 238.5,-231.658 238.5,-222.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"242,-222.607 238.5,-212.607 235,-222.607 242,-222.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140169720975440 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140169720975440</title>\n",
       "<polygon fill=\"none\" points=\"0,-83.5 0,-129.5 477,-129.5 477,-83.5 0,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"159\" y=\"-102.8\">bidirectional_2(forward_lstm_4): Bidirectional(LSTM)</text>\n",
       "<polyline fill=\"none\" points=\"318,-83.5 318,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"345.5\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"318,-106.5 373,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"345.5\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"373,-83.5 373,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"425\" y=\"-114.3\">(None, 150, 40)</text>\n",
       "<polyline fill=\"none\" points=\"373,-106.5 477,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"425\" y=\"-91.3\">(None, 40)</text>\n",
       "</g>\n",
       "<!-- 140169724686736&#45;&gt;140169720975440 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140169724686736-&gt;140169720975440</title>\n",
       "<path d=\"M238.5,-166.366C238.5,-158.152 238.5,-148.658 238.5,-139.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"242,-139.607 238.5,-129.607 235,-139.607 242,-139.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140169728402576 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140169728402576</title>\n",
       "<polygon fill=\"none\" points=\"127,-0.5 127,-46.5 350,-46.5 350,-0.5 127,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"173\" y=\"-19.8\">output: Dense</text>\n",
       "<polyline fill=\"none\" points=\"219,-0.5 219,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"246.5\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"219,-23.5 274,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"246.5\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"274,-0.5 274,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"312\" y=\"-31.3\">(None, 40)</text>\n",
       "<polyline fill=\"none\" points=\"274,-23.5 350,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"312\" y=\"-8.3\">(None, 3)</text>\n",
       "</g>\n",
       "<!-- 140169720975440&#45;&gt;140169728402576 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>140169720975440-&gt;140169728402576</title>\n",
       "<path d=\"M238.5,-83.3664C238.5,-75.1516 238.5,-65.6579 238.5,-56.7252\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"242,-56.6068 238.5,-46.6068 235,-56.6069 242,-56.6068\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(model2, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9707 samples, validate on 2427 samples\n",
      "Epoch 1/4\n",
      "58s - loss: 0.6929 - acc: 0.6878 - val_loss: 0.5845 - val_acc: 0.7639\n",
      "Epoch 2/4\n",
      "62s - loss: 0.4149 - acc: 0.8440 - val_loss: 0.9511 - val_acc: 0.6106\n",
      "Epoch 3/4\n",
      "65s - loss: 0.2554 - acc: 0.9090 - val_loss: 0.6795 - val_acc: 0.7709\n",
      "Epoch 4/4\n",
      "56s - loss: 0.1583 - acc: 0.9491 - val_loss: 0.7258 - val_acc: 0.7487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7bb93cbc90>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train_padded, Y_train, verbose=2, nb_epoch=4, batch_size=bs, validation_data=(X_test_padded, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Add regularization\n",
    "\n",
    "There are two major ways to regularize a model and to prevent overfitting.\n",
    "\n",
    "1. Dropout randomly sets a fraction *rate* of input units to 0 at each update during training time\n",
    "2. L2 regularizer\n",
    "\n",
    "\n",
    "Your task is to add dropout to the Model from the previous step. `Dropout` is just another layer you can add to your model definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = Input(shape=(timesteps,), name=\"inputs\")\n",
    "x = input\n",
    "\n",
    "### Your code goes here:\n",
    "\n",
    "##\n",
    "\n",
    "output = Dense(3, activation='softmax', name='output')(x)\n",
    "model3 = Model(input=input, output=output)\n",
    "model3.compile(optimizer=Nadam(), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9707 samples, validate on 2427 samples\n",
      "Epoch 1/4\n",
      "52s - loss: 0.7300 - acc: 0.6734 - val_loss: 0.5658 - val_acc: 0.7800\n",
      "Epoch 2/4\n",
      "51s - loss: 0.4844 - acc: 0.8221 - val_loss: 0.5880 - val_acc: 0.7779\n",
      "Epoch 3/4\n",
      "56s - loss: 0.3740 - acc: 0.8709 - val_loss: 0.5880 - val_acc: 0.7804\n",
      "Epoch 4/4\n",
      "75s - loss: 0.2803 - acc: 0.9087 - val_loss: 0.7187 - val_acc: 0.7664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7baaca89d0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(X_train_padded, Y_train, verbose=2, nb_epoch=4, batch_size=bs, validation_data=(X_test_padded, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Feature Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This task will be a bit more challenging. We are going to use an additional attribute: tags on the forum. However, because this attribute is temporally constant we will not add it to LSTM that summarizes the time series.\n",
    "\n",
    "Instead, we will *merge* the $n$-dimensional vector output of the LSTM with a $m$-dimensional vector of one-hot encoded tags, where merging means concatenating the two vectors into a vector of dimensionality $n+m$.\n",
    "\n",
    "Conveniently, we have already encoded tags as a one-hot vector, i.e. the columns in the following matrix correspond to unique tags. Note that matrix is very sparse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tags_train = np.array(X_train.drop('question', axis=1))\n",
    "tags_test = np.array(X_test.drop('question', axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you have to do the following:\n",
    "\n",
    "- Create a second Input with shape `(number_of_tags, )`. Call it input2.\n",
    "- Introduce a [Merge](https://keras.io/getting-started/sequential-model-guide/#the-merge-layer) layer that merges `[x, your_new_input]`. This can be done using the `merge([...], mode=\"concat\")` **function** (not the `Merge` class).\n",
    "\n",
    "Note that you have to implement all of the above tasks before your model actually works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = Input(shape=(timesteps,), name=\"inputs\")\n",
    "number_of_tags = tags_train.shape[1]\n",
    "x = Embedding(len(tokenizer.word_index)+1, 32)(input)\n",
    "x = LSTM(20)(x)\n",
    "\n",
    "### Your code here\n",
    "\n",
    "###\n",
    "\n",
    "output = Dense(3, activation='softmax', name='output')(x)\n",
    "model4 = Model(input=[input, input2], output=output)\n",
    "model4.compile(optimizer=Nadam(), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"387pt\" viewBox=\"0.00 0.00 583.00 387.00\" width=\"583pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 383)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-383 579,-383 579,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140169123120464 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140169123120464</title>\n",
       "<polygon fill=\"none\" points=\"32.5,-332.5 32.5,-378.5 287.5,-378.5 287.5,-332.5 32.5,-332.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"91\" y=\"-351.8\">inputs: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"149.5,-332.5 149.5,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"177\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"149.5,-355.5 204.5,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"177\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"204.5,-332.5 204.5,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"246\" y=\"-363.3\">(None, 150)</text>\n",
       "<polyline fill=\"none\" points=\"204.5,-355.5 287.5,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"246\" y=\"-340.3\">(None, 150)</text>\n",
       "</g>\n",
       "<!-- 140169123106064 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140169123106064</title>\n",
       "<polygon fill=\"none\" points=\"0,-249.5 0,-295.5 320,-295.5 320,-249.5 0,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"80.5\" y=\"-268.8\">embedding_5: Embedding</text>\n",
       "<polyline fill=\"none\" points=\"161,-249.5 161,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"188.5\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"161,-272.5 216,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"188.5\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"216,-249.5 216,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"268\" y=\"-280.3\">(None, 150)</text>\n",
       "<polyline fill=\"none\" points=\"216,-272.5 320,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"268\" y=\"-257.3\">(None, 150, 32)</text>\n",
       "</g>\n",
       "<!-- 140169123120464&#45;&gt;140169123106064 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140169123120464-&gt;140169123106064</title>\n",
       "<path d=\"M160,-332.366C160,-324.152 160,-314.658 160,-305.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"163.5,-305.607 160,-295.607 156.5,-305.607 163.5,-305.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140169123121232 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140169123121232</title>\n",
       "<polygon fill=\"none\" points=\"31.5,-166.5 31.5,-212.5 288.5,-212.5 288.5,-166.5 31.5,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"80.5\" y=\"-185.8\">lstm_7: LSTM</text>\n",
       "<polyline fill=\"none\" points=\"129.5,-166.5 129.5,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"157\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"129.5,-189.5 184.5,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"157\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"184.5,-166.5 184.5,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"236.5\" y=\"-197.3\">(None, 150, 32)</text>\n",
       "<polyline fill=\"none\" points=\"184.5,-189.5 288.5,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"236.5\" y=\"-174.3\">(None, 20)</text>\n",
       "</g>\n",
       "<!-- 140169123106064&#45;&gt;140169123121232 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140169123106064-&gt;140169123121232</title>\n",
       "<path d=\"M160,-249.366C160,-241.152 160,-231.658 160,-222.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"163.5,-222.607 160,-212.607 156.5,-222.607 163.5,-222.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140169122863632 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140169122863632</title>\n",
       "<polygon fill=\"none\" points=\"136,-83.5 136,-129.5 464,-129.5 464,-83.5 136,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"190\" y=\"-102.8\">merge_1: Merge</text>\n",
       "<polyline fill=\"none\" points=\"244,-83.5 244,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"271.5\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"244,-106.5 299,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"271.5\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"299,-83.5 299,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"381.5\" y=\"-114.3\">[(None, 20), (None, 1329)]</text>\n",
       "<polyline fill=\"none\" points=\"299,-106.5 464,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"381.5\" y=\"-91.3\">(None, 1349)</text>\n",
       "</g>\n",
       "<!-- 140169123121232&#45;&gt;140169122863632 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140169123121232-&gt;140169122863632</title>\n",
       "<path d=\"M198.256,-166.366C215.078,-156.634 235.003,-145.106 252.742,-134.842\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"254.888,-137.644 261.791,-129.607 251.382,-131.585 254.888,-137.644\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140169123120848 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140169123120848</title>\n",
       "<polygon fill=\"none\" points=\"307,-166.5 307,-212.5 575,-212.5 575,-166.5 307,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"369\" y=\"-185.8\">inputs2: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"431,-166.5 431,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"458.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"431,-189.5 486,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"458.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"486,-166.5 486,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"530.5\" y=\"-197.3\">(None, 1329)</text>\n",
       "<polyline fill=\"none\" points=\"486,-189.5 575,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"530.5\" y=\"-174.3\">(None, 1329)</text>\n",
       "</g>\n",
       "<!-- 140169123120848&#45;&gt;140169122863632 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>140169123120848-&gt;140169122863632</title>\n",
       "<path d=\"M402.471,-166.366C385.529,-156.634 365.462,-145.106 347.596,-134.842\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"348.897,-131.553 338.482,-129.607 345.41,-137.623 348.897,-131.553\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140169123104528 -->\n",
       "<g class=\"node\" id=\"node6\"><title>140169123104528</title>\n",
       "<polygon fill=\"none\" points=\"182,-0.5 182,-46.5 418,-46.5 418,-0.5 182,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"228\" y=\"-19.8\">output: Dense</text>\n",
       "<polyline fill=\"none\" points=\"274,-0.5 274,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"301.5\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"274,-23.5 329,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"301.5\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"329,-0.5 329,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"373.5\" y=\"-31.3\">(None, 1349)</text>\n",
       "<polyline fill=\"none\" points=\"329,-23.5 418,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"373.5\" y=\"-8.3\">(None, 3)</text>\n",
       "</g>\n",
       "<!-- 140169122863632&#45;&gt;140169123104528 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>140169122863632-&gt;140169123104528</title>\n",
       "<path d=\"M300,-83.3664C300,-75.1516 300,-65.6579 300,-56.7252\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"303.5,-56.6068 300,-46.6068 296.5,-56.6069 303.5,-56.6068\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(model4, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9707 samples, validate on 2427 samples\n",
      "Epoch 1/4\n",
      "16s - loss: 0.1534 - acc: 0.9534 - val_loss: 0.4707 - val_acc: 0.8171\n",
      "Epoch 2/4\n",
      "18s - loss: 0.1066 - acc: 0.9693 - val_loss: 0.4906 - val_acc: 0.8208\n",
      "Epoch 3/4\n",
      "16s - loss: 0.0691 - acc: 0.9829 - val_loss: 0.4910 - val_acc: 0.8105\n",
      "Epoch 4/4\n",
      "19s - loss: 0.0456 - acc: 0.9890 - val_loss: 0.7159 - val_acc: 0.7771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7bb8c02e10>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit([X_train_padded, tags_train], Y_train, verbose=2, nb_epoch=4, batch_size=bs, validation_data=([X_test_padded, tags_test], Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes the deep learning tutorial. Thank you for your attendance!\n",
    "\n",
    "If you still have some free time, you are welcome to experiment further with your architecture. Things you can try:\n",
    "\n",
    "- Combine your solution from task 4 with your solution from task 2/3.\n",
    "- Use GRU instead of LSTM units\n",
    "- Try l2 regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://raw.githubusercontent.com/fhirschmann/deeping/master/dl4nlp/wd.png)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
