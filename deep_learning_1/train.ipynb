{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Deep Learning Tutorial 1: Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the first deep learning tutorial!\n",
    "\n",
    "In this notebook, we are going to apply neural networks to detect failures of harddrives based on S.M.A.R.T. status observations.\n",
    "\n",
    "Note that you can interrupt the training process at any time by clicking on *Kernel* and then *Interrupt*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the [Keras](http://keras.io) framework that abstracts away a lot of the tedious details of deep learning. There are two ways to build neural networks in Keras, the [sequential API](https://keras.io/getting-started/sequential-model-guide/) and the [funcational API](https://keras.io/getting-started/functional-api-guide/)\n",
    "\n",
    "We will only use the funcational API due to its expressive power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequential API:\n",
    "\n",
    "```Python\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=784))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(64, input_dim=784))\n",
    "model.add(Activation('relu'))\n",
    "```\n",
    "\n",
    "#### Functional API\n",
    "```Python\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# this returns a tensor\n",
    "inputs = Input(shape=(784,))\n",
    "\n",
    "# a layer instance is callable on a tensor, and returns a tensor\n",
    "x = Dense(64, activation='relu')(inputs)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# this creates a model that includes\n",
    "# the Input layer and three Dense layers\n",
    "model = Model(input=inputs, output=predictions)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Same in both APIs\n",
    "\n",
    "```Python\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(data, labels) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why is the Funcional API better?\n",
    "\n",
    "It allows us to do more, for example when using the functional API we can reuse trained layers and we can train multi input and multi output models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "np.random.seed(42)\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.layers.wrappers import *\n",
    "from keras.optimizers import *\n",
    "from keras.regularizers import l2, activity_l2\n",
    "from keras.utils.visualize_util import plot, model_to_dot\n",
    "from IPython.display import SVG\n",
    "\n",
    "from callbacks import AUCHistory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \"image_dim_ordering\": \"tf\", \r\n",
      "    \"epsilon\": 1e-07, \r\n",
      "    \"floatx\": \"float32\", \r\n",
      "    \"backend\": \"theano\"\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "! cat ~/.keras/keras.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use TensorFlow we can edit the file and change the backend to \"tensorflow\". There is no need to change this for this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Set Information:\n",
    "\n",
    "The data is related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be ('yes') or not ('no') subscribed.\n",
    "\n",
    "\n",
    "Input variables:\n",
    "\n",
    "#### Bank client data:\n",
    "1.  age (numeric)\n",
    "2.  job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
    "3. marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
    "4. education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
    "5. default: has credit in default? (categorical: 'no','yes','unknown')\n",
    "6. housing: has housing loan? (categorical: 'no','yes','unknown')\n",
    "7. loan: has personal loan? (categorical: 'no','yes','unknown')\n",
    "#### related with the last contact of the current campaign:\n",
    "8. contact: contact communication type (categorical: 'cellular','telephone')\n",
    "9. month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
    "10. day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
    "11. duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "#### other attributes:\n",
    "12. campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "13. pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
    "14. previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "15. poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
    "#### social and economic context attributes\n",
    "16. emp.var.rate: employment variation rate - quarterly indicator (numeric)\n",
    "17. cons.price.idx: consumer price index - monthly indicator (numeric)\n",
    "18. cons.conf.idx: consumer confidence index - monthly indicator (numeric)\n",
    "19. euribor3m: euribor 3 month rate - daily indicator (numeric)\n",
    "20. nr.employed: number of employees - quarterly indicator (numeric)\n",
    "#### Output variable (desired target):\n",
    "21. y - has the client subscribed a term deposit? (binary: 'yes','no')\n",
    "\n",
    "### Citation:\n",
    "[Moro et al., 2014] S. Moro, P. Cortez and P. Rita. A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems, Elsevier, 62:22-31, June 2014\n",
    "\n",
    "Description and data download location:https://archive.ics.uci.edu/ml/datasets/Bank+Marketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41188, 21)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank = pd.read_csv('bank-additional/bank-additional-full.csv', sep=';')\n",
    "bank.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                 int64\n",
       "job                object\n",
       "marital            object\n",
       "education          object\n",
       "default            object\n",
       "housing            object\n",
       "loan               object\n",
       "contact            object\n",
       "month              object\n",
       "day_of_week        object\n",
       "duration            int64\n",
       "campaign            int64\n",
       "pdays               int64\n",
       "previous            int64\n",
       "poutcome           object\n",
       "emp.var.rate      float64\n",
       "cons.price.idx    float64\n",
       "cons.conf.idx     float64\n",
       "euribor3m         float64\n",
       "nr.employed       float64\n",
       "y                  object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize the numerical inputs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deeping/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/deeping/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/deeping/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/deeping/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/deeping/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/deeping/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/deeping/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/deeping/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/deeping/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/deeping/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "for c in bank.dtypes[bank.dtypes!='object'].index:\n",
    "    bank[[c]] = StandardScaler().fit_transform(bank[[c]].as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bank = pd.get_dummies(bank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                      float64\n",
       "duration                 float64\n",
       "campaign                 float64\n",
       "pdays                    float64\n",
       "previous                 float64\n",
       "emp.var.rate             float64\n",
       "cons.price.idx           float64\n",
       "cons.conf.idx            float64\n",
       "euribor3m                float64\n",
       "nr.employed              float64\n",
       "job_admin.               float64\n",
       "job_blue-collar          float64\n",
       "job_entrepreneur         float64\n",
       "job_housemaid            float64\n",
       "job_management           float64\n",
       "job_retired              float64\n",
       "job_self-employed        float64\n",
       "job_services             float64\n",
       "job_student              float64\n",
       "job_technician           float64\n",
       "job_unemployed           float64\n",
       "job_unknown              float64\n",
       "marital_divorced         float64\n",
       "marital_married          float64\n",
       "marital_single           float64\n",
       "marital_unknown          float64\n",
       "education_basic.4y       float64\n",
       "education_basic.6y       float64\n",
       "education_basic.9y       float64\n",
       "education_high.school    float64\n",
       "                          ...   \n",
       "default_unknown          float64\n",
       "default_yes              float64\n",
       "housing_no               float64\n",
       "housing_unknown          float64\n",
       "housing_yes              float64\n",
       "loan_no                  float64\n",
       "loan_unknown             float64\n",
       "loan_yes                 float64\n",
       "contact_cellular         float64\n",
       "contact_telephone        float64\n",
       "month_apr                float64\n",
       "month_aug                float64\n",
       "month_dec                float64\n",
       "month_jul                float64\n",
       "month_jun                float64\n",
       "month_mar                float64\n",
       "month_may                float64\n",
       "month_nov                float64\n",
       "month_oct                float64\n",
       "month_sep                float64\n",
       "day_of_week_fri          float64\n",
       "day_of_week_mon          float64\n",
       "day_of_week_thu          float64\n",
       "day_of_week_tue          float64\n",
       "day_of_week_wed          float64\n",
       "poutcome_failure         float64\n",
       "poutcome_nonexistent     float64\n",
       "poutcome_success         float64\n",
       "y_no                     float64\n",
       "y_yes                    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = bank.drop(['y_no', 'y_yes'], axis=1)\n",
    "Y = bank[['y_no', 'y_yes']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is already ordered by time so we can split in trait, validation, and test sets manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24712, 63), (8238, 63), (8238, 63))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X[:int(0.6*X.shape[0])]\n",
    "X_validation = X[int(0.6*X.shape[0]):int(0.8*X.shape[0])]\n",
    "X_test = X[int(0.8*X.shape[0]):]\n",
    "X_train.shape, X_validation.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24712, 2), (8238, 2), (8238, 2))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train = Y[:int(0.6*X.shape[0])]\n",
    "Y_validation = Y[int(0.6*X.shape[0]):int(0.8*X.shape[0])]\n",
    "Y_test = Y[int(0.8*X.shape[0]):]\n",
    "Y_train.shape, Y_validation.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    23524\n",
       "1.0     1188\n",
       "Name: y_yes, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train['y_yes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    7326\n",
       "1.0     912\n",
       "Name: y_yes, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_validation['y_yes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    5698\n",
       "1.0    2540\n",
       "Name: y_yes, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test['y_yes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_records = X_train.shape[0]\n",
    "n_features = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define the input layer, which just takes in our data. It does not contain any logic other than defining the shape of our input. Since we use the functional API, this also means that all matrix shapes in the following layers will be inferred automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=(n_features,), name=\"inputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the first dimension, *n_records*, is automatically inferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on callbacks see \n",
    "* https://keras.io/callbacks/\n",
    "* https://keunwoochoi.wordpress.com/2016/07/16/keras-callbacks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "        \n",
    "class AUCHistory(keras.callbacks.Callback):\n",
    "    def __init__(self, input_len=1, *args, **kwargs):\n",
    "        self.input_len = input_len\n",
    "        super(AUCHistory, self).__init__(*args, **kwargs)\n",
    " \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        # self.model.training_data cannot be used!\n",
    "        y_pred_train = self.model.predict(X_train.as_matrix())\n",
    "        auc_train = roc_auc_score(Y_train['y_yes'], y_pred_train[:, 1])\n",
    "        \n",
    "        y_pred_val = self.model.predict(self.model.validation_data[0])\n",
    "        auc_val = roc_auc_score(self.model.validation_data[1][:, 1], y_pred_val[:, 1])\n",
    "        print(\"\\nAUC train: {0}, validation: {1}\\n\".format(auc_train, auc_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24712 samples, validate on 8238 samples\n",
      "Epoch 1/10\n",
      "24608/24712 [============================>.] - ETA: 0s - loss: 0.1267 - acc: 0.9550\n",
      "AUC train: 0.958223355387, validation: 0.862175722373\n",
      "\n",
      "24712/24712 [==============================] - 0s - loss: 0.1267 - acc: 0.9550 - val_loss: 0.2624 - val_acc: 0.8928\n",
      "Epoch 2/10\n",
      "24576/24712 [============================>.] - ETA: 0s - loss: 0.1010 - acc: 0.9570\n",
      "AUC train: 0.961879607731, validation: 0.856278227989\n",
      "\n",
      "24712/24712 [==============================] - 0s - loss: 0.1010 - acc: 0.9570 - val_loss: 0.2931 - val_acc: 0.8904\n",
      "Epoch 3/10\n",
      "24352/24712 [============================>.] - ETA: 0s - loss: 0.0974 - acc: 0.9570\n",
      "AUC train: 0.963083067397, validation: 0.830024327557\n",
      "\n",
      "24712/24712 [==============================] - 0s - loss: 0.0975 - acc: 0.9570 - val_loss: 0.3230 - val_acc: 0.8897\n",
      "Epoch 4/10\n",
      "24448/24712 [============================>.] - ETA: 0s - loss: 0.0960 - acc: 0.9578\n",
      "AUC train: 0.963628484299, validation: 0.806826563406\n",
      "\n",
      "24712/24712 [==============================] - 0s - loss: 0.0960 - acc: 0.9579 - val_loss: 0.3492 - val_acc: 0.8871\n",
      "Epoch 5/10\n",
      "24608/24712 [============================>.] - ETA: 0s - loss: 0.0949 - acc: 0.9574\n",
      "AUC train: 0.964460860089, validation: 0.799608445168\n",
      "\n",
      "24712/24712 [==============================] - 0s - loss: 0.0948 - acc: 0.9574 - val_loss: 0.3820 - val_acc: 0.8869\n",
      "Epoch 6/10\n",
      "24256/24712 [============================>.] - ETA: 0s - loss: 0.0934 - acc: 0.9589\n",
      "AUC train: 0.964681388504, validation: 0.785223920092\n",
      "\n",
      "24712/24712 [==============================] - 0s - loss: 0.0941 - acc: 0.9585 - val_loss: 0.4155 - val_acc: 0.8871\n",
      "Epoch 7/10\n",
      "24384/24712 [============================>.] - ETA: 0s - loss: 0.0942 - acc: 0.9585\n",
      "AUC train: 0.964859138772, validation: 0.785706460049\n",
      "\n",
      "24712/24712 [==============================] - 0s - loss: 0.0939 - acc: 0.9586 - val_loss: 0.4586 - val_acc: 0.8888\n",
      "Epoch 8/10\n",
      "24576/24712 [============================>.] - ETA: 0s - loss: 0.0939 - acc: 0.9594\n",
      "AUC train: 0.965248042403, validation: 0.775941611468\n",
      "\n",
      "24712/24712 [==============================] - 0s - loss: 0.0937 - acc: 0.9594 - val_loss: 0.4846 - val_acc: 0.8893\n",
      "Epoch 9/10\n",
      "24512/24712 [============================>.] - ETA: 0s - loss: 0.0937 - acc: 0.9586\n",
      "AUC train: 0.96534907469, validation: 0.772176333032\n",
      "\n",
      "24712/24712 [==============================] - 0s - loss: 0.0934 - acc: 0.9587 - val_loss: 0.5167 - val_acc: 0.8886\n",
      "Epoch 10/10\n",
      "24608/24712 [============================>.] - ETA: 0s - loss: 0.0931 - acc: 0.9594\n",
      "AUC train: 0.965448800909, validation: 0.763061805825\n",
      "\n",
      "24712/24712 [==============================] - 0s - loss: 0.0932 - acc: 0.9593 - val_loss: 0.5396 - val_acc: 0.8886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f45789677d0>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = Input(shape=(n_features,), name=\"inputs\")\n",
    "\n",
    "x = Dense(32, activation='relu')(inputs)\n",
    "predictions = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = Model(input=inputs, output=predictions)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "#               loss='kullback_leibler_divergence',\n",
    "              metrics=['accuracy'],)\n",
    "\n",
    "model.fit(X_train.as_matrix(), Y_train.as_matrix(), \n",
    "          validation_data=(X_validation.as_matrix(), Y_validation.as_matrix()), \n",
    "          callbacks=[AUCHistory()])  # starts training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Try different configurations\n",
    "\n",
    "Using the below configuratin play with different values for learning rate (lr), momentum, decay, and nesterov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24712 samples, validate on 8238 samples\n",
      "Epoch 1/10\n",
      "24512/24712 [============================>.] - ETA: 0s - loss: 0.6251 - acc: 0.8904\n",
      "AUC train: 0.780957423238, validation: 0.660926776058\n",
      "\n",
      "24712/24712 [==============================] - 1s - loss: 0.6245 - acc: 0.8911 - val_loss: 0.6106 - val_acc: 0.8897\n",
      "Epoch 2/10\n",
      "24608/24712 [============================>.] - ETA: 0s - loss: 0.5029 - acc: 0.9518\n",
      "AUC train: 0.817491266889, validation: 0.670111573894\n",
      "\n",
      "24712/24712 [==============================] - 1s - loss: 0.5026 - acc: 0.9519 - val_loss: 0.5431 - val_acc: 0.8893\n",
      "Epoch 3/10\n",
      "24640/24712 [============================>.] - ETA: 0s - loss: 0.4169 - acc: 0.9519\n",
      "AUC train: 0.84007252855, validation: 0.675361366151\n",
      "\n",
      "24712/24712 [==============================] - 1s - loss: 0.4168 - acc: 0.9519 - val_loss: 0.4942 - val_acc: 0.8893\n",
      "Epoch 4/10\n",
      "24608/24712 [============================>.] - ETA: 0s - loss: 0.3548 - acc: 0.9521\n",
      "AUC train: 0.855723640932, validation: 0.679904336154\n",
      "\n",
      "24712/24712 [==============================] - 1s - loss: 0.3549 - acc: 0.9519 - val_loss: 0.4580 - val_acc: 0.8893\n",
      "Epoch 5/10\n",
      "24512/24712 [============================>.] - ETA: 0s - loss: 0.3099 - acc: 0.9518\n",
      "AUC train: 0.867776683545, validation: 0.684175727761\n",
      "\n",
      "24712/24712 [==============================] - 2s - loss: 0.3096 - acc: 0.9519 - val_loss: 0.4308 - val_acc: 0.8893\n",
      "Epoch 6/10\n",
      "24608/24712 [============================>.] - ETA: 0s - loss: 0.2765 - acc: 0.9518\n",
      "AUC train: 0.877786358455, validation: 0.688494415468\n",
      "\n",
      "24712/24712 [==============================] - 2s - loss: 0.2763 - acc: 0.9519 - val_loss: 0.4100 - val_acc: 0.8893\n",
      "Epoch 7/10\n",
      "24576/24712 [============================>.] - ETA: 0s - loss: 0.2516 - acc: 0.9520\n",
      "AUC train: 0.886307171356, validation: 0.692860923124\n",
      "\n",
      "24712/24712 [==============================] - 1s - loss: 0.2517 - acc: 0.9519 - val_loss: 0.3940 - val_acc: 0.8893\n",
      "Epoch 8/10\n",
      "24512/24712 [============================>.] - ETA: 0s - loss: 0.2336 - acc: 0.9518\n",
      "AUC train: 0.893766975285, validation: 0.697379646393\n",
      "\n",
      "24712/24712 [==============================] - 1s - loss: 0.2333 - acc: 0.9519 - val_loss: 0.3814 - val_acc: 0.8893\n",
      "Epoch 9/10\n",
      "24704/24712 [============================>.] - ETA: 0s - loss: 0.2194 - acc: 0.9520\n",
      "AUC train: 0.900296788379, validation: 0.70187509579\n",
      "\n",
      "24712/24712 [==============================] - 1s - loss: 0.2194 - acc: 0.9519 - val_loss: 0.3714 - val_acc: 0.8893\n",
      "Epoch 10/10\n",
      "24672/24712 [============================>.] - ETA: 0s - loss: 0.2089 - acc: 0.9519\n",
      "AUC train: 0.90607155197, validation: 0.706418739313\n",
      "\n",
      "24712/24712 [==============================] - 1s - loss: 0.2089 - acc: 0.9519 - val_loss: 0.3633 - val_acc: 0.8893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f456ecafdd0>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = Input(shape=(n_features,), name=\"inputs\")\n",
    "x = Dense(256, activation='tanh', init='uniform')(inputs)\n",
    "x = Dense(256, activation='tanh', init='uniform')(x)\n",
    "x = Dense(256, activation='tanh', init='uniform')(x)\n",
    "predictions = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = Model(input=inputs, output=predictions)\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.0, decay=0.0, nesterov=False),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'],)\n",
    "\n",
    "model.fit(X_train.as_matrix(), Y_train.as_matrix(), \n",
    "          validation_data=(X_validation.as_matrix(), Y_validation.as_matrix()), \n",
    "          nb_epoch=10,\n",
    "          callbacks=[AUCHistory()])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Regularization\n",
    "\n",
    "We will use rmsprop from simplicity from now on!\n",
    "\n",
    "Have a look at the performance of the below network per epoch and notice how it degregates. Use dropout and other regularization techniques to fix this problem.\n",
    "\n",
    "Dropout is a layer that can be added before every layer except Input.\n",
    "\n",
    "* Dropout: https://keras.io/layers/core/#dropout\n",
    "* Regularizers: https://keras.io/regularizers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24712 samples, validate on 8238 samples\n",
      "Epoch 1/10\n",
      "24416/24712 [============================>.] - ETA: 0s - loss: 0.1123 - acc: 0.9554\n",
      "AUC train: 0.963536487129, validation: 0.82562840951\n",
      "\n",
      "24712/24712 [==============================] - 0s - loss: 0.1122 - acc: 0.9552 - val_loss: 0.3017 - val_acc: 0.8889\n",
      "Epoch 2/10\n",
      "24192/24712 [============================>.] - ETA: 0s - loss: 0.0968 - acc: 0.9574\n",
      "AUC train: 0.965037193192, validation: 0.805273799517\n",
      "\n",
      "24712/24712 [==============================] - 0s - loss: 0.0969 - acc: 0.9573 - val_loss: 0.3506 - val_acc: 0.8882\n",
      "Epoch 3/10\n",
      "24384/24712 [============================>.] - ETA: 0s - loss: 0.0953 - acc: 0.9577\n",
      "AUC train: 0.965286956025, validation: 0.788884279016\n",
      "\n",
      "24712/24712 [==============================] - 0s - loss: 0.0949 - acc: 0.9579 - val_loss: 0.4357 - val_acc: 0.8906\n",
      "Epoch 4/10\n",
      "24704/24712 [============================>.] - ETA: 0s - loss: 0.0944 - acc: 0.9582\n",
      "AUC train: 0.965807164057, validation: 0.780398894708\n",
      "\n",
      "24712/24712 [==============================] - 0s - loss: 0.0943 - acc: 0.9582 - val_loss: 0.4480 - val_acc: 0.8915\n",
      "Epoch 5/10\n",
      "24288/24712 [============================>.] - ETA: 0s - loss: 0.0936 - acc: 0.9598\n",
      "AUC train: 0.966993519621, validation: 0.765906157354\n",
      "\n",
      "24712/24712 [==============================] - 0s - loss: 0.0932 - acc: 0.9599 - val_loss: 0.5293 - val_acc: 0.8891\n",
      "Epoch 6/10\n",
      "24416/24712 [============================>.] - ETA: 0s - loss: 0.0927 - acc: 0.9597\n",
      "AUC train: 0.966196121362, validation: 0.75333938903\n",
      "\n",
      "24712/24712 [==============================] - 0s - loss: 0.0926 - acc: 0.9598 - val_loss: 0.5950 - val_acc: 0.8897\n",
      "Epoch 7/10\n",
      "24544/24712 [============================>.] - ETA: 0s - loss: 0.0923 - acc: 0.9593\n",
      "AUC train: 0.967402389966, validation: 0.737466608355\n",
      "\n",
      "24712/24712 [==============================] - 0s - loss: 0.0921 - acc: 0.9595 - val_loss: 0.6213 - val_acc: 0.8917\n",
      "Epoch 8/10\n",
      "24448/24712 [============================>.] - ETA: 0s - loss: 0.0912 - acc: 0.9599\n",
      "AUC train: 0.967739104615, validation: 0.721403221403\n",
      "\n",
      "24712/24712 [==============================] - 0s - loss: 0.0915 - acc: 0.9599 - val_loss: 0.6304 - val_acc: 0.8906\n",
      "Epoch 9/10\n",
      "24352/24712 [============================>.] - ETA: 0s - loss: 0.0915 - acc: 0.9597\n",
      "AUC train: 0.967919395451, validation: 0.726491069419\n",
      "\n",
      "24712/24712 [==============================] - 0s - loss: 0.0913 - acc: 0.9599 - val_loss: 0.7462 - val_acc: 0.8905\n",
      "Epoch 10/10\n",
      "24608/24712 [============================>.] - ETA: 0s - loss: 0.0911 - acc: 0.9614\n",
      "AUC train: 0.96827723975, validation: 0.717861701414\n",
      "\n",
      "24712/24712 [==============================] - 0s - loss: 0.0909 - acc: 0.9615 - val_loss: 0.6857 - val_acc: 0.8914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f45923024d0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = Input(shape=(n_features,), name=\"inputs\")\n",
    "x = Dense(64, activation='relu')(inputs)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "predictions = Dense(2, activation='softmax')(x)\n",
    "\n",
    "# this creates a model that includes\n",
    "# the Input layer and three Dense layers\n",
    "model = Model(input=inputs, output=predictions)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train.as_matrix(), Y_train.as_matrix(), \n",
    "          validation_data=(X_validation.as_matrix(), Y_validation.as_matrix()), \n",
    "          callbacks=[AUCHistory()])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, add a Dropout layer before every Dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, add more layers :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third, add weight regularization to each Dense layer (W_regularizer=l2(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Architecture\n",
    "\n",
    "We have two groups of very different features: client and macro economical.\n",
    "\n",
    "Let's create two separate neural networks and combine them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_X(X):\n",
    "    X_train = X[:int(0.6*X.shape[0])]\n",
    "    X_validation = X[int(0.6*X.shape[0]):int(0.8*X.shape[0])]\n",
    "    X_test = X[int(0.8*X.shape[0]):]\n",
    "    return X_train, X_validation, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "macro = ['emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
    "\n",
    "X_macro = bank[macro]\n",
    "X_rest = bank.drop(['y_no', 'y_yes']+macro, axis=1)\n",
    "\n",
    "X_macro_train, X_macro_validation, X_macro_test = split_X(X_macro)\n",
    "X_rest_train, X_rest_validation, X_rest_test = split_X(X_rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24712, 5), (8238, 5), (8238, 5))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_macro_train.shape, X_macro_validation.shape, X_macro_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24712, 58), (8238, 58), (8238, 58))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_rest_train.shape, X_rest_validation.shape, X_rest_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An auto-encoder example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24712 samples, validate on 8238 samples\n",
      "Epoch 1/20\n",
      "24712/24712 [==============================] - 0s - loss: 0.2681 - val_loss: 2.0811\n",
      "Epoch 2/20\n",
      "24712/24712 [==============================] - 0s - loss: 0.1236 - val_loss: 1.9559\n",
      "Epoch 3/20\n",
      "24712/24712 [==============================] - 0s - loss: 0.1143 - val_loss: 1.8732\n",
      "Epoch 4/20\n",
      "24712/24712 [==============================] - 0s - loss: 0.1091 - val_loss: 1.7941\n",
      "Epoch 5/20\n",
      "24712/24712 [==============================] - 0s - loss: 0.1061 - val_loss: 1.6896\n",
      "Epoch 6/20\n",
      "24712/24712 [==============================] - 0s - loss: 0.1050 - val_loss: 1.6468\n",
      "Epoch 7/20\n",
      "24712/24712 [==============================] - 0s - loss: 0.1022 - val_loss: 1.6177\n",
      "Epoch 8/20\n",
      "24712/24712 [==============================] - 0s - loss: 0.1011 - val_loss: 1.5867\n",
      "Epoch 9/20\n",
      "24712/24712 [==============================] - 0s - loss: 0.1007 - val_loss: 1.5495\n",
      "Epoch 10/20\n",
      "24712/24712 [==============================] - 0s - loss: 0.0997 - val_loss: 1.4410\n",
      "Epoch 11/20\n",
      "24712/24712 [==============================] - 0s - loss: 0.0986 - val_loss: 1.3130\n",
      "Epoch 12/20\n",
      "24712/24712 [==============================] - 0s - loss: 0.0982 - val_loss: 1.2738\n",
      "Epoch 13/20\n",
      "24712/24712 [==============================] - 0s - loss: 0.0984 - val_loss: 1.0895\n",
      "Epoch 14/20\n",
      "24712/24712 [==============================] - 0s - loss: 0.0973 - val_loss: 1.1363\n",
      "Epoch 15/20\n",
      "24712/24712 [==============================] - 0s - loss: 0.0971 - val_loss: 1.0245\n",
      "Epoch 16/20\n",
      "24712/24712 [==============================] - 0s - loss: 0.0975 - val_loss: 1.0510\n",
      "Epoch 17/20\n",
      "24712/24712 [==============================] - 0s - loss: 0.0968 - val_loss: 1.0020\n",
      "Epoch 18/20\n",
      "24712/24712 [==============================] - 0s - loss: 0.0984 - val_loss: 0.9644\n",
      "Epoch 19/20\n",
      "24712/24712 [==============================] - 0s - loss: 0.0972 - val_loss: 0.9978\n",
      "Epoch 20/20\n",
      "24712/24712 [==============================] - 0s - loss: 0.0964 - val_loss: 0.9238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4564800fd0>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout = 0.5\n",
    "inputs_macro = Input(shape=(X_macro_train.shape[1],), name=\"inputs_macro\")\n",
    "x_macro = Dropout(dropout)(inputs_macro)\n",
    "x_macro = Dense(20, activation='relu')(x_macro)\n",
    "x_macro = Dropout(dropout)(x_macro)\n",
    "x_macro = Dense(20, activation='relu')(x_macro)\n",
    "x_macro = Dropout(dropout)(x_macro)\n",
    "predictions_macro = Dense(X_macro_train.shape[1], activation='linear')(x_macro)\n",
    "\n",
    "# this creates a model that includes\n",
    "# the Input layer and three Dense layers\n",
    "model = Model(input=inputs_macro, output=predictions_macro)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mse',\n",
    "              )\n",
    "model.fit(X_macro_train.as_matrix(), X_macro_train.as_matrix(), \n",
    "          validation_data=(X_macro_validation.as_matrix(), X_macro_validation.as_matrix()), \n",
    "          nb_epoch=20\n",
    "          )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's combine auto-encoder with the rest of the variables, in an end-to-end fashion!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AUCHistoryCombined(keras.callbacks.Callback):\n",
    "    def __init__(self, validation, input_len=1, *args, **kwargs):\n",
    "        self.input_len = input_len\n",
    "        self.validation = validation\n",
    "        super(AUCHistoryCombined, self).__init__(*args, **kwargs)\n",
    " \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        # self.model.training_data cannot be used!\n",
    "        y_pred_train = self.model.predict([X_macro_train.as_matrix(), X_rest_train.as_matrix()])\n",
    "        auc_train = roc_auc_score(Y_train['y_yes'], y_pred_train[1][:, 1])\n",
    "        \n",
    "        y_pred_val = self.model.predict(self.validation[0])\n",
    "        auc_val = roc_auc_score(self.validation[1][1][:, 1], y_pred_val[1][:, 1])\n",
    "        print(\"\\nAUC train: {0}, validation: {1}\\n\".format(auc_train, auc_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "24672/24712 [============================>.] - ETA: 0s - loss: 0.2510 - dense_388_loss: 0.3206 - dense_391_loss: 0.1869\n",
      "AUC train: 0.949633857706, validation: 0.853528618331\n",
      "\n",
      "24712/24712 [==============================] - 1s - loss: 0.2510 - dense_388_loss: 0.3204 - dense_391_loss: 0.1869     \n",
      "Epoch 2/10\n",
      "24576/24712 [============================>.] - ETA: 0s - loss: 0.2030 - dense_388_loss: 0.1388 - dense_391_loss: 0.1753\n",
      "AUC train: 0.946403919745, validation: 0.794246324674\n",
      "\n",
      "24712/24712 [==============================] - 1s - loss: 0.2026 - dense_388_loss: 0.1387 - dense_391_loss: 0.1749     \n",
      "Epoch 3/10\n",
      "24608/24712 [============================>.] - ETA: 0s - loss: 0.2045 - dense_388_loss: 0.1324 - dense_391_loss: 0.1780\n",
      "AUC train: 0.944227243815, validation: 0.812567277205\n",
      "\n",
      "24712/24712 [==============================] - 1s - loss: 0.2045 - dense_388_loss: 0.1323 - dense_391_loss: 0.1780     \n",
      "Epoch 4/10\n",
      "24512/24712 [============================>.] - ETA: 0s - loss: 0.2030 - dense_388_loss: 0.1284 - dense_391_loss: 0.1773\n",
      "AUC train: 0.938834066305, validation: 0.79631919599\n",
      "\n",
      "24712/24712 [==============================] - 1s - loss: 0.2027 - dense_388_loss: 0.1283 - dense_391_loss: 0.1771     \n",
      "Epoch 5/10\n",
      "24512/24712 [============================>.] - ETA: 0s - loss: 0.1971 - dense_388_loss: 0.1268 - dense_391_loss: 0.1717\n",
      "AUC train: 0.937318760924, validation: 0.758412569268\n",
      "\n",
      "24712/24712 [==============================] - 1s - loss: 0.1967 - dense_388_loss: 0.1267 - dense_391_loss: 0.1714     \n",
      "Epoch 6/10\n",
      "24448/24712 [============================>.] - ETA: 0s - loss: 0.2033 - dense_388_loss: 0.1257 - dense_391_loss: 0.1782\n",
      "AUC train: 0.938846804925, validation: 0.786302750119\n",
      "\n",
      "24712/24712 [==============================] - 1s - loss: 0.2035 - dense_388_loss: 0.1258 - dense_391_loss: 0.1784     \n",
      "Epoch 7/10\n",
      "24608/24712 [============================>.] - ETA: 0s - loss: 0.2036 - dense_388_loss: 0.1243 - dense_391_loss: 0.1787\n",
      "AUC train: 0.934758584542, validation: 0.739589020839\n",
      "\n",
      "24712/24712 [==============================] - 1s - loss: 0.2039 - dense_388_loss: 0.1243 - dense_391_loss: 0.1790     \n",
      "Epoch 8/10\n",
      "24512/24712 [============================>.] - ETA: 0s - loss: 0.1993 - dense_388_loss: 0.1243 - dense_391_loss: 0.1744\n",
      "AUC train: 0.948588825682, validation: 0.830849839074\n",
      "\n",
      "24712/24712 [==============================] - 1s - loss: 0.1996 - dense_388_loss: 0.1243 - dense_391_loss: 0.1748     \n",
      "Epoch 9/10\n",
      "24576/24712 [============================>.] - ETA: 0s - loss: 0.2007 - dense_388_loss: 0.1230 - dense_391_loss: 0.1761\n",
      "AUC train: 0.94142923811, validation: 0.776135136333\n",
      "\n",
      "24712/24712 [==============================] - 1s - loss: 0.2005 - dense_388_loss: 0.1230 - dense_391_loss: 0.1759     \n",
      "Epoch 10/10\n",
      "24512/24712 [============================>.] - ETA: 0s - loss: 0.1980 - dense_388_loss: 0.1218 - dense_391_loss: 0.1737\n",
      "AUC train: 0.931737080463, validation: 0.734289013894\n",
      "\n",
      "24712/24712 [==============================] - 1s - loss: 0.1984 - dense_388_loss: 0.1219 - dense_391_loss: 0.1740     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f455aefe210>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout = 0.5\n",
    "\n",
    "# First sub-network\n",
    "inputs_macro = Input(shape=(X_macro_train.shape[1],), name=\"inputs_macro\")\n",
    "x_macro = Dropout(dropout)(inputs_macro)\n",
    "x_macro = Dense(20, activation='relu')(x_macro)\n",
    "x_macro = Dropout(dropout)(x_macro)\n",
    "x_macro = Dense(20, activation='relu')(x_macro)\n",
    "x_macro = Dropout(dropout)(x_macro)\n",
    "predictions_macro = Dense(X_macro_train.shape[1], activation='linear')(x_macro)\n",
    "\n",
    "# Second sub-network\n",
    "inputs_rest = Input(shape=(X_rest_train.shape[1],), name=\"inputs_rest\")\n",
    "x_rest = Dropout(dropout)(inputs_rest)\n",
    "x_rest = Dense(128)(x_rest)\n",
    "x_rest = Dropout(dropout)(x_rest)\n",
    "x_rest = Dense(128)(x_rest)\n",
    "\n",
    "# Merging\n",
    "x = merge([x_rest, x_macro], mode='concat')\n",
    "predictions_rest = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = Model(input=[inputs_macro, inputs_rest], output=[predictions_macro, predictions_rest])\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss=['mse', 'categorical_crossentropy'] ,\n",
    "              loss_weights=[0.2, 1.]\n",
    "              )\n",
    "\n",
    "model.fit([X_macro_train.as_matrix(), X_rest_train.as_matrix()], \n",
    "          [X_macro_train.as_matrix(), Y_train.as_matrix()],\n",
    "          nb_epoch=10,\n",
    "          callbacks=[AUCHistoryCombined(validation=([X_macro_validation.as_matrix(), X_rest_validation.as_matrix()],\n",
    "                                                    [X_macro_validation.as_matrix(), Y_validation.as_matrix()]), )]\n",
    "         \n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excercise: add more layers after mergin, and play with the acritecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "Comment out the standardisation of numerical inputs and run a network with rmsprop (task 1 or 2). What happens to the validatin AUC?\n",
    "\n",
    "You will need to re-run the preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
